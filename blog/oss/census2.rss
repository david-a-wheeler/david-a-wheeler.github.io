<?xml version="1.0" encoding="UTF-8"?>
<!-- name="generator" content="blosxom/2.0" -->

<rss version="2.0">
  <channel>
    <title>David A. Wheeler's Blog   </title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"></meta>
    <link>https://www.dwheeler.com/blog</link>
    <description>David A. Wheeler's weblog.</description>
    <language>en</language>

  <item>
    <title>Census II Report on Open Source Software</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"></meta>
    <link>https://www.dwheeler.com/blog/2020/02/18#census2</link>
    <pubDate>Tue, 18 Feb 2020 18:25 GMT</pubDate>
    <!-- date: 2020-02-18 -->
    <description>
&lt;p&gt;
The Linux Foundation and the Laboratory for Innovation
Science at Harvard have just released a new report:
&lt;a href=&quot;https://www.coreinfrastructure.org/programs/census-program-ii/&quot;
&gt;“Vulnerabilities in the Core: Preliminary Report and
Census II of Open Source Software” by Frank Nagle, Jessica
Wilkerson, James Dana, and Jennifer L. Hoffman, 2020-02-14&lt;/a&gt;.
Just click on “Download Report” when you get there.  &lt;a
href=&quot;https://www.hbs.edu/news/releases/Pages/census-open-source-software-security.aspx&quot;
&gt;A summary is available from Harvard&lt;/a&gt;.
Here&amp;#8217;s a quick introduction to the paper.
&lt;/p&gt;

&lt;p&gt;
Their long-term goal is to figure out what FOSS packages are most
critical through data analysis.  This turns out to extremely difficult,
as discussed in the paper, and they expressly state that their current
results “cannot - and do not purport to - be a definitive claim of which
FOSS packages are the most critical”.  That said, they have developed
a method as a “proof of concept” to start working towards that answer.
&lt;/p&gt;

&lt;p&gt;
They describe their approach in detail. Here’s a quick summary.
First they use data from Software Composition Analysis
(SCAs) and application security companies, including Snyk and Synopsys
Cybersecurity Research Center, to identify components used in actual systems.
They then use dependency analysis (via libraries.io) to identify indirect (transitive) dependencies.
Finally, they averaged the Z-scores to provide normalized rankings.
&lt;/p&gt;

&lt;p&gt;
Here are some key lessons learned from the report (Chapter 7):
&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;There’s a need for a standardized naming scheme for software components.
&lt;li&gt;There’s an increasing importance of individual developer account security.
&lt;li&gt;Legacy software persists in the open source space.
&lt;/ul&gt;

&lt;p&gt;
Also, here&amp;#8217;s an interesting nugget:
“These statistics illustrate an interesting pattern: a high
correlation between being employed and being a top contributor to one
of the FOSS packages identified as most used.”
&lt;/p&gt;

&lt;p&gt;
I’m on the CII Steering Committee, so I did comment on an earlier draft,
but credit goes to the actual authors.
&lt;/p&gt;
</description>
   </item>
  </channel>
</rss>