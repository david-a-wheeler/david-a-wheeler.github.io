<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta>
<link rel="alternate" type="application/rss+xml" title="RSS" href="https://www.dwheeler.com/blog/index.rss"></link>
<title>David A. Wheeler's Blog   </title>
<meta name="viewport" content="width=device-width, initial-scale=1.0"></meta>
</head>
<body>
<h1 style="margin-left: auto; margin-right: auto; width: 50%;">David A. Wheeler's Blog</h1><p>  </p><p></p><h1>Thu, 23 Nov 2017</h1>
<p><a name="net-neutrality-freedom"><font size="+2"><b>FCC Votes against the People and Net Neutrality: Freedom is Slavery</b></font></a></p><p></p>
<p>
To the surprise of no one, the US FCC led by Ajit Pai has finally
issued the order to kill net neutrality.
</p>

<p>
In short, the FCC is voting to directly
harm the US people and instead aid the monopolist
Intenet Service Providers (ISPs).
<a href="https://www.techdirt.com/articles/20171122/09473038669/fcc-releases-net-neutrality-killing-order-hopes-youre-too-busy-cooking-turkey-to-read-it.shtml">More information is on Tech Dirt</a>.
</p>

<p>
This is inexcusable.
Competition is often the best way to get good results,
but for various reasons customers often cannot practically choose ISPs;
in many cases they are essentially monopolies or duopolies.
Where competition does not effectively exist, there must be
regulation to prevent the monopolists from exploiting their customers,
and the FCC has decided to expressly reject their duty to the
people of the United States.
</p>

<p>
Orwell would be proud of the order&#8217;s name,
&#8220;Restoring Internet Freedom&#8221;.
Remember, Freedom is Slavery!
</p>

<p>
I&#8217;m sure we have not heard the end of this.
This entire process was filled with fraud, with sock puppets proposing
to end net neutrality while real people were ignored.
All Americans need to make it clear to their representatives that
Internet access is important, and that ISPs must be required to neutral
carriers, instead of giving preferences to some sites or charging extra
for some sites.
I recommend
voting against any representatives who fail to protect Internet access,
as the FCC has failed to do.
</p>
<p>path: <a href="https://www.dwheeler.com/blog/misc">/misc</a> | <a href="https://www.dwheeler.com/blog">Current Weblog</a> | <a href="https://www.dwheeler.com/blog/2017/11/23#net-neutrality-freedom">permanent link to this entry</a></p>
<h1>Sat, 23 Sep 2017</h1>
<p><a name="who-decides-update"><font size="+2"><b>Who decides when you need to update vulnerable software? (Equifax)</b></font></a></p><p></p>
<p>
I have a trick question:
Who decides when you <i>need</i> to update vulnerable software
(presuming that if it&#8217;s unpatched it might lead to bad consequences)?
In a company, is that the information technology (IT) department?
The chief information officer (CIO)?
A policy?
The user of the computer?
At home, is it the user of the computer?
Perhaps the family&#8217;s &#8220;tech support&#8221; person?
</p>
<p>
Remember, it&#8217;s a trick question.  What&#8217;s the answer?
The answer is&#8230;
</p>
<p>
<b>The attacker decides.</b>
</p>
<p>
The <i>attacker</i> is the person who decides when you get attacked, and how.
Not the computer user.  Not a document.  Not support. Not an executive.
<i>The attacker decides.</i>
And that means <i>the attacker decides when you need to update
your vulnerable software</i>.
If that statement makes you uncomfortable,
then you need to change your thinking.
This is reality.
</p>
<p>
So let&#8217;s look at Equifax, and see what we can learn from it.
</p>
<p>
Let&#8217;s start with the first revelation in 2017:
<a href="https://arstechnica.com/information-technology/2017/09/massive-equifax-breach-caused-by-failure-to-patch-two-month-old-bug/">A security vulnerability
in Apache Struts (a widely-used software component)
was fixed in March 2017, but Equifax failed to update it for two whole months,
leading to the loss of
sensitive information on about 143 million US consumers</a>.
The update was available for free, for two months, and it was well-known
that attackers were <i>exploiting</i> this vulnerability in other
organizations.
Can we excuse Equifax?
Is it &#8220;too hard&#8221; to update vulnerable software (aka &#8220;patch&#8221;) in a timely way?
Is it acceptable that organizations fail to update vulnerable components
when those vulnerabilities allow unauthorized
access to lots of sensitive high-value data?
</p>
<p>
<i>Nonsense.</i>
Equifax may <i>choose</i> to fail to update known vulnerable components.
Clearly it did so!
But Equifax <i>needed</i> to update rapidly, because <i>the need to update
was decided by the attackers</i>, not by Equifax.
In fact, two months is an absurdly long time, because again, the timeframe
is determined by the <i>attacker</i>.
</p>
<p>
Now it&#8217;s true that if you don&#8217;t plan to rapidly update, it&#8217;s
hard to update.
Too bad.  Nobody cares.
Vulnerabilities are routinely found in software components, and have been
for decades.
Since it is 100% predictable that there will be vulnerabilities found in
the software you use (including third-party software components you reuse),
you need to <i>plan ahead</i>.
I don&#8217;t know when it will rain, but I know it will, so
I plan ahead by paying for a roof and buying umbrellas.
When something is certain to happen, you need to plan for it.
For example, make sure you rapidly learn about vulnerabilities in
third party software you depend on,
and that you have a process in place (with tools and
automated testing) so that you can update and ship in minutes, not months.
Days, not decades.
</p>
<p>
The
<a href="https://blogs.apache.org/foundation/entry/apache-struts-statement-on-equifax">Apache Struts Statement on Equifax Security Breach</a>
has some great points about how to properly handle
reused software components (no matter where it&#8217;s from).
The Apache Struts team notes that you should
(1) understand the software you use,
(2) establish a rapid update process,
(3) remember that all complex software has flaws,
(4) establish security layers, and
(5) establish monitoring.
Their statement has more details, in particular for #2 they say,
&#8220;establish a process to quickly roll out a security fix release&#8230;
[when reused software] needs to be updated for security reasons. Best
is to think in terms of hours or a few days, not weeks or months.&#8221;
</p>
<p>
Many militaries refer to the
<a href="https://en.wikipedia.org/wiki/OODA_loop">&#8220;OODA loop&#8221;, which is the
decision cycle of observe, orient, decide, and act</a>.
The idea was developed by military strategist and
United States Air Force Colonel John Boyd.
Boyd noted that, &#8220;In order to win, we should operate at a faster tempo
or rhythm than our adversaries&#8230;&#8221;.
Of course, if you want to lose, then you simply need to operate more
slowly than your adversary.
You need to get comfortable with this adversarial terminology, because
if you&#8217;re running a computer system today, you <i>are</i> in an
adversarial situation, and the attackers are your adversaries.
</p>
<p>
In short, you <i>must</i> update your software when vulnerabilities
are found <i>before</i> attackers can exploit them (if they can be exploited).
If you can&#8217;t do that, then you need to change how you manage your software
so <i>can</i> do that.
Again, <b>the attacker decides how fast you need to react</b>.
</p>
<p>
We&#8217;re only beginnning to learn about the Equifax disaster of 2017, but
it&#8217;s clear that Equifax &#8220;security&#8221; is just one failure after another.
The more we learn, the worse it gets.
Here are some of the information we have so far.
Equifax used the rediculous pair
<a href="https://www.cnbc.com/2017/09/14/equifax-used-admin-for-the-login-and-password-of-a-non-us-database.html">Username &#8220;admin&#8221;, password
&#8220;admin&#8221;</a> for a database with personal employee information.
<a href="https://www.grc.com/sn/SN-628-Notes.pdf">Security Now! #628</a>
showed that Equifax recommended using Netscape Navigator in their
website discussion on security, a rediculously obsolete suggestion
(Netscape shut down in 2003, 14 years ago).
Equifax provided customers with PINs that were simply the date and time,
making the PINs predictable and thus insecure.
Equifax set up a &#8220;checker&#8221; site
<a href="https://techcrunch.com/2017/09/08/psa-no-matter-what-you-write-equifax-may-tell-you-youve-been-impacted-by-the-hack/">which makes false statements</a>:
&#8220;In what is an unconscionable move by the credit report company, the
checker site, hosted by Equifax product TrustID, seems to be telling
people at random they may have been affected by the data breach&#8230;
It&#8217;s clear Equifax&#8217;s goal isn&#8217;t to protect the consumer or
bring them vital information. It&#8217;s to get you to sign up for its
revenue-generating product TrustID&#8230;  [and] TrustID&#8217;s Terms of Service [say]
that anyone signing up for the product is barred from suing the company after.&#8221;
<a href="http://www.zdnet.com/article/equifax-freeze-your-account-site-is-also-vulnerable-to-hacking/">Equifax&#8217;s credit report monitoring site was
found to be vulnerable to hacking</a>
(specifically, an XSS vulnerability that was quickly found by others).
Equifax failed to use its own domain name for all its sites (as is standard),
making it easy for others to spoof them.
Indeed, NPR reported that that
<a href="http://www.npr.org/sections/thetwo-way/2017/09/21/552681357/after-massive-data-breach-equifax-directed-customers-to-fake-site">&#8221;After Massive Data Breach, Equifax Directed Customers To Fake Site&#8221;</a>.
There are now suggestions that there were
<a href="https://arstechnica.com/information-technology/2017/09/massive-equifax-hack-reportedly-started-4-months-before-it-was-detected/">break-ins even
earlier</a> which Equifax never detected.
In short: The more we learn, the worse it gets.
</p>

<p>
Most obviously, Equifax failed
to responsibly update a known vulnerable component
in a timely way.
Updating software doesn&#8217;t matter when there&#8217;s no valuable
information, but in this case
extremely sensitive personal data was involved.
This was especially sensitive data, Equifax was using a component version
with a publicly-known vulnerability, and it was known that attackers were
exploiting that vulnerability.
It was completely foreseeable that attackers would use this vulnerable
component to extract sensitive data.
In short, Equifax had a duty of care
that they failed to perform.
Sometimes attackers perform an unprecedented kind of sneaky attack,
and get around a host of prudent defenses;
that would be different.
But there is no excuse for failing to promptly respond
when you <i>know</i> that a component is vulnerable.
That is negligence.
</p>
<p>
But how can you quickly update software components?
Does this require magic?  Not at all, it just requires accepting that
this <i>will</i> happen and so you <i>must</i> be ready.
This is not an unpredictable event; I may not know exactly <i>when</i>
it will happen, but I can be certain that it <i>will</i> happen.
Once you accept that it will happen, you can easily get ready for it.
There are tools that can help you monitor when your components publicly
report a vulnerability or security update, so that you quickly find out
when you have a problem.
Package managers let you rapidly download, review, and update a component.
You need to have an automated checking system that
uses a variety of static tools, automated test suites,
and other dynamic tools so that you can be confident that the system
(with updated component) works correctly.
You need to be confident that you can ship to production immediately
with acceptable risk after
you&#8217;ve updated your component and run your automated checking system.
If you&#8217;re not confident, then your checking system is unacceptable and
needs to be fixed.
You also need to quickly ship that to production (and this must be
automated), because again,
you have to address vulnerabilities <i>faster</i> than the attacker.
</p>
<p>
Of course, your risks go down much further if you think about security
the whole time you&#8217;re developing software.
For example, you can design your system so that a defect is
(1) less likely to lead to a system vulnerability or
(2) has less of an impact.
When you do that, then a component vulnerability will often not
lead to a system vulnerability anyway.
A single vulnerability in a front-end component should not
have allowed such a disastrous outcome in the first place, since this
was especially sensitive data, so the Equifax
design also appears to have been negligent.
They also failed to detect the problem for a long time; you should be
monitoring high-value systems, to help reduce the impact of a vulnerability.
The failure to notice this is also hard to justify.
Developing secure software is quite possible, and you don&#8217;t need to
break the bank to do it.
It&#8217;s impossible in the real world to be perfect,
but it&#8217;s very possible to be <i>adequately</i> secure.
</p>
<p>
Sadly, very few software developers know how to develop secure software.
So I&#8217;ve created a video that&#8217;s on YouTube that should help:
<a href="https://www.youtube.com/watch?v=5a5D4d6hcEY">&#8220;How to Develop Secure Applications: The BadgeApp Example&#8221; (by David A. Wheeler)</a>.
This walks through a real-world program (BadgeApp)
as an example, to show approaches
for developing far more secure software.
If you&#8217;re involved in software development in any way, I encourage you
to take a look at that video.
Your software will almost certainly look different, but if you think
about security throughout development, the results will almost certainly
be much better.
Perfection is impossible, but you can <i>manage</i> your risks, that is,
reduce the probability and impact of attacks.
There are a wide variety of countermeasures that can often prevent attacks,
and they work well when combined with monitoring and response mechanisms
for the relatively few attacks that get through.
</p>
<p>
The contrast between Equifax and BadgeApp is stark.
Full disclosure: I am the technical lead of the BadgeApp project&#8230; but
it is clear we did a better job than Equifax.
Earlier this week a vulnerability was announced
in one of the components (nokogiri) that is used by the BadgeApp.
This vulnerability was announced on
<a href="https://github.com/rubysec/ruby-advisory-db">ruby-advisory-db</a>,
a database of vulnerable Ruby gems (software library components)
used to report to users about component vulnerabilities.
Within two hours of that announcement the BadgeApp
project had downloaded the security update, run the BadgeApp
application through a variety of tools and its automated test suite
(with 100% statement coverage) to make sure everything was okay,
and pushed the fixed version to the production site.
The BadgeApp application is a simpler program, sure, but it also manages much
less sensitive data than Equifax&#8217;s systems.
We should expect Equifax to do <i>at least</i> as well, because they
handle much more sensitive data.
Instead,
Equifax failed to update reused components with known vulnerabilities in
a timely fashion.
</p>
<p>
Remember, <b>the attacker decides</b>.
</p>
<p>
The attacker decides how fast you need to react, what you need to defend
against, and what you need to counter.
More generally, the attacker decides how much you need to do to
counter attacks.
You do not get to decide what the attacker will choose to do.
But you <i>can</i> plan ahead to make your software secure.
</p>
<p>path: <a href="https://www.dwheeler.com/blog/security">/security</a> | <a href="https://www.dwheeler.com/blog">Current Weblog</a> | <a href="https://www.dwheeler.com/blog/2017/09/23#who-decides-update">permanent link to this entry</a></p>
</body></html>