<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta>
<link rel="alternate" type="application/rss+xml" title="RSS" href="http://www.dwheeler.com/blog/index.rss"></link>
<title>David A. Wheeler's Blog   </title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>
<h1 style="margin-left: auto; margin-right: auto; width: 50%;">David A. Wheeler's Blog</h1><p>  </p><p></p><h1>Sat, 24 Jun 2006</h1>
<p><a name="wisdom-crowds"><font size="+2"><b>The Wisdom of Crowds and Free-Libre / Open Source Software</b></font></a></p><p></p>
<p>
I just came across an interesting
<a href="http://leshatton.org/A17.html">
short essay by Dr. Les Hatton titled &#8220;Open source inevitably good&#8221;</a>;
it appears it was published in the July 2005 <i>IT week</i>.
He has some intriguing conclusions about free-libre / open source software
(FLOSS).
</p>
<p>
But first, a little about
<a href="http://leshatton.org/">Dr. Hatton</a>, to show that he
is no lightweight.
Dr. Hatton holds the Chair in Forensic Software Engineering at the
University of Kingston, UK,
he is a fellow of the British Computer Society,
and was voted in &#8220;World&#8217;s leading Scholars of
Systems and Software Engineering (1993-2002)&#8221;
by U.S. Journal of Systems and Software.
His
<a href="http://leshatton.org/index_CS.html">
work in computer science</a> has primarily been in the field
of software failure, especially the design and execution of experiments
to determine the cause and reduce the likelihood
of failure in software systems.
He&#8217;s particularly known for his work on
<a href="http://leshatton.org/index_SA.html">safer language subsets</a>,
such as &#8220;Safer C&#8221;.
One paper of his I especially like is
<a href="http://leshatton.org/ISOC_subset1103.html">
&#8220;EC&#8212;, a measurement based safer subset of ISO C suitable
for embedded system development&#8221;</a> - in this, he <i>measures</i>
the common mistakes made in C by professional developers, and then
proposes simple rules to reduce their likelihood (if you write software
in C, it&#8217;s definitely worth reading).
In any case, here is someone who understands software development,
and in particular has carefully studied why software fails
and how to prevent such failures in the future.
</p>
<p>
In his essay
<a href="http://leshatton.org/A17.html">&#8220;Open source inevitably good&#8221;</a>,
Hatton starts by first examining James Surowiecki&#8217;s interesting book
&#8220;The Wisdom of Crowds: Why the Many are smarter than the Few&#8221;.
It turns out that crowds working together regularly beat the experts;
there&#8217;s both good evidence for this (with legions of examples),
and good mathematical underpinnings justifying this too.
For this to happen, two simple conditions must be met:
they must all have <i>some</i> knowledge, and they must
act effectively independently.
</p>
<p>
He notes that while the &#8220;many eyeballs&#8221; theory of Raymond still operates,
this &#8220;wisdom of the crowds&#8221; also has a strong effect.
In short, FLOSS software development often appears chaotic because
much of it uses a &#8220;survival of the fittest&#8221; development approach; several
different ideas are tried, and then the most successful approach is selected
by many others.
When viewed through the lens of the &#8220;wisdom of crowds&#8221;, this is
an entirely sensible thing to do.
He concludes this startling way:
&#8220;High quality open source isn&#8217;t a surprise, it&#8217;s inevitable.&#8221;
</p>
<p>
Obviously, there has to <i>be</i> a crowd for this concept to hold.
But there are many FLOSS projects where it&#8217;s obvious that there is a
crowd, <i>and</i> where the results are really very good.
So take a peek at <a href="http://leshatton.org/A17.html">
Les Hatton&#8217;s &#8220;Open source inevitably good&#8221;</a>.
It&#8217;s an interesting and provocative piece that will make you think.
</p>
<p>path: <a href="http://www.dwheeler.com/blog/oss">/oss</a> | <a href="http://www.dwheeler.com/blog">Current Weblog</a> | <a href="http://www.dwheeler.com/blog/2006/06/24#wisdom-crowds">permanent link to this entry</a></p>
<h1>Sat, 17 Jun 2006</h1>
<p><a name="readable-sweet-lisp"><font size="+2"><b>Readable s-expressions and sweet-expressions: Getting the infix fix and fewer parentheses in Lisp-like languages</b></font></a></p><p></p>
<p>
Lisp-based programming languages
normally represent programs as <i>s-expressions</i>,
where an operation and its parameters are surrounded by parentheses.
The operation to be performed is identified first,
and each parameter afterwards is
separated by whitespace.  So the traditional &#8220;2+3&#8221; is written as
&#8220;(+&nbsp;2&nbsp;3)&#8221; instead.
This is regular, but most people find this hard to read.
Here&#8217;s a longer example of an s-expression - notice the many parentheses
and the lack of infix operations:
<pre>
 (defun factorial (n)
   (if (&lt;= n 1)
       1
       (* n (factorial (- n 1)))))
</pre>
</p>

<p>
I think there&#8217;s a small resurging interest in Lisp-based systems, because Lisp
is still very good at &#8220;programs that manipulate programs&#8221;.
The major branches of Lisp (Common Lisp, Scheme, and Emacs Lisp) have
not disappeared, after all.
And I recently encountered a very cool and very new language in development,
<a href="http://www.coyotos.org/docs/bitc/spec.html">BitC</a>.
This language was created to write low-level programs
(e.g., operating system kernels and real-time programs)
that are easy to mathematically <i>prove</i> correct.
I learned about this very cool idea while writing my paper
<a href="http://www.dwheeler.com/essays/high-assurance-floss.html">
High Assurance (for Security or Safety) and
Free-Libre / Open Source Software (FLOSS)&#8230; with Lots on Formal Methods</a>.
BitC combines ideas from Scheme, ML, and C, but it&#8217;s represented using
s-expressions because it&#8217;s easy to manipulate program fragments that way.
I don&#8217;t know how well it&#8217;ll succeed, but it has a good chance;
if nothing else, I don&#8217;t know of <i>anyone</i> who&#8217;s tried this particular
approach.
The program-prover
<a href="http://www.cs.utexas.edu/users/moore/acl2/">ACL2</a> uses
Common Lisp as a basis, for the same reason: program-manipulating programs
are easy.
The FSF backs guile (a Scheme dialect) as their recommended
tool for scripting; guile gives lots of power in a small package.
</p>

<p>
But many software developers avoid Lisp-based languages,
even in cases where they would be a good tool to use, because
most software developers find s-expressions really hard to read.
S-expressions are very regular&#8230; but so is a Turing machine.
They don&#8217;t call it
&#8216;Lots of Irritating Superfluous Parentheses&#8217; for nothing.
Even if you can read it, most developers have to work with others.
Some people like s-expressions as they are - and if so, fine!
But many others are not satisfied with the status quo.
Lots of people have tried to create easier-to-read versions, but
they generally tend to lose the advantages of s-expressions
(such as powerful macro and quoting capabilities).
Can something be done to make it easy to create easier-to-read
code for Lisp-like languages - without spoiling their advantages?
</p>

<p>
I think something can be done, and
I hope to spur a discussion about various options.
To get that started, I&#8217;ve developed my own approach, &#8220;sweet-expressions&#8221;,
which I think is actually a plausible solution.
</p>

<p>
A sweet-expression reader will accept the traditional s-expressions
(except for some pathological cases),
but it also supports various extensions that make it easier to read.
Sweet-expressions are automatically translated into s-expressions, so
they lose no power.
Here&#8217;s how that same program above could be written using sweet-expressions:
<pre>
 defun factorial (n)         ; Parameters can be indented, but need not be
   if (n &lt;= 1)               ; Supports infix, prefix, &amp; function &lt;=(n 1)
       1                     ; This has no parameters, so it's an atom.
       n * factorial(n - 1)  ; Function(...) notation supported
</pre>
</p>

<p>
Sweet-expressions add the following abilities:
<ol>
<li><b>Indentation</b>. Indentation may be used instead
of parentheses to start and end
expressions: any indented line is a parameter of its parent,
later terms on a line are parameters of the first term,
lists of lists are marked with GROUP, and
a function call with 0 parameters is surrounded or followed by a pair of
parentheses [e.g., (pi) and pi()].
A &#8220;(&#8221; disables indentation until its matching &#8220;)&#8221;.
Blank lines at the beginning of a new expression are ignored.
A term that begins at the left edge and is immediately followed by newline
is immediately executed, to make interactive use pleasant.
<li><b>Name-ending</b>. Terms of the form &#8216;NAME(x y&#8230;)&#8217;, with no whitespace before
&#8216;(&#8217;, are interpreted as &#8216;(NAME x y&#8230;)&#8217;;.
Parameters are space-separated inside.
If its content is an infix expression, it&#8217;s considered one parameter instead
(so f(2 + 3) passes the its parameter, 5, to f).
<li><b>Infix</b>.  Optionally,
expressions are automatically interpreted as infix
if their second parameter is an infix operator
(by matching an &#8220;infix operator&#8221; pattern of symbols),
the first parameter is not an infix operator,
and it has at least three parameters.
Otherwise, expressions are interpreted as
normal &#8220;function first&#8221; prefix notation.
To disable infix interpretation, surround the second parameter with as(&#8230;).
Infix expressions must have an odd number of parameters with the
even ones being binary infix operators.
You must separate each infix operator with whitespace on both sides;
precedence is supported.
Use the &#8220;name-ending&#8221; form for unary operations, e.g., -(x) for &#8220;negate x&#8221;.
Thus &#8220;2 + y * -(x)&#8221; is a valid expression, equivalent to (+ 2 (* y (- x))).
Infix operators must match this pattern (and in Scheme cannot be =&gt;):
<pre>
    [+-\*/&lt;&gt;=&amp;\|\p{Sm}]{1-4}|\:
</pre>
</ol>
</p>

<p>
I call this combination &#8220;sweet-expressions&#8221;,
because by adding syntactic sugar (which are essentially abbreviations),
I hope to create a sweeter result.
</p>

<p>
For more information on sweet-expressions or on making
s-expressions more readable in general, see my website page at
<a href="http://www.dwheeler.com/readable">http://www.dwheeler.com/readable</a>.
For example, I provide a sweet-expression reader in Scheme
(under the MIT license), as well as an indenting pretty-printer in
Common Lisp.
In particular, you can
<a href="http://www.dwheeler.com/readable/readable-s-expressions.html">
see my lengthy paper about why sweet-expressions do what they do, and
some plausible alternatives.</a>
You can also download some other implementation code.
</p>

<p>
I&#8217;ve set up a
<a href="http://sourceforge.net/projects/readable">
SourceForge project named &#8220;readable&#8221;</a> to
discuss options in making s-expressions more readable,
and to distribute open source software to implement them
(unimplemented ideas don&#8217;t go far!).
I will probably need to work on other things for a while, but
since I had this idea, I thought it&#8217;d be a good idea to
write the idea and a quick sample demo of it, so that others could
build on top of it.
There hasn&#8217;t a single place for people to discuss how to make
s-expressions more readable.. so now there is one.
There are a lot of smart people out there; giving like-minded parties
a place to discuss them is likely to produce something good.
If you&#8217;re interested in this topic, please visit/join!
</p>
<p>path: <a href="http://www.dwheeler.com/blog/misc">/misc</a> | <a href="http://www.dwheeler.com/blog">Current Weblog</a> | <a href="http://www.dwheeler.com/blog/2006/06/17#readable-sweet-lisp">permanent link to this entry</a></p>
<p><a name="learning-masters"><font size="+2"><b>Learning from the Masters</b></font></a></p><p></p>
<p>
If you want to learn something, study what the masters do.
To me that seems obvious, and yet many don&#8217;t do it.
Perhaps we simply forget.
So let me inspire you with a few examples&#8230;
</p>
<p>
I just got an advance copy of David Shenk&#8217;s
&#8220;The Immortal Game: A history of chess&#8221; - and I&#8217;m referenced in it!
Which is an odd thing; I don&#8217;t normally think of myself
as a chess commentator.
But I do like the game of chess, and one of my key approaches to
getting better is simple: Study the games of good players.
I&#8217;ve even posted a few of the games with my comments on my web site,
including The Game of the Century
(<a href="http://www.dwheeler.com/misc/game_of_the_century.pgn">PGN</a>/<a href="http://www.dwheeler.com/misc/game_of_the_century.txt">Text</a>),
The Immortal Game (<a href="http://www.dwheeler.com/misc/immortal.pgn">PGN</a>/<a href="http://www.dwheeler.com/misc/immortal.txt">Text</a>),
The Evergreen Game (<a href="http://www.dwheeler.com/misc/evergreen.pgn">PGN</a>/<a href="http://www.dwheeler.com/misc/evergreen.txt">Text</a>),
and
Deep Blue - Kasparov, 1996, Game 1 (<a href="http://www.dwheeler.com/misc/deepblue-kasparov.pgn">PGN</a>/<a href="http://www.dwheeler.com/misc/deepblue-kasparov.txt">Text</a>).
It&#8217;s my Byrne/Fischer writeup that was referenced in Shenk&#8217;s book.
But I didn&#8217;t create that stuff for a book, originally.
I can&#8217;t play like these great players can,
but I get better by studying what they do.
In short, I&#8217;ve found that I must study the work of the masters.
</p>
<p>
There are many children&#8217;s educational philosophies that have, at least in part,
the notion of studying good examples as part of education.
Ruth Beechick&#8217;s &#8220;natural method&#8221; for teaching writing emphasizes starting
by copying and studying examples of great writing. She even notes
Jack London and Benjamin Franklin started by studying works they admired.
Learning begins by studying the work of the masters.
</p>
<p>
I often write about
<a href="http://www.dwheeler.com/oss_fs_why.html">
free-libre/open source software (FLOSS)</a>.
In part, I do because it&#8217;s one amazingly interesting development.
But there are other reasons, too.
Some developers of FLOSS programs are the best in the business -
you can learn a lot by seeing what they do.
In short, one important advantage of FLOSS is that it is now possible for
software developers to study the work of the masters.
</p>
<p>
I recently wrote the article
<a href="http://www.dwheeler.com/essays/high-assurance-floss.html">
High Assurance (for Security or Safety) and Free-Libre / Open Source Software (FLOSS)&#8230; with Lots on Formal Methods (aka high confidence or high integrity)</a>
(I gave it the long title to help people find it).
Here, I note the many tools to <i>create</i> high assurance software -
but there are precious few FLOSS examples of high assurance software.
True, there are very few examples of high assurance software, period,
but where are the high assurance software components that people can study
and modify without legal encumberances?
(If you know of more,
<a href="http://www.dwheeler.com/contactme.html">contact me</a>.)
That worries me; how are we supposed to educate people how to create
high assurance software, if students never see it?
People do not wake up one morning and discover that they are an expert.
They must learn, and books about a topic are not enough.
They must study the work of the masters.
</p>
<p>path: <a href="http://www.dwheeler.com/blog/misc">/misc</a> | <a href="http://www.dwheeler.com/blog">Current Weblog</a> | <a href="http://www.dwheeler.com/blog/2006/06/17#learning-masters">permanent link to this entry</a></p>
<h1>Tue, 13 Jun 2006</h1>
<p><a name="microsoft-outlook-tnef"><font size="+2"><b>How to read the mysterious Winmail.dat / Part 1.2 files (TNEF)</b></font></a></p><p></p>
<p>
All too often nowadays people report that they
&#8220;can&#8217;t open the attachment&#8221; of an email, because
they only received a file named (typically) &#8220;Part 1.2&#8221; or &#8220;Winmail.dat&#8221;.
</p>
<p>
The basic problem is that in certain cases Microsoft Outlook
uses a nonstandard extra packaging mechanism called &#8220;ms-tnef&#8221; or &#8220;tnef&#8221;
when it sends email - typically when it sends attachments.
What Outlook is <i>supposed</i> to do is simply use the industry standards
(such as MIME and HTML) directly for attachments, but Outlook fails to do so
and adds this other nonsense instead.
The full name of the format is &#8220;Transport Neutral Encapsulation Format&#8221;,
but that is a misleading name&#8230; it may be neutral on transport, but
it obstructs reception.
</p>
<p>
Almost no other email reader can read this nonstandard format.
Email clients that can&#8217;t (currently) read this format include
Lotus Notes, Thunderbird / Netscape Mail, and Eudora.
In fact, I&#8217;ve been told that
even Microsoft&#8217;s own Outlook Express can&#8217;t read this format!
</p>
<p>
So take a look at my new article,
<a href="http://www.dwheeler.com/essays/microsoft-outlook-tnef.html">Microsoft Outlook MS-TNEF handling (aka Winmail.dat or &#8220;Part 1.2&#8221; problem of unopenable email attachments)</a>.
It gives you a brief explanation of the problem, and what to do about it,
both from the sender view (how can I stop sending unopenable email?)
and the receiver view (how can I read them anyway?).
</p>
<p>path: <a href="http://www.dwheeler.com/blog/misc">/misc</a> | <a href="http://www.dwheeler.com/blog">Current Weblog</a> | <a href="http://www.dwheeler.com/blog/2006/06/13#microsoft-outlook-tnef">permanent link to this entry</a></p>
<h1>Mon, 05 Jun 2006</h1>
<p><a name="playstation3"><font size="+2"><b>Sony Playstation 3: Train wreck in process</b></font></a></p><p></p>
<p>
I try to keep up with the general gaming business.
Many of the best new computer hardware technologies
first show up in the gaming world, for one thing.
And for another, I once in the business; in the mid-1980s
I was lead software developer/maintainer for the first commercial
multiplayer role-playing game in the U.S.,
<a href="http://en.wikipedia.org/wiki/Scepter_of_Goth">Scepter of Goth</a>.
(Full disclosure: I didn&#8217;t write the original, I maintained it after
it had been initially developed. Scepter may have been
the first commercial multiplayer RPG in the world, but I have never gotten
good-enough data to show conclusively if MUD or Scepter were first.
Bartle&#8217;s MUD was clearly first in the UK, and Scepter
was clearly the first in the US, and neither knew of the other for
a long time.)
I also wrote some videogames for the Apple ][, which I sold.
(I still play occasionally, but my hand/eye coordination is awful;
my brother had to playtest them, since I couldn&#8217;t get far in my own games.)
I generally hope for good competition, since that is what keeps the
the innovation flowing and the prices down.
My hopes are getting dashed, because Sony seems to have had
a full lobotomy recently.
</p>
<p>
If Sony is trying to go (mostly) out of business, it&#8217;s
got a great process going.
Recently about half of Sony&#8217;s income has depended on the Playstation 2,
so you&#8217;d think that they would avoid bone-headed decisions that
would doom them in the market as they release their next-generation console.
</p>
<p>
But the
<a href="http://www.philly.com/mld/philly/news/columnists/14733980.htm">
Sony Playstation 3 will come with an outrageous pricetag</a>:
starting at $599 (or $499 for a stripped-down version).
Home video-game consoles have sold for $199 to $299 traditionally, and the
X-Box 360 (its primary competitor) costs much
less than this announced price too.
</p>
<p>
Why so much?
One significant reason is
because Sony is including a Blu-ray reader, a proprietary video format
that they hope will replace DVDs;
this is both raising the price substantially <i>and</i> appears to be
delaying shipment.
Didn&#8217;t Sony learn its lesson from Betamax, their earlier costly blunder
in the videotape format war?
No, it appears that Sony must go out of business to learn.
Betamax was supposed to be better technically (and it was in some ways),
but it cost much more.
In part, the higher cost was due to the lack of competing suppliers; the
competing VHS market was full of competing suppliers who quickly marched
past the proprietary format.
Sony has even lost big money on other proprietary formats, too.
Blu-Ray has all the same earmarks of a failure, in exactly the same way.
The Playstation 3 will have a hopelessly high price tag because of
Blu-ray, and it looks like the Playstation 3 will go down with it.
Since both Blu-Ray and its competitor HD-DVD
have really more egregious digital restrictions management (DRM) mechanisms
built in, I hope both fail - their improvements frankly don&#8217;t
justify abandoning DVDs in my eyes.
</p>
<p>
Ah, but the higher price tag implies better performance, right?  Wrong.
<a href="http://www.theinquirer.net/?article=32171">The Inquirer reports
that there are some serious technical flaws in the Playstation 3</a>,
The Playstation 3 will have half the triangle setup capability compared
to Xbox 360.
What&#8217;s worse, its local cell memory read speed is about 1/1000th of
the speed it <i>should</i> be getting.
In fact, one slide describing the Playstation 3 performance had to say
&#8220;no that isn&#8217;t a typo&#8221;, because the performance figures on this
fundamental subsystem are so horrifically bad.
So people will have the option of spending a lot more money for a
less capable machine that is saddled with
yet another failed proprietary format.
And in addition, Sony is already really late with its next-gen console;
if you&#8217;re not first, you need to be <i>better or cheaper</i>, not
<i>obviously worse and more expensive</i>.
Yes, it&#8217;ll run Linux, but I can run Linux very well
on a general-purpose computer system, for less money and
without the hampering I expect from Sony.
</p>
<p>
Has greed disabled Sony&#8217;s ability to think clearly?
The
<a href="http://www.eff.org/IP/DRM/Sony-BMG/">
Sony-BMG DRM music CD scandal</a>, where Sony subverted a massive number of
computers through a rootkit on its music CDs, just led to a big settlement.
Granted, it could have been worse for Sony; under the laws of most
countries, many Sony executives should probably be in jail.
In the Sony-BMG case,
Sony tried to force a digital restrictions management (DRM)
system on users by breaking into their customers&#8217; operating systems.
The point of DRM systems is to prevent you from using copyrighted products
in ways the company doesn&#8217;t approve of &#8212; even if they are legal (!).
Hrmpf.
The
<a href="http://www.apig.org.uk/index/APIG_DRM_Report-final.pdf">
All Party Parliamentary Internet Group (APIG) in the UK</a>
recommended the publication of
&#8220;guidance to make it clear that companies
distributing Technical Protection Measures systems in the UK would, if they
have features such as those in Sony-BMGâ€™s MediaMax and XCP systems, run a
significant risk of being prosecuted for criminal actions.&#8221;
It&#8217;s fine to want money, but it&#8217;s wise to make money by making
a good product &#8212; one that is cheaper or better in some way.
&#8220;Get rich quick&#8221; schemes, like rootkitting your customers to keep them
from doing stuff you don&#8217;t like, or
trying to establish proprietary format locks so everyone has
to go to you, often backfire.
</p>
<p>
What&#8217;s weird is that this was all unnecessary; it would have
been relatively easy for Sony
to create a platform with modern electronics that had much better performance,
worth paying for, without all this.
It would have been much less risk to Sony if they&#8217;d taken a simpler
route.
What&#8217;s more, their market share is so large that it was theirs to keep;
they just had to be smart about making a good follow-on product.
</p>
<p>
Maybe Sony will pull things through in spite of its problems.
I hope they don&#8217;t just collapse, because competition is a critical force in
keeping innovation going and prices low.
Their product&#8217;s
ability to play Playstation 2 games, for example, is an advantage&#8230;
but I doubt that will be enough, because the old games won&#8217;t
exploit any of the advantages of a next-generation platform.
If Sony can get a massive number of amazingly-good platform-unique
games &#8212; ones so good that people will choose the Playstation 3 specifically
for them &#8212; then <i>maybe</i> they can survive.
But I doubt they can get that strong a corner on good games;
many independents will not want to risk their companies
by making single-platform games, especially one as risky as this one,
and Sony is unlikely to have the finances to buy them all up or
back them enough to eliminate the risks.
What is more likely to happen is that there will be a few platform-unique
games for Playstation 3, a few platform-unique games for its competitors
(particularly XBox 360), and a
few multiple-platform games&#8230; which means no lock for Sony.
In short, things do not look very good right now for Sony;
Sony seems to have
<a href="http://en.wiktionary.org/wiki/hoist_by_one%27s_own_petard">
hoisted themselves on their own petard</a>.
I don&#8217;t even see what they can do now to recover.
</p>
<p>
I think Jonathan V. Last of the Philadelphia Inquirer has it right:
&#8220;Obsessed with owning proprietary formats, Sony keeps picking fights.
[And] It keeps losing. And yet it keeps coming back for more, convinced that
all it needs to do is push a bigger stack of chips to the center of the
table. If Blu-ray fails, it will be the biggest home-electronics failure
since Betamax. If it drags PlayStation 3 down with it, it will be one
of the biggest corporate blunders of our time.&#8221;
</p>
<p>path: <a href="http://www.dwheeler.com/blog/misc">/misc</a> | <a href="http://www.dwheeler.com/blog">Current Weblog</a> | <a href="http://www.dwheeler.com/blog/2006/06/05#playstation3">permanent link to this entry</a></p>
<h1>Sun, 04 Jun 2006</h1>
<p><a name="presentations"><font size="+2"><b>My upcoming presentations - Date change and a new page</b></font></a></p><p></p>
<p>
I&#8217;m still giving a presentation at NovaLUG, but the
date has been changed from July 1 to July 8 (2006).
This is because July 4 is a U.S. holiday (independence day),
and there was concern that some people might not be able to come.
So it will now be July 8, 10am,
&#8220;Free-Libre/Open Source Software (FLOSS) and Security&#8221;.
Washington Technology Park/CSC (formerly Dyncorp),
15000 Conference Center Drive, Chantilly, VA.
</p>
<p>
This has convinced me that I need a page to help people
find when and where I&#8217;m speaking, so that they don&#8217;t have to
march through my blogs to get the information.
So here it is&#8230;
</p>
<p>
<a href="http://www.dwheeler.com/presentations.html">
Presentations by David A. Wheeler.</a>
Just click on it, and you&#8217;ll get the latest times, places, etc., of
where to go if you just can&#8217;t find something better
to do with your life :-).
</p>
<p>path: <a href="http://www.dwheeler.com/blog/website">/website</a> | <a href="http://www.dwheeler.com/blog">Current Weblog</a> | <a href="http://www.dwheeler.com/blog/2006/06/04#presentations">permanent link to this entry</a></p>
<h1>Fri, 02 Jun 2006</h1>
<p><a name="firefox-autonumbering"><font size="+2"><b>Autonumbering supported in Firefox 1.5!</b></font></a></p><p></p>
<p>
Here&#8217;s another reason to use Firefox as your web browser, besides the fact that
<a href="http://www.dwheeler.com/blog/2005/08/06/#ie-horrific">Firefox has
a better security record</a> and that Firefox has
<a href="http://news.com.com/Microsoft+yielding+to+IE+standards+pressure/2100-1032_3-5620988.html">better
support for web standards in general.</a>
Firefox 1.5 has added autonumbering support, and sites like mine are
starting to use it.
If you&#8217;re using a non-compliant web browser,
like the current version of Internet Explorer,
you&#8217;re missing out.
But let&#8217;s back up a bit to the basics: HTML.
</p>
<p>
<a href="http://www.w3.org/MarkUp/">HTML</a> has been a
spectacularly successful standard for sharing
information - web pages around the world use it.
I write a lot of my papers directly in HTML, because it&#8217;s easy,
using HTML makes them easily accessible to everyone, and it&#8217;s a
<a href="http://www.dwheeler.com/essays/opendocument-open.html">
completely open standard</a>.
</p>
<p>
But HTML has several weaknesses if you&#8217;re writing long or
technical reports.
One especially important one is automatic numbering of headers:
the original HTML specification can&#8217;t do it.
When you&#8217;re reading a long report, it can be hard to keep track of
where you are, so having every heading numbered (such as
&#8220;section 2.4.3&#8221;) is <i>really</i> helpful.
This can be solved by having programs directly insert the heading numbers
numbers into the HTML text, but that&#8217;s a messy and kludgy solution.
It&#8217;d be much
better if browsers automatically added numbered headings where appropriate,
so that the HTML file itself is simple and clean.
</p>
<p>
The W3C (the standards group in charge of HTML and related
standards) agreed that automatic numbering was important,
and included support for automatic numbering in the
<a href="http://www.w3.org/Style/CSS/">
Cascading Style Sheets (CSS) standard</a> way back in 1998.
CSS is an important support standard for HTML, so that should have been it&#8230;
but it wasn&#8217;t.
Both Netscape and Microsoft decided to not fully implement the standard,
nor try to fix the standard so that they <i>would</i> implement it.
Soon afterwards Microsoft gained dominant market share, and then
let their browser stagnate (why bother improving it, since there was
no competition?).
It looked like we, the users, would never get basic
capabilities in HTML like auto-numbering.
</p>
<p>
I&#8217;m happy to report that
<a href="http://www.spreadfirefox.com/?q=affiliates&amp;id=31988&amp;t=60">
Firefox 1.5 has added support for auto-numbering</a> headings and
other constructs too.
So I&#8217;ve modified my
<a href="http://www.dwheeler.com/essays/paper.css">CSS file for
papers and essays</a> so it auto-number headings;
I&#8217;ve released my CSS file under the MIT/X license, so anyone else can use it.
If you develop web content you may want to look
at examples like mine for a reason, because&#8230;
</p>
<p>
It turns out that the story is more complicated.
In the process of implementing auto-numbering,
the Firefox developers found a serious problem with the CSS specification.
Oops!
The <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=3247">
Mozilla Firefox bug #3247</a> and
<a href="http://www.davidflanagan.com/blog/2005_08.html#000075">
David Flanagan&#8217;s blog</a> discuss this further.
The Firefox developers talked with the W3C, and the W3C ended up creating
&#8220;CSS 2.1&#8221;, an updated/patched version of the CSS2 standard
that is in the process of being formally released.
</p>
<p>
What this means is that the examples for autonumbering
in the &#8220;official&#8221; original CSS2 standard won&#8217;t actually work!
Instead, you need to follow a slightly different approach as defined
in the patched CSS2.1 specification.
<blockquote>
<b>Technical stuff:</b>
The basic problem involves scoping issues.
To solve it, the counter-reset property <i>must</i> be in the
main heading names (like h1, h2, etc.), and <i>not</i> in the
&#8220;before&#8221; sections (like h1:before, h2:before, etc.) - in spite of
all the examples in the original CSS2 spec.
You can put counter-increment in either place, though the spec
puts them in the :before sections so I have too.
<!-- Here's the W3C example.  I don't think it matters; I think
     what matters is the location of the counter-reset.
H1:before {
    content: "Chapter " counter(chapter) ". ";
    counter-increment: chapter;  /* Add 1 to chapter */
}
H1 {
    counter-reset: section;      /* Set section to 0 */
}
The latest examples in CSS2.1 working draft of 11 April 2006
move the counter-reset property to main heading names, but keep the
counter-increment property in the ":before" sections.
-->
</blockquote>
</p>
<p>
Now people have yet another reason to upgrade to Firefox.
Firefox has had better standards support for some time;
there are now many sites that won&#8217;t display properly
(or as well) if your browser doesn&#8217;t support the standards well.
But here is a clear and functionally important difference.
</p>
<p>
I&#8217;m a big believer in standards, but they can only help users if
they are implemented, and they will only be implemented if
users demand standards compliance.
I think that the more people switch to standards-compliant browsers,
and the more that sites use standards (to encourage people to switch),
the more pressure it will bring on the other browser makers to catch up.
And that would be great for all computer users.
</p>
<p>
More broadly, this is also a good example of why it&#8217;s important to have
implementations try out standards before they are frozen;
they help avoid mistakes like this.
Today,
<a href="http://www.dwheeler.com/essays/open-standards-open-source.html">
essentially every successful open standard is implemented by
free-libre/open source software (FLOSS)</a> - this makes sure that the
standard is implementable, helps all understand what the standard
means, and also helps other developers understand at least one way
to implement it.
This doesn&#8217;t mean standards aren&#8217;t important; standards are vital!
And this also shows that when a mistake is made by a standards body,
life is not over;
standards bodies can work with implementors to fix problems.
In fact, this
shows that the best standards are those created from an
interplay between standards developers and implementors, where
standards are then made official after actual implementation experience.
</p>
<p>path: <a href="http://www.dwheeler.com/blog/oss">/oss</a> | <a href="http://www.dwheeler.com/blog">Current Weblog</a> | <a href="http://www.dwheeler.com/blog/2006/06/02#firefox-autonumbering">permanent link to this entry</a></p>
</body></html>