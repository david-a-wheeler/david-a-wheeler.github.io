<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta>
<link rel="alternate" type="application/rss+xml" title="RSS" href="http://www.dwheeler.com/blog/index.rss"></link>
<title>David A. Wheeler's Blog   </title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>
<h1 style="margin-left: auto; margin-right: auto; width: 50%;">David A. Wheeler's Blog</h1><p>  </p><p></p><h1>Mon, 19 May 2008</h1>
<p><a name="excel-oxml-yearfrac"><font size="+2"><b>YEARFRAC Incompatibilities between Excel 2007 and OOXML (OXML)</b></font></a></p><p></p>
<p>
In theory, the OOXML (OXML) specification is supposed to define
what Excel 2007 reads and writes.
In practice, it&#8217;s not true at all;
the latest public drafts of OOXML are
unable to represent many actual Excel 2007 files.
</p>
<p>
For example,
at least 26 Excel financial functions depend on a parameter called &#8220;Basis&#8221;,
which controls how the calendar is interpreted.
The YEARFRAC function is a good example of this; it returns the
fraction of years between two dates, given a &#8220;basis&#8221; for interpreting
the calendar.
Errors in these functions can have large financial stakes.
</p>
<p>
I&#8217;ve posted a new document,
<a href="http://www.dwheeler.com/yearfrac/excel-ooxml-yearfrac.pdf">YEARFRAC Incompatibilities between Excel 2007 and OOXML (OXML), and the Definitions Actually Used by Excel 2007</a>
(<a href="http://www.dwheeler.com/yearfrac/excel-ooxml-yearfrac.odt">[OpenDocument version]</a>), which shows that
the definitions of OOXML and Excel 2007 aren&#8217;t the same at all.
&#8220;This document identifies incompatibilities between the YEARFRAC function, as implemented by Microsoft Excel 2007, compared to how it is defined in the Office Open Extensible Mark-up Language (OOXML), final draft ISO/IEC 29500-1:2008(E) as of 2008-05-01 (aka OXML).  It also identifies the apparent definitions used by Excel 2007 for YEARFRAC, which to the author’s knowledge have never been fully documented anywhere.  They are not defined in the OOXML specification, because OOXML’s definitions are incompatible with the apparent definition used by Excel 2007.&#8221;
</p>
<p>
&#8220;This incompatibility means that, given OOXML’s current definition,  OOXML cannot represent any Excel spreadsheet that uses financial functions using “basis” date calculations, such as YEARFRAC, if they use common “basis” values (omitted, 0, 1, or 4).   Excel functions that depend upon &#8220;basis&#8221; date calculations include:  ACCRINT, ACCRINTM, AMORDEGRC, AMORLINC, COUPDAYBS, COUPDAYS, COUPDAYSNC, COUPNCD, COUPNUM, COUPPCD, DISC, DURATION, INTRATE, MDURATION, ODDFPRICE, ODDFYIELD, ODDLPRICE, ODDLYIELD, PRICE, PRICEDISC, PRICEMAT, RECEIVED, YEARFRAC, YIELD, YIELDDISC, and YIELDMAT (26 functions).&#8221;
</p>
<p>
<a href="http://www.dwheeler.com/yearfrac">I have much more information
about YEARFRAC if you want it.</a>
</p>
<p>path: <a href="http://www.dwheeler.com/blog/misc">/misc</a> | <a href="http://www.dwheeler.com/blog">Current Weblog</a> | <a href="http://www.dwheeler.com/blog/2008/05/19#excel-oxml-yearfrac">permanent link to this entry</a></p>
<h1>Thu, 15 May 2008</h1>
<p><a name="oracle-letter"><font size="+2"><b>Oracle letter to Universities: Educate software developers on security/assurance!</b></font></a></p><p></p>
<p>
I am <i>delighted</i> to point out a
<a href="http://www.oracle.com/security/docs/mary-ann-letter.pdf">
really interesting letter to Universities by
Mary Ann Davidson, the Chief Security Officer of Oracle Corporation</a>.
It basically tells colleges and universities to stop ignoring security, and
to instead include software security principles
in their computer science curricula.
I&#8217;m so delighted to see this letter, which has just been released to
the public (it had been privately sent to many colleges and universities).
Let me point out and comment on some great points in this letter, because
I think this letter is really important.
</p>
<p>
In this letter, she notes that
&#8220;many security vulnerabilities can be traced to a relatively few types
of common coding errors&#8221;.
<a href="http://www.dwheeler.com/secure-programs">
I&#8217;ve noted that myself, by the way</a>; simply educating developers on
what the common (past) mistakes are goes a <i>long</i> way towards
eliminating vulnerabilities.
She then notes,
&#8220;most developers we hire have not been
adequately trained in basic secure coding principles
in their undergraduate or graduate computer science programs.&#8221;
I agree and think it&#8217;s horrific; more on that in a moment.
She clarifies that this is a really important problem:
&#8220;Security flaws are widely recognized as a threat to national security
and to the privacy and financial well being of individual citizens,
in addition to the costs they impose on us and our customers.&#8221;
They haven&#8217;t just let this be; as they note,
&#8220;We have therefore had to develop and roll out our own in-house security
training program at significant time and expense.&#8221;
Kudos to Oracle for doing such training, by the way; far too many
organizations don&#8217;t do that, which explains why software continues
to have the same old vulnerabilities as it did 30 years ago.
But clearly Oracle cannot train the world, nor it is reasonable to expect
that they do so.
</p>
<p>
She also states that
&#8220;We believe that the ability to recognize and avoid common errors that can
result in catastrophic security failures should be a core part of computer
science curricula and that the above measures will foster such change.
We strongly recommend that universities adopt secure coding practices as
part of their computer science curricula, to improve the security of all
commercial software, and ensure that their graduates remain competitive
in the job market.&#8221;
To that I say, Amen.
</p>
<p>
By itself, that&#8217;s <i>great</i>, but here&#8217;s the kicker:
&#8220;In the future, Oracle plans to give <i><b>hiring preference</b></i>
to students who have received such training and can demonstrate competence
in software security principles.&#8221;
Do you see this?
Students at colleges and universities that fail
to properly prepare them will be at a competitive disadvantage!
</p>
<p>
Today, almost all computer science and software engineering
graduates will develop software that
connects to a network, or must take data from a network&#8230;
yet almost all are absolutely clueless about how to do so.
Not because they don&#8217;t know what a &#8220;socket&#8221; is, but because they don&#8217;t
know how to counter attacks.
And if you&#8217;re hooked to a network, or take data from one, you
<i>will</i> get attacked.
</p>
<p>
Yet the education community (with a few wonderful exceptions) still
completely ignores the need to educate software developers on how to develop
secure software.
&#8220;It&#8217;s not my job&#8221; is not just wrong; it&#8217;s almost criminal.
Society is <i>depending</i> on the educational community to educate students
in the fundamentals of what they need to know.
Society depends on software, and
essentially <i>every</i> student in a software-related field
will, after they graduate, write software that will be attacked.
Attacks are no longer a surprise - they are a guarantee.
Yet the educational system that&#8217;s supposed to prepare our developers
fundamentally fails to do so.
Since attacks are guaranteed, and the
students are guaranteed to <i>not</i>
know how to counter them, what other results would you expect?
The basics of developing secure software should be a <b>mandatory</b>
part of computer science and software engineering undergraduate curricula.
The vulnerabilities that the students <i>will</i> embed in software,
if they do not get this education, will
lead to great loss of life and the loss of billions of dollars.
Sure, schools already have a lot of material to cover,
but practically nothing in a computer science curricula is
as important as how to develop secure software;
I can think of no other omissions in the CS curricula that
cause so much damage.
Don&#8217;t tell me that you only teach the &#8220;fundamentals&#8221;; programming languages
change, but the need for security will <i>never</i> go away; it
<i>is</i> fundamental.
I think
computer science and software engineering departments that do not explain
the basics of developing secure software
to all of their undergraduate and graduate students should be
shut down, as a menace to society, until they change their ways.
</p>
<p>
Oh, if you want to see more about this letter,
<a href="http://blogs.oracle.com/maryanndavidson/2008/04/08#a286">
see Mary Ann Davidson&#8217;s blog article about it,
&#8220;The Supply Chain Problem&#8221;</a>, where
she talks about what led up to the letter, and the
follow-on from it:
&#8220;Last year, I got fed up enough with Oracle having to train otherwise bright
and capable CS grads in secure coding 101 that I sent letters to the top 10 or
so universities we recruit from (my boss came up with the idea and someone on
my team executed on it - teamwork is a wonderful thing)&#8230;
I am sorry to state that only one of those universities we wrote to responded
to my letter&#8230;
We need a revolution - an upending of the way we think about security -and
that means upsetting the supply chain of software developers&#8230;
To universities, I cannot but contrast the education of engineers with that of
computer science majors. Engineers know that their work product must above all
be safe, secure and reliable. They are trained to think this way (not pawn off
&#8216;safety&#8217; on &#8216;testers&#8217;) and their curricula builds and reinforces the
techniques and mindset of safe, secure and reliable product. (A civil engineer
who ignores the principles of basic structures - a core course - in an upper
level class is not going to graduate, and can&#8217;t dismiss structures as a
&#8216;legacy problem.&#8217;)&#8221;
</p>
<p>
I would <i>love</i> to see many organizations banding together to sign
a letter like this one.
If enough organizations band together, I think many universities and
colleges will finally get the message.
I would expand it beyond computer science, to any curricula with a significant
amount of software development (such as software engineering, MIS, and so on),
but that&#8217;s a quibble.
My goal is not to shut down any departments (I hope that&#8217;s clear);
it&#8217;s to repair a serious omission in our educational system.
Kudos to Mary Ann Davidson, for writing the letter and sending it to
a number of Universities.
When I learned of it, I begged her to please post it publicly.
To her <i>great</i> credit, she&#8217;s now done so.
Thanks, from the bottom of my heart!
Now colleges and universities have even fewer reasons to claim the nonsense,
&#8220;well, no one wants information on developing secure software.&#8221;
The companies that will hire your students know otherwise.
</p>
<p>path: <a href="http://www.dwheeler.com/blog/security">/security</a> | <a href="http://www.dwheeler.com/blog">Current Weblog</a> | <a href="http://www.dwheeler.com/blog/2008/05/15#oracle-letter">permanent link to this entry</a></p>
<h1>Wed, 14 May 2008</h1>
<p><a name="open-standards-digistan"><font size="+2"><b>Defining &#8220;open standards&#8221;: The Digital Standards Organization (digistan.org)</b></font></a></p><p></p>
<p>
Lots of people agree that we need &#8220;open standards&#8221; in information
technology.
The problem is, there are a lot of snake-oil salesmen
who are trying to (re)define that term
to mean &#8220;whatever proprietary product I&#8217;m selling&#8221;.
</p>
<p>
Will we be able to choose what products we use?
Will we even be able to exercise our rights (as citizens) at all?
These are important questions about our future.
The answers to those questions
depends on whether or not we have <i>real</i> open standards in place
for critical areas of our lives.
A vendor who controls critical standards could easily decide that something
that is manifestly <i>not</i> in our interest could be in theirs, and
force us to submit to their malevolent actions.
This is already a concern, and through globalization it will only get worse.
We are dependent on information systems, and those who
control their standards control those systems&#8230; and thus, us.
It&#8217;s about power; should we have any?
This means that
understanding what <i>real</i> open standards are about is vital.
</p>
<p>
In my essay
<a href="http://www.dwheeler.com/essays/opendocument-open.html">
&#8220;Is OpenDocument an Open Standard? Yes!&#8221;</a>,
I addressed this problem of multiple different definitions
by finding three widely-used definitions
(Perens&#8217;, Krechmer&#8217;s, and the European Commission&#8217;s) and merging them.
After all, if a specification meets all three definitions of
&#8220;open standard&#8221;, then it&#8217;s far more likely to be a true open standard.
Problem is, with all those trees, it&#8217;s hard to see the forest.
</p>
<p>
So I&#8217;m delighted to have discovered the
<a href="http://www.digistan.org/">Digital Standards Organization
(digistan.org)</a>.
They have a wonderfully brief definition of &#8220;open standard&#8221;:
&#8220;a published specification that is immune to vendor capture at all
stages in its life-cycle&#8221;.
That can be a little mystifying, so they also provide a
<a href="http://www.digistan.org/open-standard">
slightly longer definition of &#8220;open standard&#8221; that clarifies what
that means</a>:
<ul>
<li>&#8220;The standard is adopted and will be maintained by a not-for-profit organization, and its ongoing development occurs on the basis of an open decision-making procedure available to all interested parties.</li>
<li>The standard has been published and the standard specification document is available freely. It must be permissible to all to copy, distribute, and use it freely.</li>
<li>The patents possibly present on (parts of) the standard are made irrevocably available on a royalty-free basis.</li>
<li>There are no constraints on the re-use of the standard.</li>
</ul>
A key defining property is that an open standard is immune to vendor capture at all stages in its life-cycle. Immunity from vendor capture makes it possible to improve upon, trust, and extend an open standard over time.&#8221;
</p>
<p>
That&#8217;s a remarkably clear and simple definition, and good definitions are hard!
Even better, they have posted a
<a href="http://www.digistan.org/rationale">rationale for this definition</a>
that cuts through all the noise and nonsense, and instead gets to the heart
of the matter.
For example, it explains the real goals of open standards:
&#8220;An open standard must be aimed at creating unrestricted competition between
vendors and unrestricted choice for users. Any barrier - including RAND,
FRAND, and variants - to vendor competition or user choice is incompatible
with the needs of the market at large.&#8221;
Here&#8217;s a quote from the rationale&#8217;s
abstract, which I think makes a lot of sense:
<blockquote><i>
&#8220;Many groups and individuals have provided definitions for &#8216;open standard&#8217; that reflect their economic interests in the standards process. We see that the fundamental conflict is between vendors who seek to capture markets and raise costs, and the market at large, which seeks freedom and lower costs.
There are thus only two types of standard: franchise standards, and open standards. Vendors work hard to turn open standards into franchise standards. They work to change the statutory language so they can cloak franchise standards in the sheep&#8217;s clothing of &#8216;open standard&#8217;.
Our canonical definition of open standard derives from the conclusion that this conflict lies at the heart of the matter. We define an open standard as &#8216;a published specification that is immune to vendor capture at all stages in its life-cycle&#8217;.
A full definition of &#8216;open standard&#8217; must take into account the direct economic conflict between vendors and the market at large. Such conflicts do not end when a standard is published, so an open standard must also be immune from attack long after it has been widely implemented.&#8221;
</i></blockquote>
</p>
<p>
Digistan is currently asking people to sign
<a href="http://www.digistan.org/hague-declaration">
&#8220;The Hague Declaration&#8221;</a> by 2008-05-21.
This one states why open standards are important to human liberty,
in ways that non-technical people can understand.
<a href="
http://www.freesoftwaremagazine.com/columns/open_letter_standards_professionals_developers_and_activists">
As Pieter Hintjens argues in his
&#8220;Open letter to Standards Professionals, Developers, and Activists&#8221;</a>,
&#8220;The Hague Declaration argues that international law and national
constitutions of most democracies oblige governments to adopt open standards.&#8221;
If the text of this letter looks a little like
<a href="http://www.gesmer.com/attorneys/updegrove.php">Andrew Updegrove</a>&#8217;s
<a href="http://consortiuminfo.org/bulletins/pdf/feb08/feb08.pdf">
A Proposal to Recognize the Special Status of
&#8220;Civil ICT Standards&#8221;</a> or his
<a href="http://consortiuminfo.org/standardsblog/article.php?story=20080409110045256">testimony in Texas</a>, that&#8217;s no accident;
<a href="http://www.digistan.org/about">
Andrew Updegrove is one of Digistan&#8217;s founders</a>.

</p>
<p>
Standards are vitally important.
If we allow individual companies to control standards, then we have ensured
that they will control us - and what we may do - through them.
Being a non-profit helps, but even a non-profit&#8217;s no guarantee; is the
organization interested in maximizing implementation and
competition between potential suppliers,
or does it have some other motivation (such as maximizing publication revenue)?
</p>
<p>
I think making standards available at no-charge is no longer a nicety; it
is a necessity for a specification to be a truly open standard.
When there were only a few standards, and all products were developed by
large big-budget corporations, a $100 standard was not a big deal.
But today there are a vast array of standards; simply buying
&#8220;all relevant standards&#8221; is becoming prohibitive even for
large companies with massive budgets.
And those big budgets are increasingly rare; suppliers are often
small organizations or individuals collaborating together, or are
in countries where those kinds of funds are unavailable.
Because the world now includes so many new suppliers, anything that
prevents those suppliers from using standards is simply unacceptable.
Don&#8217;t give me the nonsense that the money is needed to help
develop standards; it&#8217;s not true.
I&#8217;ve helped to develop many standards, and I never received a penny from the
publication royalties.
The IETF, W3C, OASIS, and many other organizations manage to publish their
standards, and have for years.
The world has changed.
In today&#8217;s world, &#8220;publish&#8221; means &#8220;freely available over the Internet without
having to register for it&#8221;; if you can&#8217;t Google it, it doesn&#8217;t exist.
The cost of putting a specification on a public web server is essentially
petty cash, and <i>not</i> doing so means that many (if not most) of
the specification&#8217;s potential users cannot use it.
</p>
<p>
Open standards and
<a href="http://www.dwheeler.com/oss_fs_why.html">free-libre / open source software (FLOSS)</a>
are not the same thing - not at all!
There are some similarities, though.
From a customer&#8217;s point of view, both open standards and FLOSS
are strategies for enabling supplier switching (by preventing lock-in).
In addition, customers often don&#8217;t switch to a FLOSS product,
even it&#8217;s technologically superior or has lower total costs, solely
because the customer is locked into an existing product due to
proprietary standards (in data formats, APIs, and so on).
You can choose to use open standards and not use FLOSS products, but
if you use an open standard, it <i>enables</i> you to select a FLOSS product
(now or later).
</p>
<p>
I believe, very much, in the power of competition to produce
lower-cost, higher-quality, and innovative components.
But competition is easily stymied through lock-in via &#8220;franchise&#8221; standards.
Open standards are necessary to eliminate lock-in and bring to everyone
the advantages of competition:
lower cost, higher quality, and greater innovation.
</p>
<p>path: <a href="http://www.dwheeler.com/blog/oss">/oss</a> | <a href="http://www.dwheeler.com/blog">Current Weblog</a> | <a href="http://www.dwheeler.com/blog/2008/05/14#open-standards-digistan">permanent link to this entry</a></p>
<h1>Fri, 09 May 2008</h1>
<p><a name="bilski-information-is-physical"><font size="+2"><b>Bilski: Information is physical!?</b></font></a></p><p></p>
<p>
The
<a href="http://www.groklaw.net/article.php?story=20080508231813484">
US Court of Appeals for the Federal Circuit in Washington, DC just
heard arguments in the <i>Bilski</i> case</a>,
where the appellant (Bilski) is arguing that a completely mental
process should get a patent.
The fact that this was even entertained demonstrates why
the patent system has truly descended into new levels of madness.
At least the PTO rejected the application; the problem is that the PTO
now allows business method patents and software patents.
Once they allowed them, there&#8217;s no rational way to say
&#8220;stop! That&#8217;s rediculous!&#8221; without being arbitrary.
</p>
<p>
Mr. David Hanson (Webb Law Firm) argued for the appellant (Bilski), and
got peppered with questions.
&#8220;Is a curve ball patentable?&#8221;, for example.
At the end, he finally asked the court to think of
&#8220;information as physical&#8221;; it is therefore tangible and can be transformed.
</p>

<p>
That is complete lunacy, and it clearly demonstrates why
the patent office is in real trouble.
</p>
<p>
Information is <b>not</b> physical, it is fundamentally different,
and that difference has been understood for centuries.
If I give you my car, I no longer have that car.
If I give you some information, I still have the information.
That is a <i>fundamental</i> difference in information, and always
has been.
The fact that Bilski&#8217;s lawyer can&#8217;t understand this difference shows
why our patent office is so messed up.
</p>
<p>
This fundamental difference between information and physical objects
was well-understood by the U.S. founding fathers. Here&#8217;s what Thomas
Jefferson said: &#8220;That ideas should freely spread from one to another over
the globe, for the moral and mutual instruction of man, and improvement
of his condition, seems to have been peculiarly and benevolently designed
by nature, when she made them, like fire, expansible over all space,
without lessening their density at any point, and like the air in which
we breath, move, and have our physical being, incapable of confinement
or exclusive appropriation. Inventions then cannot, in nature, be a
subject of property.&#8221; Thomas Jefferson was a founder, and an inventor.
No, they didn&#8217;t have computers then, but computers merely automate
the processing of information; the <i>essential difference</i> between
information and physical/tangible objects was quite clear then.
</p>
<p>
Our laws need to distinguish between information and physical objects,
because they have fundamentally different characteristics.
</p>
<p>
Basically, by failing to understand the differences, the PTO let in
software patents and business method patents, which have been
grossly harmful to the United States.
</p>
<p>
Even if you thought they were merely &#8220;neutral&#8221;, that&#8217;s not enough.
There&#8217;s a famous English speech about the trade-offs of copyright law,
whose principles also apply here: &#8220;It is good that authors should be
remunerated; and the least exceptionable way of remunerating them is by
a monopoly. Yet monopoly is an evil. For the sake of the good we must
submit to the evil; but the evil ought not to last a day longer than is
necessary for the purpose of securing the good.&#8221; -
<a href="http://www.apig.org.uk/index/APIG_DRM_Report-final.pdf">
Thomas Babbington
Macaulay, speech to the House of Commons, February 5, 1841</a>.
</p>
<p>
I believe that software patents need to be abolished, pronto.
<a href="http://www.dwheeler.com/innovation/innovation.html#patents">
As I&#8217;ve discussed elsewhere, software patents harm software innovation</a>,
not help it.
</p>
<p>
But here in the Bilski case we see
why some some people have managed to sneak software patents into
the patent process.
In short, too many people do not understand the fundamental differences
between information and physical objects.
People whose thinking is <i>that</i> fuzzy are easily duped.
Though clearly many people aren&#8217;t as confused as Bilski&#8217;s lawyer,
I think too many people in the patent process have become so
confused about the difference between physical objects and
information that they don&#8217;t understand why software patents
are a serious problem.
Patents should only apply to processes that directly change physical
objects, and their scope should only cover the specifics of those changes.
I add that latter part because yes, changing the number on a display does
change something physical, but that is irrelevant.
If you have a wholly new process for making displays (say, using a new
chemical compound), that could be patentable, but changing a &#8220;5&#8221; to a &#8220;6&#8221;
should not be patentable because &#8220;changing a 5 to a 6&#8221; is not fundamentally
a change in nature.
Taking something unpatentable and adding the phrase &#8220;doing it with a computer&#8221;
should not change an unpatentable invention
into a patentable one; the Supreme Court
understood that, but the PTO still fails to understand that.
</p>
<p>
I think pharmaceutical companies are afraid of any patent reform laws,
because they&#8217;re afraid that a change in the patent system might hurt them.
But if the patent system isn&#8217;t fixed - by eliminating business method
patents and software patents - the entire patent system might become
too overwhelmed to function, and thus eventually scrapped.
I don&#8217;t know if pharma patents are more help than hinderance; I&#8217;m not
an expert in that area.
But I make my living with software, and
it&#8217;s obvious to me (and most other software practitioners)
that software patents and business patents are becoming
a massive drag on innovation.
If we can&#8217;t fix the patent system, we&#8217;ll have to abolish the
patent system completely.
A lot of lawyers will be unhappy if the patent system is
eliminated, but there are more non-lawyers than lawyers.
If the pharma companies want to have a working patent system,
then they&#8217;ll need to help reign in patents in other areas,
or the whole system may collapse.
</p>
<p>path: <a href="http://www.dwheeler.com/blog/misc">/misc</a> | <a href="http://www.dwheeler.com/blog">Current Weblog</a> | <a href="http://www.dwheeler.com/blog/2008/05/09#bilski-information-is-physical">permanent link to this entry</a></p>
<h1>Thu, 08 May 2008</h1>
<p><a name="ocert.org"><font size="+2"><b>Open Source Computer Emergency Response Team (oCERT)</b></font></a></p><p></p>
<p>
Here&#8217;s something new and interesting: the
<a href="http://ocert.org/">Open Source Computer Emergency Response Team
(oCERT)</a>.
Here&#8217;s how they describe themselves:
&#8220;The oCERT project is a public effort providing security handling
support to Open Source projects affected by
security incidents or vulnerabilities&#8230;&#8221;.
</p>

<p>
They promise to keep things moving.
They do permit embargo periods (where vulnerabilities are not publicly
disclosing, giving time for developers to fix the problem first).
More importantly, though, they have a maximum embargo time of two months;
I think that&#8217;s great, and important, because a lot of suppliers have
abused embargo periods and failed to fix critical vulnerabilities
as long as they&#8217;re embargoed.
These abuses often resulted in customers being exploited through mechanisms
that the supplier knew about, but refused to fix in a timely manner.
</p>

<p>
<a href="http://googleonlinesecurity.blogspot.com/2008/05/contributing-to-open-source-software.html">Google is backing oCERT</a>, which is certainly
encouraging.
Google even mentions my &#8220;three conditions&#8221; for securing software (thanks!):
<ol>
<li>people need to actually review the code</li>
<li>developers/reviewers need to know how to write secure code</li>
<li>once found, security problems need to be fixed quickly, and their fixes distributed quickly</li>
</ol>
Clearly, something like oCERT could help with these.
</p>

<p>
<a href="http://www.computerworld.com/action/article.do?command=viewArticleBasic&articleId=9083458&intsrc=news_ts_head">This ComputerWorld article on
oCERT</a> makes some interesting points.
One minor point: They worry that oCERT is using the term &#8220;CERT&#8221; without
permission, but oCERT reports that they do indeed have that permission.
</p>
<p>path: <a href="http://www.dwheeler.com/blog/oss">/oss</a> | <a href="http://www.dwheeler.com/blog">Current Weblog</a> | <a href="http://www.dwheeler.com/blog/2008/05/08#ocert.org">permanent link to this entry</a></p>
<h1>Tue, 06 May 2008</h1>
<p><a name="securing-oss-2008"><font size="+2"><b>Securing Open Source Software (OSS)</b></font></a></p><p></p>
<p>
I&#8217;ve just posted my
<a href="http://www.dwheeler.com/essays/securing-oss.pdf">
presentation titled &#8220;Securing Open Source Software (OSS or FLOSS)</a>,
which is to be presented at the
<a href="http://www.bowheadevents.com/swaforum2008/index.cfm">
8th Semi-Annual Software Assurance Forum, May 6-8, 2008,
Sheraton Premiere, Tyson&#8217;s Corner in Vienna, Virginia.</a>
In it, I discuss how to improve the security of an OSS component
by modifying its environment, as
well as securing the OSS component itself (by selecting a secure
component, building a secure component from scratch, or
modifying an existing component).
I include a number of examples; they&#8217;re necessarily incomplete, but
I hope it will help people who are developing or deploying systems.
(Here is <a href="http://www.dwheeler.com/essays/securing-oss.odp">
&#8220;Securing Open Source Software (OSS or FLOSS)&#8221; in OpenDocument format</a>.)
Enjoy!
</p>
<p>path: <a href="http://www.dwheeler.com/blog/security">/security</a> | <a href="http://www.dwheeler.com/blog">Current Weblog</a> | <a href="http://www.dwheeler.com/blog/2008/05/06#securing-oss-2008">permanent link to this entry</a></p>
</body></html>