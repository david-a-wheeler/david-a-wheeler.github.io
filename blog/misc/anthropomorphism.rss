<?xml version="1.0"?>
<!-- name="generator" content="blosxom/2.0" -->

<rss version="2.0">
  <channel>
    <title>David A. Wheeler's Blog   </title>
    <link>http://www.dwheeler.com/blog</link>
    <description>David A. Wheeler's weblog.</description>
    <language>en</language>

  <item>
    <title>Don&amp;#8217;t anthropomorphize computers, they hate that</title>
    <link>http://www.dwheeler.com/blog/2013/08/06#anthropomorphism</link>
    <pubDate>Tue, 06 Aug 2013 22:38 GMT</pubDate>
    <!-- date: 2013-08-06 -->
    <description>
&lt;p&gt;
A lot of people who program computers or live in the computing world &amp;dash;
including me &amp;dash;
talk about computer hardware and software as if they are people.
Why is that?
This is not as obvious as you&amp;#8217;d think.
&lt;/p&gt;

&lt;p&gt;
After all, if you read the literature about learning how to program,
you&amp;#8217;d think that programmers
would &lt;i&gt;never&lt;/i&gt; use anthropomorphic language.
&lt;a href=&quot;http://www.codinghorror.com/blog/2006/07/separating-programming-sheep-from-non-programming-goats.html&quot;&gt;
&amp;#8220;Separating Programming Sheep from Non-Programming Goats&amp;#8221;
by Jeff Atwood&lt;/a&gt;
discusses teaching programming and points to the
intriguing paper
&lt;a href=&quot;http://www.eis.mdx.ac.uk/research/PhDArea/saeed/paper1.pdf&quot;&gt;
&amp;#8220;The camel has two humps&amp;#8221; by
Saeed Dehnadi and Richard Bornat&lt;/a&gt;.
This paper reported experimental evidence on why
some people can learn to program, while others struggle.
Basically, to learn to program you must fully understand
that computers mindlessly follow rules, and that
computers just don&amp;#8217;t act like humans.
As their paper said,
&amp;#8220;Programs&amp;#8230; are utterly meaningless.
To write a computer program you have to come to terms with this,
to accept that whatever you might want the program to mean,
the machine will blindly follow its meaningless rules and come to
some meaningless conclusion&amp;#8230;
the consistent group [of people] showed a pre-acceptance of this fact:
they are capable of seeing mathematical calculation problems
in terms of rules, and can follow those rules wheresoever they may lead.
The inconsistent group, on the other hand, looks for meaning
where it is not.
The blank group knows that it is looking at meaninglessness,
and refuses to deal with it.
[The experimental results suggest] that it is extremely difficult
to teach programming to the inconsistent and blank groups.&amp;#8221;
&lt;a href=&quot;http://www.eis.mdx.ac.uk/research/PhDArea/saeed/&quot;&gt;
Later work by Saeed Dehnadi and sometimes others&lt;/a&gt;
expands on this earlier work.
&lt;!-- &quot;Testing Programming Aptitude&quot; --&gt;
The intermediate paper
&amp;#8220;Mental models, Consistency and Programming Aptitude&amp;#8221; (2008)
seemed to have refuted the idea that consistency
(and ignoring meaning) was critical to programming, but the later
&lt;a href=&quot;http://www.eis.mdx.ac.uk/research/PhDArea/saeed/SD_PPIG_2009.pdf&quot;&gt;
&amp;#8220;Meta-analysis of the effect of consistency on success
in early learning of programming&amp;#8221; (2009)&lt;/a&gt;
added additional refinements and then re-confirmed this hypothesis.
The reconfirmation involved a meta-analysis of
six replications of an improved version of Dehnadi&amp;#8217;s
original experiment, and again showed that understanding that computers were
mindlessly consistent was key in successfully learning to program.
&lt;/p&gt;

&lt;p&gt;
So the good programmers know darn well that computers mindlessly
follow rules.
But many use anthropomorphic language anyway.
Huh?
Why is that?
&lt;/p&gt;

&lt;p&gt;
Some do object to anthropomorphism, of course.
&lt;a href=&quot;http://lambda-the-ultimate.org/node/264&quot;&gt;Edjar Dijkstra
certainly railed against anthropomorphizing computers&lt;/a&gt;.
For example,
in &lt;a href=&quot;http://www.cs.utexas.edu/users/EWD/ewd08xx/EWD854.PDF&quot;&gt;EWD854&lt;/a&gt;
(1983) he said,
&amp;#8220;I think anthropomorphism is the worst of all [analogies].
I have now seen programs &amp;#8216;trying to do things&amp;#8217;, &amp;#8216;wanting to do things&amp;#8217;,
&amp;#8216;believing things to be true&amp;#8217;, &amp;#8216;knowing things&amp;#8217; etc.
Don&amp;#8217;t be so naive as to believe that this use of language is harmless.&amp;#8221;
He believed that analogies (like these) led to a host of misunderstandings,
and that those misunderstandings led to repeated
multi-million-dollar failures.
It is certainly true that misunderstandings can lead to catastrophe.
But I think one reason Dijkstra railed particularly against anthropomorphism
was (in part) because it is a widespread practice, even among those
who &lt;i&gt;do&lt;/i&gt; understand things &amp;dash;
and I see no evidence that anthropomorphism is going away.
&lt;/p&gt;

&lt;p&gt;
The
&lt;a href=&quot;http://www.catb.org/jargon/html/anthropomorphization.html&quot;&gt;
Jargon file specifically discusses anthropomorphization&lt;/a&gt;:
&amp;#8220;one rich source of jargon constructions is the hackish tendency
to anthropomorphize hardware and software. English purists and
academic computer scientists frequently look down on others for
anthropomorphizing hardware and software, considering this sort of
behavior to be characteristic of naive misunderstanding.
But most hackers anthropomorphize freely,
frequently describing program behavior in terms of wants and desires.
Thus it is common to hear hardware or software talked about as though
it has homunculi talking to each other inside it, with intentions and
desires&amp;#8230;
As hackers are among the people
who know best how these phenomena work, it seems odd that they would
use language that seems to ascribe consciousness to them. The mind-set
behind this tendency thus demands examination.
The key to understanding this kind of usage is that it isn&amp;#8217;t done in
a naive way; hackers don&amp;#8217;t personalize their stuff in the sense of
feeling empathy with it, nor do they mystically believe that the things
they work on every day are &amp;#8216;alive&amp;#8217;.&amp;#8221;
&lt;/p&gt;

&lt;p&gt;
Okay, so others have noticed this too.
The
&lt;a href=&quot;http://www.catb.org/jargon/html/anthropomorphization.html&quot;&gt;
Jargon file even proposes some possible reasons for anthropomorphizing
computer hardware and software&lt;/a&gt;:
&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;It reflects a &amp;#8220;mechanistic view of human behavior.&amp;#8221;
&amp;#8220;In this view, people are biological
machines - consciousness is an interesting and valuable epiphenomenon,
but mind is implemented in machinery which is not fundamentally different
in information-processing capacity from computers&amp;#8230;
Because hackers accept that a human machine can have intentions, it
is therefore easy for them to ascribe consciousness and intention to
other complex patterned systems such as computers.&amp;#8221;
But while the materialistic view of humans has respectible company,
this &amp;#8220;explanation&amp;#8221; fails to explain
why humans would use anthropomorphic
terms about computer hardware and software,
since they are manifestly not human.
Indeed, as the Jargon file acknowledges,
even hackers who have contrary religious views will use
anthropological terminology.
&lt;/li&gt;
&lt;li&gt;
It reflects
&amp;#8220;a blurring of the boundary between the programmer and
his artifacts - the human qualities belong to the programmer and the
code merely expresses these qualities as his/her proxy. On this view,
a hacker saying a piece of code &amp;#8216;got confused&amp;#8217; is really saying that
he (or she) was confused about exactly what he wanted the computer to do,
the code naturally incorporated this confusion, and the code expressed the
programmer&amp;#8217;s confusion when executed by crashing or otherwise misbehaving.
Note that by displacing from &amp;#8220;I got confused&amp;#8221; to
&amp;#8220;It got confused&amp;#8221;, the programmer is not avoiding responsibility,
but rather getting some analytical distance in order
to be able to consider the bug dispassionately.&amp;#8221;
&lt;/li&gt;
&lt;li&gt;
&amp;#8220;It has also been suggested that anthropomorphizing complex systems is
actually an expression of humility, a way of acknowleging that simple
rules we do understand (or that we invented) can lead to emergent
behavioral complexities that we don&amp;#8217;t completely understand.&amp;#8221;
&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;
The Jargon file claims that
&amp;#8220;All three explanations accurately model hacker psychology, and should
be considered complementary rather than competing.&amp;#8221;
I think the first &amp;#8220;explanation&amp;#8221; is completely unjustified.
The second and third explanations do have some merit.
However, I think there&amp;#8217;s a simpler and more important reason: Language.
&lt;/p&gt;

&lt;p&gt;
When we communicate with a human, we must use some language that will be
more-or-less understood by the other human.
Over the years people have developed a variety of human languages
that do this pretty well (again, more-or-less).
Human languages were not particularly designed to deal with computers,
but languages &lt;i&gt;have&lt;/i&gt; been honed over long periods of time
to discuss human behaviors and their mental states
(thoughts, beliefs, goals, and so on).
The sentence
&amp;#8220;Sally says that Linda likes Tom,
but Tom won&amp;#8217;t talk to Linda&amp;#8221;
would be understood by any normal seven-year-old girl
(well, assuming she speaks English).
&lt;/p&gt;

&lt;p&gt;
I think a primary reason people anthropomorphic terminology
is because it&amp;#8217;s much easier to communicate that way
when discussing computer hardware and software using existing languages.
Compare &amp;#8220;the program got confused&amp;#8221; with
the overly long
&amp;#8220;the program executed a different path than the one expected by the
program&amp;#8217;s programmer&amp;#8221;.
Human languages have been honed to discuss human behaviors and
mental states, so it is much easier to use languages this way.
As long as both the sender and receiver of the message understand the
message, the fact that the terminology is anthropomorphic is
not a problem.
&lt;/p&gt;

&lt;p&gt;
It&amp;#8217;s true that anthropomorphic language can confuse some people.
But the primary reason it confuses some people is that they
still have trouble understanding that computers are mindless &amp;dash;
that computers simply do whatever their instructions tell them.
Perhaps this is an innate weakness in some people,
but I think that addressing this weakness head-on
can help counter it.
This is probably a good reason for ensuring that people learn
a little programming as kids &amp;dash; not because they will
necessarily do it later, but because computers are so central
to the modern world that people should have a basic understanding of them.
&lt;/p&gt;
</description>
   </item>
  </channel>
</rss>