<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta>
<link rel="alternate" type="application/rss+xml" title="RSS" href="http://www.dwheeler.com/blog/index.rss"></link>
<title>David A. Wheeler's Blog   </title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>
<h1 style="margin-left: auto; margin-right: auto; width: 50%;">David A. Wheeler's Blog</h1><p>  </p><p></p><h1>Mon, 12 Dec 2005</h1>
<p><a name="trusting-trust"><font size="+2"><b>Countering Trusting Trust through Diverse Double-Compiling, ACSAC 2005</b></font></a></p><p></p>
<p>
Something new: I have a section about
my work to counter the &#8220;Trusting Trust&#8221; computer security attack.
The &#8220;Trusting Trust&#8221; attack is a very old and
incredibly nasty attack in computer security.
Karger and Schell published information about this attack in 1974,
and Ken Thompson (of Unix fame) made it much more widely known in 1984
in his Turing award speech &#8220;Reflections on Trusting Trust.&#8221;
Ken Thompson even <i>demonstrated</i> it; he gained complete control over
another system, and that system&#8217;s owners never detected the subversion.
Up to now it&#8217;s been presumed that the &#8220;Trusting Trust&#8221; attack
is the essential uncounterable attack.
</p>
<p>
What exactly <i>is</i> the trusting trust attack?
Basically, if an attacker can get a Trojan Horse into the binary
of a compiler, at any time, you&#8217;re essentially doomed.
The subverted compiler can subvert itself, indefinitely into the future,
as well as anything else it compiles.
</p>
<p>
I&#8217;ve worried about this attack for a long time, essentially since Thompson
made his report.
If there&#8217;s a <i>known</i> attack that cannot be effectively countered, even
in theory, should we really be using computers at all?
My hope is that my work in this areas aids the computer security field
writ large.
</p>
<p>
The reason I note this in my blog is that I&#8217;ve finally formally
published my paper that describes a technique for countering this attack.
The paper is
<a href="http://www.acsa-admin.org/2005/abstracts/47.html">
Countering Trusting Trust through Diverse Double-Compiling</a> (DDC),
and it was published by ACSAC 2005.
<a href="http://www.dwheeler.com/trusting-trust">Here&#8217;s a local copy,
along with more info and material.</a>
Here&#8217;s the abstract of that paper:
</p>
<p>
<blockquote>
<i>
An Air Force evaluation of Multics, and Ken Thompson&#8217;s famous Turing
award lecture &#8220;Reflections on Trusting Trust,&#8221; showed that compilers
can be subverted to insert malicious Trojan horses into critical software,
including themselves.  If this attack goes undetected, even complete
analysis of a system&#8217;s source code will not find the malicious code
that is running, and methods for detecting this particular attack
are not widely known.  This paper describes a practical technique,
termed diverse double-compiling (DDC), that detects this attack and
some compiler defects as well.  Simply recompile the source code twice:
once with a second (trusted) compiler, and again using the result of
the first compilation. If the result is bit-for-bit identical with
the untrusted binary, then the source code accurately represents the
binary. This technique has been mentioned informally, but its issues and
ramifications have not been identified or discussed in a peer-reviewed
work, nor has a public demonstration been made. This paper describes the
technique, justifies it, describes how to overcome practical challenges,
and demonstrates it.
</i>
</blockquote>
</p>

<p>
I just got back from the ACSAC 2005 computer security conference.
Several interesting papers there, on a variety of topics.
</p>

<p>
An aside: At ACSAC 2005, Aleks Kissinger (from the University of Tulsa) also
presented work that he and I had done on micro-tainting.
This was the presentation
&#8220;Fine-Grained Taint Analysis using Regular Expressions,&#8221; which was part
of the
<a href="http://www.acsa-admin.org/2005/wip.html">Works in Progress</a>.
Basically, we noted that instead of assigning &#8220;taint&#8221; to a whole value, such as a string, you could
assign taint on subcomponents, such as each character.
Then you could assign rules that identified the input paths and
what could come in &#8212;
typically zero or more tainted characters &#8212; and rules on output paths.
We concentrated on defining regular expressions for what is legal,
though any other expression for patterns such as BNFs would be fine too.
We noted that you could then check statically or dynamically.
For the static case, when you work backwards, if the check &#8220;fails&#8221; you can
even trivially derive the input patterns that cause security failures
(and from that information it should be easy to figure out how to fix it).
Aleks has recently made some good progress by transforming the regular
expressions into DFAs.
There was another ACSAC presentation on doing taint analysis with Java,
but this was the traditional &#8220;whole variable&#8221; approach that is used in
many languages, but through which many vulnerabilities slip by.
We hope this micro-tainting approach will lead to improved tools for detecting
security vulnerabilities in software, <i>before</i> that software is
delivered to end-users.
</p>
<p>path: <a href="http://www.dwheeler.com/blog/security">/security</a> | <a href="http://www.dwheeler.com/blog">Current Weblog</a> | <a href="http://www.dwheeler.com/blog/2005/12/12#trusting-trust">permanent link to this entry</a></p>
</body></html>