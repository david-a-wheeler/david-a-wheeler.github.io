<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
<meta http-equiv="CONTENT-TYPE" content="text/html; charset=us-ascii">
<title>Fully Countering Trusting Trust through Diverse Double-Compiling</title>
<meta name="GENERATOR" content="OpenOffice.org 3.2">
<meta name="AUTHOR" content="David A. Wheeler">
<meta name="CREATED" content="20070402;9480700">
<meta name="CHANGEDBY" content="David A. Wheeler">
<meta name="CHANGED" content="20091207;11433300">
<meta name="CLASSIFICATION" content=
"Computer security, computer science, software engineering, software assurance">
<meta name="DESCRIPTION" content=
"Describes how to counter the &quot;Trusting Trust&quot; attack, as described by Ken Thompson, using a technique called Diverse Double-Compiling (DDC).">
<meta name="KEYWORDS" content=
"trusting trust, diverse double-compiling, DDC, Reflections, Thompson, compilers, compiler, subversion, subverted, security, software assurance, malicious, corrupted, Multics, Karger, Schell, GCC, tcc, diversity, diverse, countermeasure, alternative, counter, Trojan horse">
<meta name="Author" content="David A. Wheeler">
<style type="text/css">
       p { margin-top: 0.17in; margin-bottom: 0in; background: transparent; line-height: 150%; text-align: justify; widows: 2; orphans: 2; page-break-before: auto; page-break-after: auto }
       h1 { margin-top: 2em; margin-bottom: 1em; background: transparent; text-align: center; page-break-before: always; page-break-inside: avoid; page-break-after: avoid; }
       h1.samepage { margin-top: 1em; page-break-before: auto }
       h2 { margin-bottom: 0.08in; page-break-before: auto; page-break-inside: avoid; page-break-after: avoid; }
       h3 { margin-bottom: 0.08in; page-break-before: auto; page-break-inside: avoid; page-break-after: avoid; }
       h4 { margin-top: 0.08in; margin-bottom: 0in; background: transparent; page-break-before: auto; page-break-inside: avoid; page-break-after: avoid; }
       td p { margin-bottom: 0in; page-break-before: auto; line-height: 100%;; text-align: left; }
       th p { margin-bottom: 0in; margin-top: 0in; background: #c0c0c0; page-break-before: auto; line-height: 100% }
       p.sdfootnote { text-indent: 0.2in; margin-top: 0in; background: transparent; line-height: 100%; text-align: left; widows: 0; orphans: 0; page-break-after: auto }
       blockquote { margin-left: 0.5in; margin-right: 0.5in; margin-bottom: 0.17in; page-break-before: auto }
       pre { page-break-before: auto }
       a:link { background: transparent; text-decoration: none }
       a:visited { text-decoration: none }
       a.sdfootnoteanc { font-size: 90% }
</style>
</head>
<body lang="en-US" dir="ltr">
<h1 class="samepage"><a href="#0.Abstract|outline">Fully Countering
Trusting Trust through Diverse Double-Compiling</a></h1>
<center>A dissertation submitted in partial fulfillment of the requirements<br>
for the degree of Doctor of Philosophy at George Mason University<br>
By<br>
<a href="http://www.dwheeler.com/">David A. Wheeler</a><br>
Master of Science<br>
George Mason University, 1994<br>
Bachelor of Science<br>
George Mason University, 1988<br>
Co-Directors: Dr. Daniel A. Menasc&#233; and Dr. Ravi Sandhu,
Professors<br>
The Volgenau School of Information Technology &amp; Engineering<br>
Fall Semester 2009<br>
George Mason University<br>
Fairfax, VA<br>
<br>
Copyright &#169; 2009 <a href="http://www.dwheeler.com/">David A.
Wheeler</a></center>
<p><br></p>
<p>You may use and redistribute this work under the <a href=
"http://creativecommons.org/licenses/by-sa/3.0/us/">Creative
Commons Attribution-Share Alike (CC-BY-SA) 3.0 United States
License</a>. You are free to Share (to copy, distribute, display,
and perform the work) and to Remix (to make derivative works),
under the following conditions:</p>
<ol>
<li>Attribution. You must attribute the work in the manner
specified by the author or licensor (but not in any way that
suggests that they endorse you or your use of the work).</li>
<li>Share Alike. If you alter, transform, or build upon this work,
you may distribute the resulting work only under the same, similar
or a compatible license.</li>
</ol>
<p>Alternatively, permission is also granted to copy, distribute
and/or modify this document under the terms of the <a href=
"http://www.gnu.org/licenses/fdl.html">GNU Free Documentation
License, Version 1.2</a> or any later version published by the
<a href="http://www.fsf.org/">Free Software Foundation</a>.</p>
<p>As a third alternative, permission is also granted to copy,
distribute and/or modify this document under the terms of the GNU
General Public License (GPL) version 2 or any later version
published by the <a href="http://www.fsf.org/">Free Software
Foundation</a>.</p>
<p>All trademarks, service marks, logos, and company names
mentioned in this work are the property of their respective
owners.</p>
<h1>Dedication</h1>
<p>This is dedicated to my wife and children, who sacrificed many
days so I could perform this work, to my extended family, and to
the memory of my former mentors Dennis W. Fife and Donald Macleay,
who always believed in me.</p>
<p>Soli Deo gloria&#8212;Glory to God alone.</p>
<h1>Acknowledgments</h1>
<p>I would like to thank my PhD committee members and former
members Dr. Daniel A. Menasc&#233;, Dr. Ravi Sandhu, Dr. Paul
Ammann, Dr. Jeff Offutt, Dr. Yutao Zhong, and Dr. David Rine, for
their helpful comments.</p>
<p>The Institute for Defense Analyses (IDA) provided a great deal
of help. Dr. Roger Mason and the Honorable Priscilla Guthrie,
former directors of IDA&#8217;s Information Technology and Systems
Division (ITSD), partly supported this work through IDA&#8217;s
Central Research Program. Dr. Margaret E. Myers, current IDA ITSD
director, approved its final release. I am very grateful to my IDA
co-workers (alphabetically by last name) Dr. Brian Cohen, Aaron
Hatcher, Dr. Dale Lichtblau, Dr. Reg Meeson, Dr. Clyde Moseberry,
Dr. Clyde Roby, Dr. Ed Schneider, Dr. Marty Stytz, and Dr. Andy
Trice, who had many helpful comments on this dissertation and/or
the previous ACSAC paper. Reg Meeson in particular spent many hours
carefully reviewing the proofs and related materials, and Clyde
Roby carefully reviewed the whole dissertation; I thank them both.
Aaron Hatcher was immensely helpful in working to scale the Diverse
Double-Compiling (DDC) technique up to a real-world application
using GCC. In particular, Aaron helped implement many applications
of DDC that we thought should have worked with GCC, but
didn&#8217;t, and then helped to determine <i>why</i> they
didn&#8217;t work. These &#8220;Edison successes&#8221; (which
successfully found out what did <i>not</i> work) were important in
helping to lead to a working application of DDC to GCC.</p>
<p>Many others also helped create this work. The work of Dr. Paul
A. Karger, Dr. Roger R. Schell, and Ken Thompson made the world
aware of a problem that needed solving; without knowing there was a
problem, there would have been no work to solve it. Henry Spencer
posted the first version of this idea that eventually led to this
dissertation (though this dissertation expands on it far beyond the
few sentences that he wrote). Henry Spencer, Eric S. Raymond, and
the anonymous ACSAC reviewers provided helpful comments on the
ACSAC paper. I received many helpful comments and other information
after publication of the ACSAC paper, including comments from
(alphabetically by last name) Bill Alexander, Dr. Steven M.
Bellovin, Terry Bollinger, Ulf Dittmer, Jakub Jelinek, Dr. Paul A.
Karger, Ben Laurie, Mike Lisanke, Thomas Lord, Bruce Schneier,
Brian Snow, Ken Thompson, Dr. Larry Wagoner, and James Walden.
Tawnia Wheeler proofread both the ACSAC paper and this document;
thank you! My thanks to the many developers of the OpenDocument
specification and the OpenOffice.org implementation, who made
developing this document a joy.</p>
<h1>Table of Contents</h1>
<div id="Table_of_Contents1" dir="ltr" style=
"background: transparent">
<p><a href="#0.List_of_Tables|outline">List of Tables viii</a><br>
<a href="#0.List_of_Figures|outline">List of Figures ix</a><br>
<a href="#0.List%20of%20Abbreviations%20and%20Symbols|outline">List
of Abbreviations and Symbols x</a><br>
<a href="#0.Abstract|outline">Abstract xiv</a><br>
<a href="#1.Introduction|outline">1 Introduction 1</a><br>
<a href="#2.Background%20and%20related%20work|outline">2 Background
and related work 4</a><br>
<a href=
"#2.1.Initial%20revelation:%20Karger,%20Schell,%20and%20Thompson|outline">
2.1 Initial revelation: Karger, Schell, and Thompson 4</a><br>
<a href=
"#2.2.Other%20work%20on%20corrupted%20compilers|outline">2.2 Other
work on corrupted compilers 6</a><br>
<a href="#2.3.Compiler%20bootstrap%20test|outline">2.3 Compiler
bootstrap test 9</a><br>
<a href="#2.4.Analyzing%20software|outline">2.4 Analyzing software
10</a><br>
<a href="#2.4.1.Static%20analysis|outline">2.4.1 Static analysis
11</a><br>
<a href="#2.4.2.Dynamic%20analysis|outline">2.4.2 Dynamic analysis
14</a><br>
<a href="#2.5.Diversity%20for%20security|outline">2.5 Diversity for
security 16</a><br>
<a href=
"#2.6.Subversion%20of%20software%20is%20a%20real%20problem|outline">
2.6 Subversion of software is a real problem 17</a><br>
<a href="#2.7.Previous%20DDC%20paper|outline">2.7 Previous DDC
paper 21</a><br>
<a href="#3.Description%20of%20threat|outline">3 Description of
threat 23</a><br>
<a href="#3.1.Attacker%20motivation|outline">3.1 Attacker
motivation 23</a><br>
<a href=
"#3.2.Triggers,%20payloads,%20and%20non-discovery|outline">3.2
Triggers, payloads, and non-discovery 27</a><br>
<a href=
"#4.Informal%20description%20of%20Diverse%20Double-Compiling%20(DDC)|outline">
4 Informal description of Diverse Double-Compiling (DDC) 30</a><br>
<a href="#4.1.Terminology%20and%20notation|outline">4.1 Terminology
and notation 30</a><br>
<a href="#4.2.Informal%20description%20of%20DDC|outline">4.2
Informal description of DDC 32</a><br>
<a href="#4.3.Informal%20assumptions|outline">4.3 Informal
assumptions 35</a><br>
<a href=
"#4.4.DDC%20does%20not%20require%20that%20different%20compilers%20produce%20identical%20executables|outline">
4.4 DDC does not require that different compilers produce identical
executables 37</a><br>
<a href=
"#4.5.Special%20case:%20Self-parenting%20compiler|outline">4.5
Special case: Self-parenting compiler 38</a><br>
<a href=
"#4.6.Why%20not%20always%20use%20the%20trusted%20compiler_|outline">
4.6 Why not always use the trusted compiler? 40</a><br>
<a href=
"#4.7.Why%20is%20DDC%20different%20from%20N-version%20programming_|outline">
4.7 Why is DDC different from N-version programming? 41</a><br>
<a href=
"#4.8.DDC%20works%20with%20randomly-corrupting%20compilers|outline">
4.8 DDC works with randomly-corrupting compilers 43</a><br>
<a href="#5.Formal%20proof|outline">5 Formal proof 44</a><br>
<a href=
"#5.1.Graphical%20model%20for%20formal%20proof%20|outline">5.1
Graphical model for formal proof 45</a><br>
<a href="#5.1.1.Types|outline">5.1.1 Types 46</a><br>
<a href="#5.1.2.DDC%20components|outline">5.1.2 DDC components
47</a><br>
<a href="#5.1.3.Claimed%20origin|outline">5.1.3 Claimed origin
48</a><br>
<a href=
"#5.2.Formal%20notation:%20First-Order%20Logic%20(FOL)|outline">5.2
Formal notation: First-Order Logic (FOL) 49</a><br>
<a href=
"#5.3.Proof%20step%20rationales%20(derivation%20rules%20or%20rules%20of%20inference)|outline">
5.3 Proof step rationales (derivation rules or rules of inference)
51</a><br>
<a href=
"#5.4.Tools%20and%20rationale%20for%20confidence%20in%20the%20proofs|outline">
5.4 Tools and rationale for confidence in the proofs 54</a><br>
<a href="#5.4.1.Early%20DDC%20proof%20efforts|outline">5.4.1 Early
DDC proof efforts 54</a><br>
<a href="#5.4.2.Prover9,%20mace4,%20and%20ivy|outline">5.4.2
Prover9, mace4, and ivy 54</a><br>
<a href="#5.4.3.Tool%20limitations|outline">5.4.3 Tool limitations
56</a><br>
<a href=
"#5.4.4.Proofs%E2%80%99%20conclusions%20follow%20from%20their%20assumptions|outline">
5.4.4 Proofs&#8217; conclusions follow from their assumptions
57</a><br>
<a href=
"#5.4.5.Proofs%E2%80%99%20assumptions%20and%20goals%20adequately%20model%20the%20world|outline">
5.4.5 Proofs&#8217; assumptions and goals adequately model the
world 57</a><br>
<a href="#5.5.Proof%20conventions|outline">5.5 Proof conventions
59</a><br>
<a href=
"#5.6.Proof%20#1:%20Goal%20source_corresponds_to_executable|outline">
5.6 Proof #1: Goal source_corresponds_to_executable 60</a><br>
<a href=
"#5.6.1.Predicate%20%E2%80%9C=%E2%80%9D%20given%20two%20executables|outline">
5.6.1 Predicate &#8220;=&#8221; given two executables 60</a><br>
<a href="#5.6.2.Predicate%20exactly_correspond|outline">5.6.2
Predicate exactly_correspond 62</a><br>
<a href="#5.6.3.Predicate%20accurately_translates|outline">5.6.3
Predicate accurately_translates 63</a><br>
<a href="#5.6.4.Assumption%20cT_compiles_sP|outline">5.6.4
Assumption cT_compiles_sP 63</a><br>
<a href=
"#5.6.4.1.Implications%20for%20the%20language|outline">5.6.4.1
Implications for the language 64</a><br>
<a href=
"#5.6.4.2.Implications%20for%20the%20trusted%20compiler%20and%20its%20environment|outline">
5.6.4.2 Implications for the trusted compiler and its environment
66</a><br>
<a href="#5.6.5.Function%20compile|outline">5.6.5 Function compile
69</a><br>
<a href="#5.6.6.Assumption%20sP_compiles_sA|outline">5.6.6
Assumption sP_compiles_sA 71</a><br>
<a href="#5.6.7.Definition%20definition_stage1|outline">5.6.7
Definition definition_stage1 72</a><br>
<a href=
"#5.6.8.Definition%20define_exactly_correspond|outline">5.6.8
Definition define_exactly_correspond 72</a><br>
<a href="#5.6.9.Definition%20definition_stage2|outline">5.6.9
Definition definition_stage2 73</a><br>
<a href=
"#5.6.10.Goal%20source_corresponds_to_executable|outline">5.6.10
Goal source_corresponds_to_executable 73</a><br>
<a href=
"#5.6.11.Prover9%20proof%20of%20source_corresponds_to_executable|outline">
5.6.11 Prover9 proof of source_corresponds_to_executable 74</a><br>
<a href="#5.6.12.Discussion%20of%20proof%20#1|outline">5.6.12
Discussion of proof #1 75</a><br>
<a href="#5.7.Proof%20#2:%20Goal%20always_equal|outline">5.7 Proof
#2: Goal always_equal 76</a><br>
<a href=
"#5.7.1.Reused%20definitions%20define_exactly_correspond,%20definition_stage1,%20and%20definition_stage2|outline">
5.7.1 Reused definitions define_exactly_correspond,
definition_stage1, and definition_stage2 77</a><br>
<a href="#5.7.2.Assumption%20cT_compiles_sP|outline">5.7.2
Assumption cT_compiles_sP 78</a><br>
<a href=
"#5.7.3.Predicate%20deterministic_and_portable|outline">5.7.3
Predicate deterministic_and_portable 78</a><br>
<a href="#5.7.4.Function%20run|outline">5.7.4 Function run
79</a><br>
<a href="#5.7.5.Function%20converttext|outline">5.7.5 Function
converttext 80</a><br>
<a href="#5.7.6.Function%20extract|outline">5.7.6 Function extract
81</a><br>
<a href="#5.7.7.Function%20retarget|outline">5.7.7 Function
retarget 81</a><br>
<a href=
"#5.7.8.Assumption%20sP_portable_and_deterministic|outline">5.7.8
Assumption sP_portable_and_deterministic 81</a><br>
<a href=
"#5.7.9.Definition%20define_portable_and_deterministic|outline">5.7.9
Definition define_portable_and_deterministic 83</a><br>
<a href="#5.7.10.Assumption%20cP_corresponds_to_sP|outline">5.7.10
Assumption cP_corresponds_to_sP 84</a><br>
<a href="#5.7.11.Definition%20define_compile|outline">5.7.11
Definition define_compile 85</a><br>
<a href="#5.7.12.Definition%20definition_cA|outline">5.7.12
Definition definition_cA 86</a><br>
<a href="#5.7.13.Goal%20always_equal|outline">5.7.13 Goal
always_equal 86</a><br>
<a href=
"#5.7.14.Prover9%20proof%20of%20always_equal|outline">5.7.14
Prover9 proof of always_equal 86</a><br>
<a href="#5.7.15.Discussion%20of%20proof%20#2|outline">5.7.15
Discussion of proof #2 88</a><br>
<a href=
"#5.8.Proof%20#3:%20Goal%20cP_corresponds_to_sP|outline">5.8 Proof
#3: Goal cP_corresponds_to_sP 89</a><br>
<a href="#5.8.1.Definition%20definition_cP|outline">5.8.1
Definition definition_cP 90</a><br>
<a href="#5.8.2.Assumption%20cGP_compiles_sP|outline">5.8.2
Assumption cGP_compiles_sP 90</a><br>
<a href="#5.8.3.Goal%20cP_corresponds_to_sP|outline">5.8.3 Goal
cP_corresponds_to_sP 90</a><br>
<a href=
"#5.8.4.Prover9%20proof%20of%20cP_corresponds_to_sP|outline">5.8.4
Prover9 proof of cP_corresponds_to_sP 90</a><br>
<a href="#5.8.5.Discussion%20of%20proof%20#3|outline">5.8.5
Discussion of proof #3 91</a><br>
<a href="#6.Methods%20to%20increase%20diversity|outline">6 Methods
to increase diversity 92</a><br>
<a href=
"#6.1.Diversity%20in%20compiler%20implementation|outline">6.1
Diversity in compiler implementation 93</a><br>
<a href="#6.2.Diversity%20in%20time|outline">6.2 Diversity in time
93</a><br>
<a href="#6.3.Diversity%20in%20environment|outline">6.3 Diversity
in environment 95</a><br>
<a href="#6.4.Diversity%20in%20source%20code%20input|outline">6.4
Diversity in source code input 95</a><br>
<a href="#7.Demonstrations%20of%20DDC|outline">7 Demonstrations of
DDC 98</a><br>
<a href="#7.1.tcc|outline">7.1 tcc 98</a><br>
<a href="#7.1.1.Test%20configuration|outline">7.1.1 Test
configuration 99</a><br>
<a href="#7.1.2.Diverse%20double-compiling%20tcc|outline">7.1.2
Diverse double-compiling tcc 100</a><br>
<a href=
"#7.1.3.Defect%20in%20sign-extending%20cast%208-bit%20values|outline">
7.1.3 Defect in sign-extending cast 8-bit values 102</a><br>
<a href="#7.1.4.Long%20double%20constant%20problem|outline">7.1.4
Long double constant problem 105</a><br>
<a href=
"#7.1.5.Final%20results%20with%20tcc%20demonstration|outline">7.1.5
Final results with tcc demonstration 106</a><br>
<a href="#7.2.Goerigk%20Lisp%20compilers|outline">7.2 Goerigk Lisp
compilers 106</a><br>
<a href="#7.3.GCC|outline">7.3 GCC 109</a><br>
<a href="#7.3.1.Setup%20for%20GCC|outline">7.3.1 Setup for GCC
109</a><br>
<a href="#7.3.2.Challenges|outline">7.3.2 Challenges 113</a><br>
<a href="#7.3.2.1.Master%20result%20directory|outline">7.3.2.1
Master result directory 113</a><br>
<a href="#7.3.2.2.Obsolete%20format%20for%20tail|outline">7.3.2.2
Obsolete format for tail 114</a><br>
<a href="#7.3.2.3.Libiberty%20library|outline">7.3.2.3 Libiberty
library 115</a><br>
<a href="#7.3.3.GCC%20Results|outline">7.3.3 GCC Results
117</a><br>
<a href="#8.Practical%20challenges|outline">8 Practical challenges
118</a><br>
<a href="#8.1.Limitations|outline">8.1 Limitations 118</a><br>
<a href="#8.2.Non-determinism|outline">8.2 Non-determinism
119</a><br>
<a href=
"#8.3.Difficulty%20in%20finding%20alternative%20compilers|outline">8.3
Difficulty in finding alternative compilers 120</a><br>
<a href=
"#8.4.Countering%20%E2%80%9Cpop-up%E2%80%9D%20attacks|outline">8.4
Countering &#8220;pop-up&#8221; attacks 121</a><br>
<a href="#8.5.Multiple%20sub-components|outline">8.5 Multiple
sub-components 121</a><br>
<a href="#8.6.Timestamps%20and%20inexact%20comparison|outline">8.6
Timestamps and inexact comparison 122</a><br>
<a href=
"#8.7.Interpreters%20and%20recompilation%20dependency%20loops|outline">
8.7 Interpreters and recompilation dependency loops 124</a><br>
<a href=
"#8.8.Untrusted%20environments%20and%20broadening%20DDC%20application|outline">
8.8 Untrusted environments and broadening DDC application
125</a><br>
<a href="#8.9.Trusted%20build%20agents|outline">8.9 Trusted build
agents 126</a><br>
<a href=
"#8.10.Application%20problems%20with%20current%20distributions|outline">
8.10 Application problems with current distributions 127</a><br>
<a href=
"#8.11.Finding%20errors%20and%20maliciously%20misleading%20code|outline">
8.11 Finding errors and maliciously misleading code 129</a><br>
<a href="#8.12.Hardware|outline">8.12 Hardware 130</a><br>
<a href="#8.13.Complex%20libraries%20and%20frameworks|outline">8.13
Complex libraries and frameworks 135</a><br>
<a href=
"#8.14.How%20can%20an%20attacker%20counter%20DDC_|outline">8.14 How
can an attacker counter DDC? 136</a><br>
<a href="#9.Conclusions%20and%20ramifications|outline">9
Conclusions and ramifications 140</a><br>
<a href="#1.Lisp%20results|outline">Appendix A: Lisp results
144</a><br>
<a href="#1.1.Source%20code%20for%20correct%20compiler|outline">A.1
Source code for correct compiler 144</a><br>
<a href=
"#1.2.Compiled%20code%20for%20correct%20compiler|outline">A.2
Compiled code for correct compiler 145</a><br>
<a href="#1.3.Compilation%20of%20factorial%20function|outline">A.3
Compilation of factorial function 146</a><br>
<a href="#1.4.Compilation%20of%20login%20function|outline">A.4
Compilation of login function 146</a><br>
<a href="#1.5.DDC%20application|outline">A.5 DDC application
147</a><br>
<a href="#2.Detailed%20GCC%20results|outline">Appendix B: Detailed
GCC results 153</a><br>
<a href="#3.Model%20results|outline">Appendix C: Model results
156</a><br>
<a href="#9.1.Proof%20#1%20model|outline">C.1 Proof #1 model
157</a><br>
<a href="#9.2.Proof%20#2%20model|outline">C.2 Proof #2 model
159</a><br>
<a href="#9.3.Proof%20#3%20model|outline">C.3 Proof #3 model
162</a><br>
<a href=
"#4.Guidelines%20for%20Compiler%20Suppliers|outline">Appendix D:
Guidelines for Compiler Suppliers 165</a><br>
<a href="#5.Key%20definitions|outline">Appendix E: Key definitions
170</a><br>
<a href="#9.Bibliography|outline">Bibliography 172</a></p>
</div>
<p><br></p>
<h1><a name="0.List_of_Tables|outline"></a>List of Tables</h1>
<div id="Index_of_Tables1" dir="ltr">
<p><a href="#table1">Table 1: FOL notation 50</a><br>
<a href="#table2">Table 2: Proof #1
(source_corresponds_to_executable) in prover9 format 74</a><br>
<a href="#table3">Table 3: Proof #2 (always_equal) in prover9
format 87</a><br>
<a href="#table4">Table 4: Proof #3 (cP_corresponds_to_sP) in
prover9 format 91</a><br>
<a href="#table5">Table 5: Statistics for GCC C compiler, both
compiler-under-test and DDC result 154</a><br></p>
</div>
<p><br></p>
<h1><a name="0.List_of_Figures|outline"></a> List of Figures</h1>
<div id="Illustration_Index1" dir="ltr">
<p><a href="#figure1">Figure 1: Illustration of graphical notation
31</a><br>
<a href="#figure2">Figure 2: Informal graphical representation of
DDC 33</a><br>
<a href="#figure3">Figure 3: Informal graphical representation of
DDC for self-regeneration case 39</a><br>
<a href="#figure4">Figure 4: Graphical representation of DDC formal
model 45</a><br>
<a href="#figure5">Figure 5: Diverse double-compiling with
self-regeneration check, using tcc 101</a><br>
<a href="#figure6">Figure 6: DDC applied to GCC 113</a><br></p>
</div>
<p><br></p>
<h1><a name="0.List of Abbreviations and Symbols|outline"></a>List
of Abbreviations and Symbols</h1>
<table width="100%" border="0" cellpadding="0" cellspacing="0">
<col width="46*">
<col width="210*">
<tr valign="top">
<td width="18%">
<p>-A</p>
</td>
<td width="82%">
<p>not A. Equivalent to <img src=
"wheeler-trusting-trust-ddc_html_14708c70.gif" alt="&not;A" align="absmiddle" width="29" height="18"></p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>A &amp; B</p>
</td>
<td width="82%">
<p>A and B (logical and). Equivalent to <img src=
"wheeler-trusting-trust-ddc_html_m1fac73e5.gif" alt="A&and;B" align="absmiddle" width="43" height="18"></p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>A | B</p>
</td>
<td width="82%">
<p>A or B (logical or). Equivalent to <img src=
"wheeler-trusting-trust-ddc_html_m2d10c7e2.gif" alt="A&or;B" align="absmiddle" width="43" height="18"></p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>A -&gt; B</p>
</td>
<td width="82%">
<p>A implies B. Equivalent to <img src=
"wheeler-trusting-trust-ddc_html_39c62bfa.gif" alt="A&rArr;B" align="absmiddle" width="47" height="18"> and <img src=
"wheeler-trusting-trust-ddc_html_m6459d4e9.gif" alt="(&not;A)&or;B" align="absmiddle" width="65" height="18"></p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>ACL2</p>
</td>
<td width="82%">
<p>A Computational Logic for Applicative Common Lisp</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>ACSAC</p>
</td>
<td width="82%">
<p>Annual Computer Security Applications Conference</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>aka</p>
</td>
<td width="82%">
<p>also known as</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>all X A</p>
</td>
<td width="82%">
<p>for all X, A. Equivalent to <img src=
"wheeler-trusting-trust-ddc_html_40f67fd6.gif" alt="&forall;X&nbsp;A" align="absmiddle" width="53" height="18"></p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>ANSI</p>
</td>
<td width="82%">
<p>American National Standards Institute</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>API</p>
</td>
<td width="82%">
<p>Application Programmer Interface</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>ASCII</p>
</td>
<td width="82%">
<p>American Standard Code for Information Interchange</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>BIOS</p>
</td>
<td width="82%">
<p>Basic input/output system</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>BSD</p>
</td>
<td width="82%">
<p>Berkeley Software Distribution</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>cA or c<sub>A</sub></p>
</td>
<td width="82%">
<p>Compiler c<sub>A</sub>, the compiler-under-test executable (see
<i>s</i><sub>A</sub>)</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>cGP or c<sub>GP</sub></p>
</td>
<td width="82%">
<p>Compiler c<sub>GP</sub>, the putative grandparent of
c<sub>A</sub> and putative parent of c<sub>P</sub></p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>CNSS</p>
</td>
<td width="82%">
<p>Committee on National Security Systems</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>cP or c<sub>P</sub></p>
</td>
<td width="82%">
<p>Compiler P, the putative parent of c<sub>A</sub></p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>CP/M</p>
</td>
<td width="82%">
<p>Control Program for Microcomputers</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>CPU</p>
</td>
<td width="82%">
<p>Central Processing Unit</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>cT or c<sub>T</sub></p>
</td>
<td width="82%">
<p>Compiler c<sub>T</sub>, a &#8220;trusted&#8221; compiler (see
section 4.3)</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>DDC</p>
</td>
<td width="82%">
<p>Diverse Double-Compiling</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>DoD</p>
</td>
<td width="82%">
<p>Department of Defense (U.S.)</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>DOS</p>
</td>
<td width="82%">
<p>Disk Operating System</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>DRAM</p>
</td>
<td width="82%">
<p>Dynamic Random Access Memory</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>e1</p>
</td>
<td width="82%">
<p>Environment that produces stage1</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>e2</p>
</td>
<td width="82%">
<p>Environment that produces stage2</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>eA</p>
</td>
<td width="82%">
<p>Environment that putatively produced c<sub>A</sub></p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>eArun</p>
</td>
<td width="82%">
<p>Environment that c<sub>A</sub> and stage2 are intended to run
in</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>EBCDIC</p>
</td>
<td width="82%">
<p>Extended Binary Coded Decimal Interchange Code</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>ECC</p>
</td>
<td width="82%">
<p>Error Correcting Code(s)</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>eP</p>
</td>
<td width="82%">
<p>Environment that putatively produced c<sub>P</sub></p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>FOL</p>
</td>
<td width="82%">
<p>First-Order Logic (with equality), aka first-order predicate
logic</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>FS</p>
</td>
<td width="82%">
<p>Free Software</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>FLOSS</p>
</td>
<td width="82%">
<p>Free-Libre/Open Source Software</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>FOSS</p>
</td>
<td width="82%">
<p>Free/Open Source Software</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>FSF</p>
</td>
<td width="82%">
<p>Free Software Foundation</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>GAO</p>
</td>
<td width="82%">
<p>General Accounting Office (U.S.)</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>GCC</p>
</td>
<td width="82%">
<p>GNU Compiler Collection (formerly the GNU C compiler)</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>GNU</p>
</td>
<td width="82%">
<p>GNU&#8217;s not Unix</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>GPL</p>
</td>
<td width="82%">
<p>General Public License</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>HOL</p>
</td>
<td width="82%">
<p>Higher Order Logic</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>IC</p>
</td>
<td width="82%">
<p>Integrated Circuit</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>IDA</p>
</td>
<td width="82%">
<p>Institute for Defense Analyses</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>iff</p>
</td>
<td width="82%">
<p>if and only if</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>I/O</p>
</td>
<td width="82%">
<p>input/output</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>IP</p>
</td>
<td width="82%">
<p>Intellectual Property</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>ISO</p>
</td>
<td width="82%">
<p>International Organization for Standardization (sic)</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>ITSD</p>
</td>
<td width="82%">
<p>Information Technology and Systems Division</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>MDA</p>
</td>
<td width="82%">
<p>Missile Defense Agency (U.S.); formerly named SDIO</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>MS-DOS</p>
</td>
<td width="82%">
<p>Microsoft Disk Operating System (MS-DOS)</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>NEL</p>
</td>
<td width="82%">
<p>Newline (#x85), used in OS/360</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>NIST</p>
</td>
<td width="82%">
<p>National Institute of Science and Technology (U.S.)</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>OpenBSD</p>
</td>
<td width="82%">
<p>Open Berkeley Software Distribution</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>OS/360</p>
</td>
<td width="82%">
<p>IBM System/390 operating-system</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>OSI</p>
</td>
<td width="82%">
<p>Open Source Initiative</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>OSS</p>
</td>
<td width="82%">
<p>Open Source Software</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>OSS/FS</p>
</td>
<td width="82%">
<p>Open Source Software/Free Software</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>PITAC</p>
</td>
<td width="82%">
<p>President&#8217;s Information Technology Advisory Committee</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>ProDOS</p>
</td>
<td width="82%">
<p>Professional Disk Operating System</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>PVS</p>
</td>
<td width="82%">
<p>Prototype Verification System</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>QED</p>
</td>
<td width="82%">
<p>Quod erat demonstrandum (&#8220;which was to be
demonstrated&#8221;)</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>RepRap</p>
</td>
<td width="82%">
<p>Replicating Rapid-prototyper</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>S-expression</p>
</td>
<td width="82%">
<p>Symbolic expression</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>sA or <i>s</i><sub>A</sub></p>
</td>
<td width="82%">
<p>putative source code of c<sub>A</sub></p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>SAMATE</p>
</td>
<td width="82%">
<p>Software Assurance Metrics And Tool Evaluation (NIST
project)</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>SDIO</p>
</td>
<td width="82%">
<p>Strategic Defense Initiative Organization (U.S.); later renamed
to the Missile Defense Agency (MDA)</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>SHA</p>
</td>
<td width="82%">
<p>Secure Hash Algorithm</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>sic</p>
</td>
<td width="82%">
<p>spelling is correct</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>sP or <i>s</i><sub>P</sub></p>
</td>
<td width="82%">
<p>putative source code of c<sub>P</sub></p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>SQL</p>
</td>
<td width="82%">
<p>Structured Query Language</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>STEM</p>
</td>
<td width="82%">
<p>Scanning Transmission Electron Microscope</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>tcc or TinyCC</p>
</td>
<td width="82%">
<p>Tiny C Compiler</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>UCS</p>
</td>
<td width="82%">
<p>Universal Character Set</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>URL</p>
</td>
<td width="82%">
<p>Uniform Resource Locator</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>U.S.</p>
</td>
<td width="82%">
<p>United States</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>UTF-8</p>
</td>
<td width="82%">
<p>8-bit UCS/Unicode Transformation Format</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>UTF-16</p>
</td>
<td width="82%">
<p>16-bit UCS/Unicode Transformation Format</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>VHDL</p>
</td>
<td width="82%">
<p>VHSIC hardware description language</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p>VHSIC</p>
</td>
<td width="82%">
<p>Very High Speed Integrated Circuit</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p><img src="wheeler-trusting-trust-ddc_html_633331a0.gif" alt="&Phi;,&Psi;,&Lambda;" align="absmiddle" width="58" height="18"></p>
</td>
<td width="82%">
<p>Arbitrary FOL formula</p>
</td>
</tr>
<tr valign="top">
<td width="18%">
<p><img src="wheeler-trusting-trust-ddc_html_78d80682.gif" alt="&tau;x" align="absmiddle" width="22" height="20"></p>
</td>
<td width="82%">
<p>Arbitrary FOL term number x</p>
</td>
</tr>
</table>
<p>See appendix E for key definitions.</p>
<h1><a name="0.Abstract|outline"></a> Abstract</h1>
<center>Fully Countering Trusting Trust through Diverse
Double-Compiling<br>
David A. Wheeler, PhD<br>
George Mason University, 2009<br>
Dissertation Directors: Dr. Daniel A. Menasc&#233; and Dr. Ravi
Sandhu<br></center>
<p>An Air Force evaluation of Multics, and Ken Thompson&#8217;s
Turing award lecture (&#8220;Reflections on Trusting Trust&#8221;),
showed that compilers can be subverted to insert malicious Trojan
horses into critical software, including themselves. If this
&#8220;trusting trust&#8221; attack goes undetected, even complete
analysis of a system&#8217;s source code will not find the
malicious code that is running. Previously-known countermeasures
have been grossly inadequate. If this attack cannot be countered,
attackers can quietly subvert entire classes of computer systems,
gaining complete control over financial, infrastructure, military,
and/or business systems worldwide. This dissertation&#8217;s thesis
is that the trusting trust attack can be detected and effectively
countered using the &#8220;Diverse Double-Compiling&#8221; (DDC)
technique, as demonstrated by (1) a formal proof that DDC can
determine if source code and generated executable code correspond,
(2) a demonstration of DDC with four compilers (a small C compiler,
a small Lisp compiler, a small maliciously corrupted Lisp compiler,
and a large industrial-strength C compiler, GCC), and (3) a
description of approaches for applying DDC in various real-world
scenarios. In the DDC technique, source code is compiled twice: the
source code of the compiler&#8217;s parent is compiled using a
trusted compiler, and then the putative compiler source code is
compiled using the result of the first compilation. If the DDC
result is bit-for-bit identical with the original
compiler-under-test&#8217;s executable, and certain other
assumptions hold, then the compiler-under-test&#8217;s executable
corresponds with its putative source code.</p>
<h1><a name="1.Introduction|outline"></a> 1 Introduction</h1>
<p>Many software security evaluations examine source code, under
the assumption that a program&#8217;s source code accurately
represents the executable actually run by the computer<a class=
"sdfootnoteanc" name="sdfootnote1anc" href=
"#sdfootnote1sym"><sup>1</sup></a>. Na&#239;ve developers presume
that this can be assured simply by recompiling the source code to
see if the same executable is produced. Unfortunately, the
&#8220;trusting trust&#8221; attack can falsify this
presumption.</p>
<p>For purposes of this dissertation, an executable that does not
correspond to its putative source code is <i>corrupted</i><a class=
"sdfootnoteanc" name="sdfootnote2anc" href=
"#sdfootnote2sym"><sup>2</sup></a>. If a corrupted executable was
intentionally created, we can call it a <i>maliciously
corrupted</i> executable. The <i>trusting trust attack</i> occurs
when an attacker attempts to disseminate a compiler executable that
produces corrupted executables, at least one of those produced
corrupted executables is a corrupted compiler, and the attacker
attempts to make this situation self-perpetuating. The attacker may
use this attack to insert other Trojan horse(s) (software that
appears to the user to perform a desirable function but facilitates
unauthorized access into the user&#8217;s computer system).</p>
<p>Information about the trusting trust attack was first published
in [Karger1974]; it became widely known through [Thompson1984].
Unfortunately, there has been no practical way to fully detect or
counter the trusting trust attack, because repeated in-depth review
of industrial compilers&#8217; executable code is impractical.</p>
<p>For source code evaluations to be strongly credible, there must
be a way to justify that the source code being examined accurately
represents what is being executed&#8212;yet the trusting trust
attack subverts that very claim. Internet Security System&#8217;s
David Maynor argues that the risk of attacks on compilation
processes is increasing [Maynor2004] [Maynor2005]. Karger and
Schell noted that the trusting trust attack was still a problem in
2000 [Karger2000], and some technologists doubt that computer-based
systems can ever be secure because of the existence of this attack
[Gauis2000]. Anderson et al. argue that the general risk of
subversion is increasing [Anderson2004].</p>
<p>Recently, in several mailing lists and blogs, a technique to
detect such attacks has been briefly described, which uses a second
(diverse) &#8220;trusted&#8221; compiler (as will be defined in
section 4.3) and two compilation stages. This dissertation terms
the technique &#8220;diverse double-compiling&#8221; (DDC). In the
DDC technique, the source code of the compiler&#8217;s parent is
compiled using a trusted compiler, and then the putative compiler
source code is compiled using the result of the first compilation
(chapter 4 further explains this). If the DDC result is bit-for-bit
identical with the original compiler-under-test&#8217;s executable,
and certain other assumptions hold, then the
compiler-under-test&#8217;s executable corresponds with its
putative source code (chapter 5 justifies this claim). Before this
work began, there had been no examination of DDC in detail which
identified its assumptions, proved its correctness or
effectiveness, or discussed practical issues in applying it. There
had also not been any public demonstration of DDC.</p>
<p>This dissertation&#8217;s thesis is that the trusting trust
attack can be detected and effectively countered using the
&#8220;Diverse Double-Compiling&#8221; (DDC) technique, as
demonstrated by (1) a formal proof that DDC can determine if source
code and generated executable code correspond, (2) a demonstration
of DDC with four compilers (a small C compiler, a small Lisp
compiler, a small maliciously corrupted Lisp compiler, and a large
industrial-strength C compiler, GCC), and (3) a description of
approaches for applying DDC in various real-world scenarios.</p>
<p>This dissertation provides background and a description of the
threat, followed by an informal description of DDC. This is
followed by a formal proof of DDC, information on how diversity (a
key requirement of DDC) can be increased, demonstrations of DDC,
and information on how to overcome practical challenges in applying
DDC. The dissertation closes with conclusions and ramifications.
Appendices have some additional detail. Further details, including
materials sufficient to reproduce the experiments, are available
at:</p>
<p><a href=
"http://www.dwheeler.com/trusting-trust/">http://www.dwheeler.com/trusting-trust/</a></p>
<p>This dissertation follows the guidelines of [Bailey1996] to
enhance readability. In addition, this dissertation uses logical
(British) quoting conventions; quotes do not enclose punctuation
unless they are part of the quote [Ritter2002]. Including
extraneous characters in a quotation can be grossly misleading,
especially in computer-related material [Raymond2003, chapter
5].</p>
<h1><a name="2.Background and related work|outline"></a> 2
Background and related work</h1>
<p>This chapter provides background and related work. It begins
with a discussion of the initial revelation of the trusting trust
attack by Karger, Schell, and Thompson, including a brief
description of &#8220;obvious&#8221; yet inadequate solutions. The
next sections discuss work on corrupted or subverted compilers, the
compiler bootstrap test, general work on analyzing software, and
general approaches for using diversity to improve security. This is
followed by evidence that software subversion is a real problem,
not just a theoretical concern. This chapter concludes by
discussing the DDC paper published by the Annual Computer Security
Applications Conference (ACSAC) [Wheeler2005] and the improvements
to DDC that have been made since that time.</p>
<h2><a name=
"2.1.Initial revelation: Karger, Schell, and Thompson|outline"></a>
2.1 Initial revelation: Karger, Schell, and Thompson</h2>
<p>Karger and Schell provided the first public description of the
problem that compiler executables can insert malicious code into
themselves. They noted in their examination of Multics
vulnerabilities that a &#8220;penetrator could insert a trap door
into the... compiler... [and] since the PL/I compiler is itself
written in PL/I, the trap door can maintain itself, even when the
compiler is recompiled. Compiler trap doors are significantly more
complex than the other trap doors... However, they are quite
practical to implement&#8221; [Karger1974].</p>
<p>Ken Thompson widely publicized this problem in his 1984 Turing
Award presentation (&#8220;Reflections on Trusting Trust&#8221;),
clearly explaining it and demonstrating that this was both a
practical and dangerous attack. He described how to modify the Unix
C compiler to inject a Trojan horse, in this case to modify the
operating system login program to surreptitiously give him root
access. He also added code so that the compiler would inject a
Trojan Horse when compiling itself, so the compiler became a
&#8220;self-reproducing program that inserts both Trojan horses
into the compiler&#8221;. Once this is done, the attacks could be
removed from the source code. At that point no source code
examination&#8212;even of the compiler&#8212;would reveal the
existence of the Trojan horses, yet the attacks could persist
through recompilations and cross-compilations of the compiler. He
then stated that &#8220;No amount of source-level verification or
scrutiny will protect you from using untrusted code... I could have
picked on any program-handling program such as an assembler, a
loader, or even hardware microcode. As the level of program gets
lower, these defects will be harder and harder to detect&#8221;
[Thompson1984]. Thompson&#8217;s demonstration also subverted the
disassembler, hiding the attack from disassembly. Thompson
implemented this attack in the C compiler and (as a demonstration)
successfully subverted another Bell Labs group, the attack was
never detected.</p>
<p>Thompson later gave more details about his demonstration,
including assurances that the maliciously corrupted compiler was
never released outside Bell Labs [Thornburg2000].</p>
<p>Obviously, this attack invalidates security evaluations based on
source code review, and recompilation of source code using a
potentially-corrupted compiler does not eliminate the risk. Some
simple approaches appear to solve the problem at first glance, yet
fail to do so or have significant weaknesses:</p>
<ul>
<li>
<p>Compiler executables could be manually compared with their
source code. This is impractical given compilers&#8217; large
sizes, complexity, and rate of change.</p>
</li>
<li>
<p>Such comparison could be automated, but optimizing compilers
make such comparisons extremely difficult, compiler changes make
keeping such tools up-to-date difficult, and the tool&#8217;s
complexity would be similar to a compiler&#8217;s.</p>
</li>
<li>
<p>A second compiler could compile the source code, and then the
executables could be compared automatically to argue semantic
equivalence. There is some work in determining the semantic
equivalence of two different executables [Sabin2004], but this is
very difficult to do in practice.</p>
</li>
<li>
<p>Receivers could require that they only receive source code and
then recompile everything themselves. This fails if the
receiver&#8217;s compiler is already maliciously corrupted; thus,
it simply moves the attack location. An attacker could also insert
the attack into the compiler&#8217;s source; if the receiver
accepts it (due to lack of diligence or conspiracy), the attacker
could remove the evidence in a later version of the compiler (as
further discussed in section 8.4).</p>
</li>
<li>
<p>Programs can be written in interpreted languages. But eventually
an interpreter must be implemented by machine code, so this simply
moves the attack location.</p>
</li>
</ul>
<h2><a name="2.2.Other work on corrupted compilers|outline"></a>
2.2 Other work on corrupted compilers</h2>
<p>Some previous papers outline approaches for countering corrupted
compilers, though their approaches have significant weaknesses.
Draper [Draper1984] recommends screening out maliciously corrupted
compilers by writing a &#8220;paraphrase&#8221; compiler (possibly
with a few dummy statements) or a different compiler executable,
compiling once to remove the Trojan horse, and then compiling a
second time to produce a Trojan horse-free compiler. This idea is
expanded upon by McDermott [McDermott1988], who notes that the
alternative compiler could be a reduced-function compiler or one
with large amounts of code unrelated to compilation. Lee&#8217;s
&#8220;approach #2&#8221; describes most of the basic process of
diverse double-compiling, but implies that the results might not be
bit-for-bit identical [Lee2000]. Luzar makes a similar point as
Lee, describing how to rebuild a system from scratch using a
different trusted compiler but not noting that the final result
should be bit-for-bit identical if other factors are carefully
controlled [Luzar2003].</p>
<p>None of these papers note that it is possible to produce a
result that is bit-for-bit identical to the original compiler
executable. This is a significant advantage of diverse
double-compiling (DDC), because determining if two different
executables are &#8220;functionally equivalent&#8221; is extremely
difficult<a class="sdfootnoteanc" name="sdfootnote3anc" href=
"#sdfootnote3sym"><sup>3</sup></a>, while determining if two
executables are bit-for-bit identical is extremely easy. These
previous approaches require each defender to recompile their
compiler themselves before using it; in contrast, DDC can be used
as an after-the-fact vetting process by multiple third parties,
without requiring a significant change in compiler delivery or
installation processes, and without requiring that all compiler
users receive the compiler source code. All of these previous
approaches simply move the potential vulnerability somewhere else
(e.g., to the process using the &#8220;paraphrase&#8221; compiler).
In contrast, an attacker who wishes to avoid detection by DDC must
corrupt <i>both</i> the original compiler and <i>every</i>
application of DDC to that executable, so each application of DDC
can further build confidence that a specific executable corresponds
with its putative source code. Also, none of these papers
demonstrate their technique.</p>
<p>Magdsick discusses using different versions of a compiler, and
different compiler platforms such as central processing unit (CPU)
and operating system, to check executables. However, Magdsick
presumes that the compiler itself will be the same base compiler
(though possibly a different version). He does note the value of
recompiling &#8220;everything&#8221; to check it [Magdsick2003].
Anderson notes that cross-compilation does not help if the attack
is in the compiler [Anderson2003]. Mohring argues for the use of
recompilation by GCC to check other components, presuming that the
GCC executables themselves in some environments would be pristine
[Mohring2004]. He makes no notice that all GCC executables used
might be maliciously corrupted, or of the importance of diversity
in compiler implementation. In his approach different compiler
versions may be used, so outputs would be &#8220;similar&#8221; but
not identical; this leaves the difficult problem of comparing
executables for &#8220;exact equivalence&#8221; unresolved.</p>
<p>A great deal of effort has been spent to develop proofs of
correctness for compilers, either of the compiler itself and/or its
generated results [Dave2003] [Stringer-Calvert1998] [Bellovin1982].
This is quite difficult even for simple languages, though there has
been progress. [Leinenbach2005] discusses progress in verifying a
subset C compiler using Isabelle/Higher Order Logic (HOL).
&#8220;Compcert&#8221; is a compiler that generates PowerPC
assembly code from Clight (a large subset of the C programming
language); this compiler is primarily written using the
specification language of the Coq proof assistant, and its
correctness (that the generated assembly code is semantically
equivalent to its source program) has been entirely proved within
the Coq proof assistant [Leroy2006] [Blazy2006] [Leroy2008]
[Leroy2009]. [Goerigk1997] requires formal specifications and
correspondence proofs, along with double-checking of resulting
transformations with the formal specifications. It does briefly
note that &#8220;if an independent (whatever that is)
implementation of the specification will generate an equal
bootstrapping result, this fact might perhaps increase confidence.
Note however, that, in particular in the area of security... We
want to guarantee the correctness of the generated code, e.g.,
preventing criminal attacks&#8221; [Goerigk1997, 17]. However, it
does not explain what independence would mean, nor what kind of
confidence this equality would provide. [Goerigk1999] specifically
focuses on countering Trojan horses in compilers, through formal
verification techniques, but again this requires having formal
specifications and performing formal correspondence proofs. Goerigk
recommends &#8220;a posteriori code inspection based on syntactic
code comparison&#8221; to counter the trusting trust attack, but
such inspection is very labor-intensive on industrial-scale
compilers that implement significant optimizations. DDC can be
dramatically strengthened by having formal specifications and
proofs of compilers (which can then be used as the trusted
compiler), but DDC does not require them. Indeed, DDC and formal
proofs of compilers can be used in a complementary way: A
formally-proved compiler may omit many useful optimizations (as
they can be difficult or time-consuming to prove), but it can still
be used as the DDC &#8220;trusted compiler&#8221; to gain
confidence in another (production-ready) compiler.</p>
<p>Spinellis argues that &#8220;Thompson showed us that one cannot
trust an application&#8217;s security policy by examining its
source code... The recent Xbox attack demonstrated that one cannot
trust a platform&#8217;s security policy if the applications
running on it cannot be trusted&#8221; [Spinellis2003]. It is worth
noting that the literature for change detection (such as [Kim1994]
and [Forrest1994]) and intrusion detection do not easily address
this problem, because a compiler is <i>expected</i> to accept
source code and generate object code.</p>
<p>Faigon&#8217;s &#8220;Constrained Random Testing&#8221; process
detects compiler defects by creating many random test programs,
compiling them with a compiler-under-test and a reference compiler,
and detecting if running them produces different results [Faigon].
Faigon&#8217;s approach may be useful for finding some compiler
errors, but it is extremely unlikely to find maliciously corrupted
compilers.</p>
<h2><a name="__RefHeading__32296994"></a><a name=
"2.3.Compiler bootstrap test|outline"></a> 2.3 Compiler bootstrap
test</h2>
<p>A common test for errors used by many compilers (including GCC)
is the so-called &#8220;compiler bootstrap test&#8221;. Goerigk
formally describes this test, crediting Niklaus Wirth&#8217;s 1986
book <i>Compilerbau</i> as proposing this test for detecting errors
in compilers [Goerigk1999]. In this test, if c(s,b) is the result
of compiling source s using compiler executable b, and <span style=
"text-decoration: overline">m</span> is some other compiler (the
&#8220;bootstrap&#8221; compiler), then<a class="sdfootnoteanc"
name="sdfootnote4anc" href="#sdfootnote4sym"><sup>4</sup></a>:</p>
<blockquote><i>If m0 and s are both correct and deterministic,
<span style="text-decoration: overline">m</span> is correct,
m0=c(s,<span style="text-decoration: overline">m</span>),
m1=c(s,m0), m2=c(s,m1), all compilations terminate, and if the
underlying hardware works correctly, then m1=m2.</i></blockquote>
<p>The compiler bootstrap test goes through steps to determine if
m1=m2; if not, there is a compiler error of some kind. This test
finds many unintentional errors, which is why it is popular. But
[Goerigk1999] points out that this test is insufficient to make
strong claims, in particular, m1 may equal m2 even if <span style=
"text-decoration: overline">m</span>, m0, or s are <i>not</i>
correct. For example, it is trivial to create compiler source code
that passes this test, yet is incorrect, since this test only tests
features used in the compiler itself. More importantly (for
purposes of this dissertation), if <span style=
"text-decoration: overline">m</span> is a maliciously corrupted
compiler, a compilation process can pass this test yet produce a
maliciously corrupted compiler m2. Note that the compiler bootstrap
test does <i>not</i> consider the possibility of using two
different bootstrap compilers (<span style=
"text-decoration: overline">m</span> and <span style=
"text-decoration: overline">m</span>&#8242;) and later comparing
their different compiler results (m2 and m2&#8242;) to see if they
produce the same (bit-for-bit) result. Therefore, the DDC technique
is <i>not</i> the same as the compiler bootstrap test. However, DDC
<i>does</i> have many of the same preconditions as the compiler
bootstrap test. Since the compiler bootstrap test is popular, many
DDC preconditions are already met by typical industrial compilers,
making DDC easier to apply to typical industrial compilers.</p>
<h2><a name="__RefHeading__33364470"></a><a name=
"2.4.Analyzing software|outline"></a> 2.4 Analyzing software</h2>
<p>All programs can be analyzed to find intentionally-inserted or
unintentional security issues (aka vulnerabilities). These
techniques can be broadly divided into static analysis (which
examines a static representation of the program, such as source
code or executable, without executing it) and dynamic analysis
(which examines what the program does while it is executing).
Formal methods, which are techniques that use mathematics to prove
programs or program models are correct, can be considered a
specific kind of static analysis technique.</p>
<p>Since compilers are programs, these general analysis techniques
(both static and dynamic) that are not specific to compilers can be
used on compilers as well.</p>
<h3><a name="2.4.1.Static analysis|outline"></a>2.4.1 Static
analysis</h3>
<p>Static analysis techniques examine programs (their source code,
executable, or both) without executing them. Both programs and
humans can perform static analysis.</p>
<p>There are many static analysis programs (aka tools) available;
many are focused on identifying security vulnerabilities in
software. The National Institute of Science and Technology (NIST)
Software Assurance Metrics And Tool Evaluation (SAMATE) project
(<a href="http://samate.nist.gov/">http://samate.nist.gov)</a> is
&#8220;developing methods to enable software tool evaluations,
measuring the effectiveness of tools and techniques, and
identifying gaps in tools and methods&#8221;. SAMATE has collected
a long list of static analysis programs for finding security
vulnerabilities by examining source code or executable code. There
are also a number of published reports comparing various static
analysis tools, such as [Zitser2004], [Forristal2005],
[Kratkiewicz2005], and [Michaud2006]. A draft functional
specification for source code analysis tools has been developed
[Kass2006], proposing a set of defects that such tools would be
required to find and the code complexity that they must be able to
handle while detecting them.</p>
<p>Although [Kass2006] briefly notes that source code analysis
tools might happen to find malicious trap doors, many documents on
static analysis focus on finding <i>unintentional</i> errors, not
maliciously-implanted vulnerabilities. [Kass2006] specifies a
specific set of security-relevant errors that have been made many
times in real programs, and limits the required depth of the
analysis (to make analysis time and reporting manageable).
[Chou2006] also notes that in practice, static analyzers give up on
error classes that are too hard to diagnose. For unintentional
vulnerabilities, this is sensible; unintentional errors that have
commonly occurred in the past are likely to recur (so searching for
them can be very helpful). Unfortunately, these approaches are less
helpful against an adversary who is <i>intentionally</i> inserting
malicious code into a program. An adversary could intentionally
insert one of these common errors, perhaps because they have high
deniability, but ensure that it is so complex that a tool is
unlikely to find it. Alternatively, an adversary could insert code
that is an attack but not in the list of patterns the tools search
for. Indeed, an adversary can repeatedly use static analysis tools
until he or she has verified that the malicious code will
<i>not</i> be detected later by those tools.</p>
<p>Static analysis tools also exist for analyzing executable files,
instead of source code files. Indeed, [Balakrishnan2005] argues
that program analysis should begin with executables instead of
source code, because only the executables are actually run and
source code analysis can be misled. To address this, there are
efforts to compute better higher-level constructs from executable
code, but in the general case this is still a difficult research
area [Linger2006].</p>
<p>[Wysopal] presents a number of heuristics that can be used to
statically detect some application backdoors in executable files.
This includes identifying static variables that &#8220;look
like&#8221; usernames, passwords, or cryptographic keys, searching
for network application programmer interface (API) calls in
applications where they are unexpected, searching for standard
date/time API calls (which may lead to a time bomb), and so on.
Unfortunately, many malicious programs will not be detected by such
heuristics, and as noted above, attackers can develop malicious
software in ways that specifically avoid detection by the
heuristics of such tools.</p>
<p>Many static analysis tools for executables use the same approach
as many static analysis tools for source code: they search for
specific programs or program fragments known to be problematic. The
most obvious case are virus-checkers; though it is possible to
examine behavior, and some anti-virus programs are increasingly
doing so, historically &#8220;anti-virus&#8221; programs have a set
of patterns of known viruses, which is constantly updated and used
to search various executables (e.g., in a file or boot record) to
see if these patterns are present [Singh2002] [Lapell2006].
However, as noted in Fred Cohen&#8217;s initial work on computer
viruses [Cohen1985], viruses can mutate as they propagate, and it
is not possible to create a pattern listing all-and-only malicious
programs. [Christodorescu2003] attempts to partially counter this;
this paper regards malicious code detection as an
obfuscation-deobfuscation game between malicious code writers and
researchers, and presents an architecture for detecting known
malicious patterns in executables that are hidden by common
obfuscation techniques. Even this more robust architecture does not
work against different malicious patterns, nor against different
obfuscation techniques.</p>
<p>Of course, even if tools cannot find malicious code, detailed
human review can be used at the source or executable level if the
software is critical enough to warrant it. For example, the Open
Berkeley Software Distribution (OpenBSD) operating system source
code is regularly and purposefully examined by a team of people
with the explicit intention of finding and fixing security holes,
and as a result has an excellent security record [Payne2002]. The
Strategic Defense Initiative Organization (SDIO), now named the
Missile Defense Agency (MDA), even developed a set of process
requirements to counter malicious and unintentional
vulnerabilities, emphasizing multi-person knowledge and review
along with configuration management and other safeguards
[SDIO1993].</p>
<p>Unfortunately, the trusting trust attack can render human
reviews moot if there is no technique to counter the attack. The
trusting trust attack immediately renders examination of the source
code inadequate, because the executable code need not correspond to
the source code. Thompson&#8217;s attack subverted the symbolic
debugger, so in that case, even human review of the executable
could fail to detect the attack. Thus, human reviews are less
convincing unless the trusting trust attack is itself
countered.</p>
<p>Human review also presumes that other humans examining source
code or executables will be able to detect malicious code. In large
code bases, this can be a challenge simply due to their size and
complexity. In addition, it is possible for an adversary to create
source code that <i>appears</i> to work correctly, yet actually
performs a malevolent action instead. This dissertation uses the
term <i>maliciously misleading code</i> for any source code that is
intentionally designed to look benign, yet creates a vulnerability
(including an attack). The topic of maliciously misleading code is
further discussed in section 8.11.</p>
<h3><a name="2.4.2.Dynamic analysis|outline"></a>2.4.2 Dynamic
analysis</h3>
<p>It is also possible to use dynamic techniques in an attempt to
detect and/or counter vulnerabilities by examining the activities
of a system, and then halting or examining the system when those
activities are suspicious. A trivial example is execution testing,
where a small set of inputs are provided and the inputs are checked
to see if they are correct. However, dynamic analysis is completely
inadequate for countering the trusting trust attack.</p>
<p>Traditional execution testing is unlikely to counter the
trusting trust attack. Such attacks will only &#8220;trigger&#8221;
on very specific inputs, as discussed in section 3.2, so even if
the executable is examined in detail, it is extremely unlikely that
traditional execution testing will detect this problem.</p>
<p>Detecting at run-time arbitrary corrupted code in a compiler or
the executable code it generates is very difficult. The fundamental
behavior of a corrupted compiler &#8211; that it accepts source
code and generates an executable &#8211; is no different from a
uncorrupted one. Similarly, any malicious code a compiler inserts
into other programs can often be made to behave normally in most
cases. For example, a login program with a trap door (a hidden
username and/or password) has the same general behavior: It decides
if a user may log in and what privileges to apply. Indeed, it may
act completely correctly as long as the hidden username and/or
password are not used.</p>
<p>In theory, continuous comparison of an executable&#8217;s
behavior at run-time to its source code could detect differences
between the executable and source code. Unfortunately, this would
need to be done all the time, draining performance. Even worse,
tools to do this comparison, given modern compilers producing
highly optimized code, would be far more complex than a compiler,
and would themselves be vulnerable to attack.</p>
<p>Given an extremely broad definition of &#8220;system&#8221;, the
use of software configuration management tools and change detection
tools like Tripwire [Kim1994] could be considered dynamic
techniques for countering malicious software. Both enable detection
of changes in the behavior of a larger system. Certainly a
configuration management system could be used to record changes
made to compiler source, and then used to enable reviewers to
examine just the differences. But again, such review presupposes
that any vulnerability in an executable could be revealed by
analyzing its source code, a presupposition the trusting trust
attack subverts.</p>
<p>A broader problem is that once code is running, <i>some</i>
programs must be trusted, and at least some of that code will
almost certainly have been generated by a compiler. Any program
that attempts to monitor execution might itself be subverted, just
as Thompson subverted the symbolic debugger, unless there is a
technique to prevent it. In any case, it would be better to detect
and counter malicious code <i>before</i> it executed, instead of
trying to detect malicious code&#8217;s execution while or after it
occurs.</p>
<h2><a name="2.5.Diversity for security|outline"></a>2.5 Diversity
for security</h2>
<p>There are a number of papers and articles about employing
diversity to aid computer security, though they generally do not
discuss or examine how to use diversity to counter Trojan horses
inside compilers themselves or the compilation environment.</p>
<p>Geer et al. strongly argue that a monoculture (an absence of
diversity) in computing platforms is a serious security problem
[Geer2003] [Bridis2003], but do not discuss employing compiler
diversity to counter this particular attack.</p>
<p>Forrest et al argue that run-time diversity in general is
beneficial for computer security. In particular, their paper
discusses techniques to vary final executables by
&#8220;randomized&#8221; transformations affecting compilation,
loading, and/or execution. Their goal was to automatically change
the executable (as seen at run-time) in some random ways sufficient
to make it more difficult to attack. The paper provides a set of
examples, including adding/deleting nonfunctional code, reordering
code, and varying memory layout. They demonstrated the concept
through a compiler that randomized the amount of memory allocated
on a stack frame, and showed that the approach foiled a simple
buffer overflow attack [Forrest1997]. Again, they do not attempt to
counter corrupted compilers.</p>
<p>John Knight and Nancy Leveson performed an experiment with
&#8220;N-version programming&#8221; and showed that, in their
experiment, &#8220;the assumption of independence of errors that is
fundamental to some analyses of N-version programming does not
hold&#8221; [Knight1986] [Knight1990]. As will be explained in
section 4.7, this result does not invalidate DDC.</p>
<h2><a name="__RefHeading__37236461"></a><a name=
"2.6.Subversion of software is a real problem|outline"></a> 2.6
Subversion of software is a real problem</h2>
<p>Subversion of software is not just a theoretical possibility; it
is a current problem. One book on computer crime lists various
kinds of software subversion as attack methods (e.g., trap doors,
Trojan horses, viruses, worms, salamis, and logic bombs)
[Icove1995, 57-58]. CERT<a class="sdfootnoteanc" name=
"sdfootnote5anc" href="#sdfootnote5sym"><sup>5</sup></a> has
published a set of case studies of &#8220;persons who used
programming techniques to commit malicious acts against their
organizations&#8221; [Cappelli2008]. Examples of specific software
subversion or subversion attempts include:</p>
<ul>
<li>
<p>Michael Lauffenburger inserted a logic bomb into a program at
defense contractor General Dynamics, his employer. The bomb would
have deleted vital rocket project data in 1991, including much that
was unrecoverable, but another employee stumbled onto it before it
was triggered [AP1991] [Hoffman1991].</p>
</li>
<li>
<p>Timothy Lloyd planted a 6-line logic bomb into the systems of
Omega Engineering, his employer, that went off on July 31, 1996.
This erased all of the company&#8217;s contracts and proprietary
software used by their manufacturing tools, resulting in an
estimated $12 million in damages, 80 people permanently losing
their jobs, and the loss of their competitive edge in the
electronics market space. Plant manager Jim Ferguson stated flatly,
&#8220;We will never recover&#8221;. On February 26, 2002, a judge
sentenced Lloyd to 41 months in prison, three years of probation,
and ordered him to pay more than $2 million in damages to Omega
[Ulsh2000] [Gardian].</p>
</li>
<li>
<p>Roger Duronio worked at UBS PaineWebber&#8217;s offices in
Weehawken, N.J., and was with the company for two years as a system
administrator. Apparently dissatisfied with his pay, he installed a
logic bomb to detonate on March 4, 2002, and resigned from the
company. When the logic bomb went off, it caused over 1,000 of
their 1,500 networked computers to begin deleting files. This cost
UBS PaineWebber more than $3 million to assess and repair the
damage, plus an undetermined amount from lost business. Duronio was
sentenced to 97 months in federal prison (the maximum per the U.S.
sentencing guidelines), and ordered to make $3.1 million in
restitution [DoJ2006] [Gaudin2006b]. The attack was only a few
lines of C code, which examined the time to see if it was the
detonation time, and then (if so) executed a shell command to erase
everything [Gaudin2006a].</p>
</li>
<li>
<p>An unnamed developer inside Borland inserted a back door into
the Borland/Inprise Interbase Structured Query Language (SQL)
database server around 1994. This was a &#8220;superuser&#8221;
account (&#8220;politically&#8221;) with a known password
(&#8220;correct&#8221;), which could not be &#8220;changed using
normal operational commands, nor [deleted] from existing vulnerable
servers&#8221;. Versions released to the public from 1994 through
2001 included this back door. Originally Interbase was a
proprietary program sold by Borland/Inprise. However, it was
released as open source software<a class="sdfootnoteanc" name=
"sdfootnote6anc" href="#sdfootnote6sym"><sup>6</sup></a> in July
2000, and less than six months later the open source software
developers discovered the vulnerability [Havrilla2001a]
[Havrilla2001b]. The Firebird project, an alternate open source
software package based on the same Interbase code, was also
affected. Jim Starkey, who launched InterBase but left in 1991
before the back door was added to the software in 1994, stated that
he believed that this back door was not malicious, but simply added
to enable one part of the database software to communicate with
another part [Shankland2001]. However, this code had the hallmarks
of many malicious back doors: It added a special account that was
(1) undocumented, (2) cannot be changed, and (3) gave complete
control to the requester.</p>
</li>
<li>
<p>An unknown attacker attempted to insert a malicious back door in
the Linux kernel in 2003. The two new lines were crafted to
<i>appear</i> legitimate, by using an &#8220;=&#8221; where a
&#8220;==&#8221; would be expected. The configuration management
tools immediately identified a discrepancy, and examination of the
changes by the Linux developers quickly determined that it was an
attempted attack [Miller2003] [Andrews2003].</p>
</li>
</ul>
<p>More recently, in 2009 the Win32.Induc virus was discovered in
the wild. This virus attacks Delphi compiler installations,
modifying the compiler itself. Once the compiler is infected, all
programs compiled by that compiler will be infected [Mills2009]
[Feng2009]. Thus, countering subverted compilers is no longer an
academic exercise; attacks on compilers have already occurred.</p>
<p>Many have noted insertion of malicious code into software as an
important risk:</p>
<ul>
<li value="1">
<p>Many have noted subversion of software as an issue in electronic
voting machines [Saltman1988] [Kohno2004] [Feldman2006]
[Barr2007].</p>
</li>
<li>
<p>The U.S. Department of Defense (DoD) established a
&#8220;software assurance initiative&#8221; in 2003 to examine
software assurance issues in defense software, including how to
counter intentionally inserted malicious code [Komaroff2005]. In
2004, the U.S. General Accounting Office (GAO) criticized the DoD,
claiming that the DoD &#8220;policies do not fully address the risk
of using foreign suppliers to develop weapon system software...
policies [fail to focus] on insider threats, such as the insertion
of malicious code by software developers...&#8221; [GAO2004]. The
U.S. Committee on National Security Systems (CNSS) defines Software
Assurance (SwA) as &#8220;the level of confidence that software is
free from vulnerabilities, either intentionally designed into the
software or accidentally inserted at anytime during its lifecycle,
and that the software functions in the intended manner&#8221;
[CNSS2006]. Note that intentionally-created vulnerabilities
inserting during software development are specifically included in
this definition.</p>
</li>
<li>
<p>The President&#8217;s Information Technology Advisory Committee
(PITAC) found that &#8220;Vulnerabilities in software that are
introduced by mistake or poor practices are a serious problem
today. In the future, the Nation may face an even more challenging
problem as adversaries &#8211; both foreign and domestic &#8211;
become increasingly sophisticated in their ability to insert
malicious code into critical software&#8221; [PITAC2005, 9]. The
U.S. National Strategy to Secure Cyberspace reported that a
&#8220;spectrum of malicious actors can and do conduct attacks
against our critical information infrastructures. Of primary
concern is the threat of organized cyber attacks capable of causing
debilitating disruption to our Nation&#8217;s critical
infrastructures, economy, or national security.... [and could
subvert] our infrastructure with back doors and other means of
access.&#8221; [PCIB2003,6]</p>
</li>
<li>
<p>In 2003, China's State Council announced a plan requiring all
government ministries to buy only locally produced software when
upgrading, and to increase use of open source software, in part due
to concerns over &#8220;data spyholes installed by foreign
powers&#8221; in software they procured for government use
[CNETAsia2003].</p>
</li>
</ul>
<p>In short, as software becomes more pervasive, subversion of it
becomes ever more tempting to powerful individuals and
institutions. Attackers can even buy legitimate software companies,
or build them up, to widely disseminate quality products at a low
price... but with &#8220;a ticking time bomb inside&#8221;
[Schwartau1994, 304-305].</p>
<p>Not all articles about subversion specifically note the trusting
trust attack as an issue, but as noted earlier, for source code
evaluations to be strongly credible, there must be a way to justify
that the source code being examined accurately represents what is
being executed&#8212;yet the trusting trust attack subverts that
very claim. Internet Security System&#8217;s David Maynor argues
that the risk of attacks on compilation processes is increasing
[Maynor2004] [Maynor2005]; Karger and Schell noted that the
trusting trust attack was still a problem in 2000 [Karger2000], and
some technologists doubt that computer-based systems can ever be
secure because of the existence of this attack [Gauis2000].
Anderson et al. argue that the general risk of subversion is
increasing [Anderson2004]. Williams argues that the risk from
malicious developers should be taken seriously, and describes a
variety of techniques that malicious programmers can use to insert
and hide attacks in an enterprise Java application
[Williams2009].</p>
<h2><a name="2.7.Previous DDC paper|outline"></a>2.7 Previous DDC
paper</h2>
<p>Initial results from DDC research were published by the Annual
Computer Security Applications Conference (ACSAC) in [Wheeler2005].
This paper was well-received, for example, Bruce Schneier wrote a
glowing review and summary of the paper [Schneier2006], and the
Spring 2006 class &#8220;Secure Software Engineering Seminar&#8221;
of Dr. James Walden (Northern Kentucky University) included it in
its required reading list.</p>
<p>This dissertation includes the results of [Wheeler2005] and
refines it further:</p>
<ul>
<li>
<p>The definition of DDC is generalized to cover the case where the
compiler is not self-regenerating. Instead, a compiler-under-test
may have been generated using a different &#8220;parent&#8221;
compiler. Self-regeneration (where the putative source code of the
parent and compiler-under-test are the same) is now a special
case.</p>
</li>
<li>
<p>A formal proof of DDC is provided, including a formalization of
DDC assumptions. The earlier paper includes only an informal
justification. The proof covers cases where the environments are
different, including the effect of different text representation
systems.</p>
</li>
<li>
<p>A demonstration of DDC with a known maliciously corrupted
compiler is shown. As expected, DDC detects this case.</p>
</li>
<li>
<p>A demonstration of DDC with an industrial-strength compiler
(GCC) is shown.</p>
</li>
<li>
<p>The discussion on the application of DDC is extended to cover
additional challenges, including its potential application to
hardware.</p>
</li>
</ul>
<h1><a name="3.Description of threat|outline"></a>3 Description of
threat</h1>
<p>Thompson describes how to perform the trusting trust attack, but
there are some important characteristics of the attack that are not
immediately obvious from his presentation. This chapter examines
the threat in more detail and introduces terminology to describe
the threat. This terminology will be used later to explain how the
threat is countered. For a more detailed model of this threat, see
[Goerigk2000] and [Goerigk2002] which provide a formal model of the
trusting trust attack.</p>
<p>The following sections describe what might motivate an attacker
to actually perform such an attack, and the mechanisms an attacker
uses that make this attack work (triggers, payloads, and
non-discovery).</p>
<h2><a name="__RefHeading__36351251"></a><a name=
"3.1.Attacker motivation|outline"></a> 3.1 Attacker motivation</h2>
<p>Understanding any potential threat involves determining the
benefits to an attacker of an attack, and comparing them to the
attacker&#8217;s risks, costs, and difficulties. Although this
trusting trust attack may seem exotic, its large benefits may
outweigh its costs to some attackers.</p>
<p>The potential benefits are immense to a malicious attacker. A
successful attacker can completely control all systems that are
compiled by that executable and that executable&#8217;s
descendants, e.g., they can have a known login (e.g., a
&#8220;backdoor password&#8221;) to gain unlimited privileges on
entire classes of systems. Since detailed source code reviews will
not find the attack, even defenders who have highly valuable
resources and check all source code are vulnerable to this
attack.</p>
<p>For a widely-used compiler, or one used to compile a widely-used
program or operating system, this attack could result in global
control. Control over banking systems, financial markets,
militaries, or governments could be gained with a single attack. An
attacker could possibly acquire enormous funds (by manipulating the
entire financial system), acquire or change extremely sensitive
information, or disable a nation&#8217;s critical infrastructure on
command.</p>
<p>An attacker can perform the attack against multiple compilers as
well. Once control is gained over all systems that use one
compiler, trust relationships and network interconnections could be
exploited to ease attacks against other compiler executables. This
would be especially true of a patient and careful attacker; once a
compiler is subverted, it is likely to stay subverted for a long
time, giving an attacker time to use it to launch further
attacks.</p>
<p>An attacker (either an individual or an organization) who
subverted a few of the most widely used compilers of the most
widely-used operating systems could effectively control, directly
or indirectly, almost every computer in existence.</p>
<p>The attack requires knowledge about compilers, effort to create
the attack, and access (gained somehow) to the compiler executable,
but all are achievable. Compiler construction techniques are
standard Computer Science course material. The attack requires the
insertion of relatively small amounts of code, so the attack can be
developed by a single knowledgeable person. Access rights to change
the relevant compiler executables are usually harder to acquire,
but there are clearly some who have such privileges already, and a
determined attacker may be able to acquire such privileges through
a variety of means (including network attack, social engineering,
physical attack, bribery, and betrayal).</p>
<p>The amount of power this attack offers is great, so it is easy
to imagine a single person deciding to perform this attack for
their own ends. Individuals entrusted with compiler development
might succumb to the temptation if they believed they could not be
caught. Today there are many virus writers, showing that many
people are willing to write malicious code even without gaining the
control this attack can provide.</p>
<p>It is true that there are <i>other</i> devastating attacks that
an attacker could perform in the current environment. Many users
routinely download and install massive executables, including large
patches and updates, that could include malicious code, and few
users routinely examine executable machine code or byte code. Few
users examine source code even when they <i>can</i> receive it, and
in many cases users are not legally allowed to examine the source
code. As a result, here are some other potentially-devastating
attacks that could be performed besides the trusting trust
attack:</p>
<ul>
<li>
<p>An attacker can find unintentional vulnerabilities in existing
executables, and then write code to exploit them.</p>
</li>
<li>
<p>An attacker could modify or replace a widely-used/important
executable during or after its compilation, but before its release
by its supplier. For example, an attacker might be able to do this
by bribing or extorting a key person in the supplying organization,
by becoming a key person, or by subverting the supplier&#8217;s
infrastructure.</p>
</li>
<li>
<p>Even when users only accept source code and compile the source
code themselves, an attacker could insert an intentional attack in
the source code of a widely-used/important program in the hope that
no one will find it later.</p>
</li>
<li>
<p>An attacker with a long-range plan could develop a useful
program specifically so that they can embed or eventually embed an
attack (using the two attacks previously noted). In such cases the
attacker might become a trusted (but not trustworthy) supplier.</p>
</li>
</ul>
<p>However, there is a <i>fundamental difference</i> with the
attacks listed above and the trusting trust attack: there are
<i>known detection techniques</i> for these attacks:</p>
<ul>
<li>
<p>Static and dynamic analysis can detect many unintentional
vulnerabilities, because they tend to be caused by common
implementation mistakes. In addition, software designs can reduce
the damage from such mistakes, and some implementation languages
can completely eliminate certain kinds of mistakes. Many documents
discuss how to develop secure software for those trying to do so,
including [Wheeler2003s] and [NDIA2008].</p>
</li>
<li>
<p>If an attacker swaps the expected executable with a malicious
executable, without using a trusting trust attack, the attack can
be discovered by recompiling the source code to see if it produces
the same results (presuming a deterministic compiler is used). Even
if it is not discovered, recompilation of the next version of the
executable will often eliminate the attack if it is not a
&#8220;trusting trust&#8221; attack.</p>
</li>
<li>
<p>If an attacker inserts an intentional attack or vulnerability in
the source code, this can be revealed by examining the source code
(see section 8.11 for a discussion on attacks which are
intentionally difficult to find in source code).</p>
</li>
<li>
<p>If the user does not fully trust the supplier to perform such
tests, then these tests could be performed by the user (if the user
has the necessary information), or by a third party who is trusted
by the user and supplier (if the supplier is unwilling to give
necessary information to the user, but are willing to give it to
such a third party). If the supplier is unwilling to provide the
necessary information to either the user or a third party, the user
could reasonably conclude that using such suppliers is a higher
risk than using suppliers who <i>are</i> willing to provide this
information, and then take steps based on that conclusion.</p>
</li>
</ul>
<p>In contrast, there has been <i>no</i> known effective detection
technique for the trusting trust attack. Thus, even if all of these
well-known detection techniques were used, users would <i>still</i>
be vulnerable to the trusting trust attack. What is more, the
subversion can persist indefinitely; the longer it remains
undetected, the more difficult it will be to reliably identify the
perpetrator even if it <i>is</i> detected.</p>
<p>Given such extraordinarily large benefits to an attacker, and
the lack of an effective detection mechanism, a highly resourced
organization (such as a government) might decide to undertake it.
Such an organization could supply hundreds of experts, working
together full-time to deploy attacks over a period of decades.
Defending against this scale of attack is far beyond the defensive
abilities of most companies and non-profit organizations who
develop and maintain popular compilers.</p>
<p>In short, this is an attack that can yield complete control over
a vast number of systems, even those systems whose defenders
perform independent source code analysis (e.g., those who have
especially high-value assets), so it is worth defending
against.</p>
<h2><a name="__RefHeading__32211702"></a><a name=
"3.2.Triggers, payloads, and non-discovery|outline"></a> 3.2
Triggers, payloads, and non-discovery</h2>
<p>The trusting trust attack depends on three things: triggers,
payloads, and non-discovery. For purposes of this dissertation, a
&#8220;trigger&#8221; is a condition determined by an attacker in
which a malicious event is to occur (e.g., when malicious code is
to be inserted into a program). A &#8220;payload&#8221; is the code
that actually performs the malicious event (e.g., the inserted
malicious code and the code that causes its insertion). The attack
also depends on non-discovery by its victims, that is, it depends
on victims not detecting the attack (before, during, or after it
has been triggered)<a class="sdfootnoteanc" name="sdfootnote7anc"
href="#sdfootnote7sym"><sup>7</sup></a>.</p>
<p>For this attack to be valuable, there must be at least two
triggers that can occur during compilation: at least one to cause a
malicious attack directly of value to the attacker (e.g., detecting
compilation of a &#8220;login&#8221; program so that a Trojan horse
can be inserted into it), and one to propagate attacks into future
versions of the compiler executable.</p>
<p>If a trigger is activated when the attacker does not intend the
trigger to be activated, the probability of detection increases.
However, if a trigger is not activated when the attacker intends it
to be activated, then that particular attack will be disabled. If
all the attacks by the compiler against itself are disabled, then
the attack will no longer propagate; once the compiler is
recompiled, the attacks will disappear. Similarly, if a payload
requires a situation that (through the process of change)
disappears, then the payload will no longer be effective (and its
failure may reveal the attack).</p>
<p>In this dissertation, &#8220;fragility&#8221; is the
susceptibility of the trusting trust attack to failure, i.e., that
a trigger will activate when the attacker did not wish it to
(risking a revelation of the attack), fail to trigger when the
attacker would wish it to, or that the payload will fail to work as
intended by the attacker. Fragility is unfortunately less helpful
to the defender than it might first appear. An attacker can counter
fragility by simply incorporating many narrowly-defined triggers
and payloads. Even if a change causes one trigger to fail, another
trigger may still fire. By using multiple triggers and payloads, an
attacker can attack multiple points in the compiler and attack
different subsystems as final targets (e.g., the login system, the
networking interface, and so on). Thus, even if some attacks fail
over time, there may be enough vulnerabilities in the resulting
system to allow attackers to re-enter and re-insert new triggers
and payloads into a malicious compiler. Even if a compiler
misbehaves from malfunctioning malware, the results could appear to
be a mysterious compiler defect; if programmers &#8220;code
around&#8221; the problem, the attack will stay undetected.</p>
<p>Since attackers do not want their malicious code to be
discovered, they may limit the number of triggers/payloads they
insert and the number of attacked compilers. In particular,
attackers may tend to attack only &#8220;important&#8221; compilers
(e.g., compilers that are widely-used or used for high-asset
projects), since each compiler they attack (initially or to add new
triggers and payloads) increases the risk of discovery. However,
since these attacks can allow an attacker to deeply penetrate
systems generated with the compiler, maliciously corrupted
compilers make it easier for an attacker to re-enter a previously
penetrated development environment to refresh an executable with
new triggers and payloads. Thus, once a compiler has been
subverted, it may be difficult to undo the damage without a process
for ensuring that there are no attacks left.</p>
<p>The text above might give the impression that only the compiler
itself, as usually interpreted, can influence results (or how they
are run), yet this is obviously not true. Assemblers and loaders
are excellent places to place a trigger (the popular GCC C compiler
actually generates assembly language as text and then invokes an
assembler). An attacker could place the trigger mechanism in the
compiler&#8217;s supporting infrastructure such as the operating
system kernel, libraries, or privileged programs.</p>
<h1><a name="__RefHeading__33161301"></a><a name=
"4.Informal description of Diverse Double-Compiling (DDC)|outline"></a>
4 Informal description of Diverse Double-Compiling (DDC)</h1>
<p>The idea of diverse double-compiling (DDC) was first created and
posted by Henry Spencer in 1998 [Spencer1998] in a very short
posting. It was inspired by McKeeman et al&#8217;s exercise for
detecting compiler defects [McKeeman1970] [Spencer2005]. Since this
time, this idea has been posted in several places, typically with
very short descriptions [Mohring2004] [Libra2004] [Buck2004]. This
chapter describes the graphical notation for describing DDC that is
used in this dissertation. This is followed by a brief informal
description of DDC, an informal discussion of its assumptions, a
clarification that DDC does <i>not</i> require that arbitrary
<i>different</i> compilers produce the same executable output given
the same input, and a discussion of a common special case:
Self-parenting compilers. This chapter closes by answering some
questions, including: Why not <i>always</i> use the trusted
compiler, and why is this different from N-version programming?</p>
<h2><a name="4.1.Terminology and notation|outline"></a> 4.1
Terminology and notation</h2>
<p>This dissertation focuses on compilers. For purposes of this
dissertation, compilers execute in some environment, receiving as
input <i>source code</i> as well as other input from the
environment, and producing a result termed an <i>executable</i>. A
compiler is, itself, an executable.</p>
<p><a name="figure1"></a><img src="figure1.png" alt="Illustration of graphical notation. Inputs are a compiler, source code, and other input, producing a compilation result."  width="404" height="254">
<br clear="left">
<font size="3"><i>Figure 1: Illustration of graphical
notation</i></font></p>
<br clear="left">
<p>Figure 1 illustrates the notation used in this dissertation. A
shaded box shows a compilation step, which executes a compiler
(input from the top), processing source code (input from the left),
and uses other input (input from the right), all to produce an
executable (output exiting down). To distinguish the different
steps, each compilation step will be given a unique name (shown
here as &#8220;n&#8221;). Source code that is purported to be the
source code for the executable Y is notated as
<i>s</i><sub>Y</sub>. The result of a compilation step using
compiler X, source code <i>s</i><sub>Y</sub>, other input I (e.g.,
run-time libraries, random number results, and thread schedule),
and environment E is an executable, notated here as
compile(<i>s</i><sub>Y</sub>,&nbsp;c<sub>X</sub>,&nbsp;I,&nbsp;E).
Where the environment can be determined from context (e.g., it is
all the same) that parameter is omitted; where that is true and any
other input (if relevant) can be inferred, both are omitted
yielding the notation
compile(<i>s</i><sub>Y</sub>,&nbsp;c<sub>X</sub>). In some cases,
this will be further abbreviated as
c(<i>s</i><sub>Y</sub>,&nbsp;c<sub>X</sub>).</p>
<p>The widely-used &#8220;T&nbsp;diagram&#8221; (aka
&#8220;Bratman&#8221;) notation is not used in this dissertation.
T&nbsp;diagrams were originally created by Bratman [Bratman1961],
and later greatly extended and formalized by Earley and Sturgis
[Earley1970]. T&nbsp;diagrams can be very helpful when discussing
certain kinds of bootstrapping approaches. However, they are not a
universally perfect notation, and this dissertation intentionally
uses a different notation because the weaknesses of T&nbsp;diagrams
make DDC unnecessarily difficult to describe:</p>
<ul>
<li>
<p>T&nbsp;diagrams combining multiple compilation steps can be very
confusing [Mogensen2007, 219]. This is a serious problem when
representing DDC, since DDC is fundamentally about multiple
compilation steps.</p>
</li>
<li>
<p>T&nbsp;diagrams quickly grow in width when multiple steps are
involved; since paper is usually taller than it is wide, this can
make complex situations more difficult to represent on the printed
page. Again, applying DDC involves multiple steps.</p>
</li>
<li>
<p>T&nbsp;diagrams do not handle multiple sub-components well
(e.g., a library embedded in a compiler). The notation can be
&#8220;fudged&#8221; to do this (see [Early1970, 609]) but the
resulting graphic is excessively complex. Again, compilation of
real compilers using DDC often involves handling multiple
sub-components, making this weakness more important.</p>
</li>
<li>
<p>T&nbsp;diagrams create unnecessary clutter when applied to DDC.
In a T&nbsp;diagram, every compiler source code and compiler
executable, as well as their executions, are represented by a T.
This creates unnecessary visual clutter, making it difficult to see
what is executed and what is not.</p>
</li>
</ul>
<p>Niklaus Wirth abandoned T&nbsp;diagrams in his 1996 book on
compilers, without even mentioning them [Wirth1996], so clearly
T&nbsp;diagrams are not absolutely required when discussing
compiler bootstrapping. The notation of this dissertation uses a
single, simple box for each execution of a compiler, instead of a
trio of T&nbsp;shaped figures. As DDC application becomes complex,
this simplification matters.</p>
<h2><a name="4.2.Informal description of DDC|outline"></a> 4.2
Informal description of DDC</h2>
<p>In brief, to perform DDC, source code must be compiled twice.
First, use a separate &#8220;trusted&#8221; compiler to compile the
source code of the &#8220;parent&#8221; of the compiler-under-test.
Then, run that resulting executable to compile the purported source
code of the compiler-under-test. Then, check if the final result is
<i>exactly</i> identical to the original compiler executable (e.g.,
bit-for-bit equality) using some trusted means. If it is, then the
purported source code and executable of the compiler-under-test
correspond, given some assumptions to be discussed later.</p>
<p><a name="figure2"></a><img src="figure2.png" alt="Information graphical representation of DDCD.  The DDC process has two steps, as does the claimed origin/regeneration process.  At the end, the results of the two processes are compared."  width="636" height="295">
<br clear="left">
<font size="3"><i>Figure 2: Informal graphical representation of DDC</i></font></p>
<br clear="left">
<p>Figure 2 presents an informal, simplified graphical
representation of DDC, along with the claimed origin of the
compiler-under-test (this claimed original process can be
re-executed as a check for self-regeneration). The dashed line
labeled &#8220;compare&#8221; is a comparison for exact equality.
This figure uses the following symbols:</p>
<ul>
<li value="1">
<p>c<sub>A</sub>: Executable of the compiler-under-test, which may
be corrupt (maliciously corrupted compilers are by definition
corrupt).</p>
</li>
<li>
<p><i>s</i><sub>A</sub>: Purported source code of compiler
c<sub>A</sub>. Our goal is determine if c<sub>A</sub> and
<i>s</i><sub>A</sub> correspond.</p>
</li>
<li>
<p>c<sub>P</sub>: Executable of the compiler that is purported to
have generated c<sub>A</sub> (it is the purported
&#8220;parent&#8221; of c<sub>A</sub>).</p>
</li>
<li>
<p><i>s</i><sub>P</sub>: Purported source code of parent
c<sub>P</sub>. Often a variant/older version of
<i>s</i><sub>A</sub>.</p>
</li>
<li>
<p>c<sub>T</sub>: Executable of a &#8220;trusted&#8221; compiler,
which must be able to compile <i>s</i><sub>P</sub>.. The exact
meaning of &#8220;trusted&#8221; will be explained later.</p>
</li>
<li>
<p>1, 2, o1, o2: Stage identifiers. Each stage executes a
compiler.</p>
</li>
<li>
<p>stage1, stage2: The outputs of the DDC stages. Stage1 is a
function of c<sub>T</sub> and <i>s</i><sub>P</sub>, and can be
represented as c(<i>s</i><sub>P</sub>, c<sub>T</sub>) where
&#8220;c&#8221; means &#8220;compile&#8221;. Similarly, stage2 can
be represented as c(<i>s</i><sub>A</sub>, stage1) or
c(<i>s</i><sub>A</sub>, c(<i>s</i><sub>P</sub>,
c<sub>T</sub>)).</p>
</li>
</ul>
<p>The right-hand-side shows the process that purportedly generated
the compiler-under-test executable c<sub>A</sub> in the first
place. The right-hand-side shows the DDC process. The process
graphs are very similar, so it should not be surprising that the
results should be identical. This dissertation formally proves this
(given certain conditions) and demonstrates that this actually
occurs with real-world compilers.</p>
<p>Before performing DDC itself, it is wise to perform a
regeneration check, which checks to see if we can regenerate
c<sub>A</sub> using exactly the same process that was supposedly
used to create it originally<a class="sdfootnoteanc" name=
"sdfootnote8anc" href="#sdfootnote8sym"><sup>8</sup></a>. Since
c<sub>A</sub> was supposed to have been created this way in the
first place, regeneration should produce the same result. In
practice, the author has found that this is often not the case. For
example, many organizations&#8217; configuration control systems do
not record all the information necessary to accurately regenerate a
compiled executable, and the ability to perform regeneration is
necessary for the DDC process. In such cases, regeneration acts
like the control of an experiment; it detects when we do not have
proper control over all the relevant inputs or environment.
Corrupted compilers can also pass the regeneration test, so by
itself the regeneration test is not sufficient to reliably detect
corrupted compilers.</p>
<p>We then perform DDC by compiling twice. These two compilation
steps are the origin of this technique&#8217;s name: we compile
twice, the first time using a different (diverse) trusted compiler.
All compilation stages (stage 1 and stage 2, as well as the
regeneration test) could be performed on the same or on different
environments. Libraries can be handled in DDC by considering them
as part of the compiler (if they are executed in that stage) or
part of the source code (if they are used as input data but not
executed in that stage).</p>
<p>Note that the DDC technique uses a separate trusted compiler as
a check on the compiler-under-test. The trusting trust attack
assumes that all later generations of the compiler will be
descendants of a corrupted compiler; using a completely different
second compiler can invalidate this assumption. The trusted
compiler and its environment may be malicious, as long as that does
not impact their result during DDC, and they may be very slow.</p>
<p>The formalized DDC model, along with formalized assumptions and
its proof, are presented in chapter 5.</p>
<h2><a name="__RefHeading__35596484"></a><a name=
"4.3.Informal assumptions|outline"></a> 4.3 Informal
assumptions</h2>
<p>All approaches have assumptions. These will be formally and
completely stated later, but a brief statement of some key
assumptions should help in understanding the approach:</p>
<ul>
<li>
<p>DDC must be performed only by trusted programs and processes,
including a trusted compiler c<sub>T</sub>, trusted environment(s)
to run DDC, a trusted comparer, and trusted processes and tools to
acquire the compiler-under-test c<sub>A</sub> and the source code
<i>s</i><sub>P</sub> and <span lang="zxx"><i><span style=
"background: transparent">s</span></i></span><sub><span lang=
"zxx"><span style=
"background: transparent">A</span></span></sub>.</p>
<p>In this dissertation, something is &#8220;trusted&#8221; if we
have <i>justified confidence</i> that it does not have triggers and
payloads that would affect the results of DDC. A trusted program or
process may have triggers and payloads, as long as they do not
affect the result. A trusted program or process may have defects,
though as shown later, any defects that affect its result in DDC
are likely to be detected. Methods to increase the level of
confidence are discussed in chapter 6.</p>
</li>
<li>
<p>Compiler c<sub>T</sub> must have the same semantics for the same
constructs as required by <i>s</i><sub>P</sub>. For example, a
Java<sup>(TM)</sup> compiler cannot be used directly as
c<sub>T</sub> if <i>s</i><sub>P</sub> is written in the C language.
If <i>s</i><sub>P</sub> uses any nonstandard language extensions,
or depends on a construct not defined by a published language
specification, then c<sub>T</sub> must implement them in the way
required by <i>s</i><sub>P</sub>. Any defect in c<sub>T</sub> can
also cause problems if it affects compiling <i>s</i><sub>P</sub>
(otherwise it is irrelevant for DDC).</p>
</li>
<li>
<p>The compiler defined by <i>s</i><sub>P</sub> should be
deterministic given its inputs. That is, once compiled, and then
executed multiple times given the same inputs, it should produce
exactly the same outputs each time. If the compiler described by
<i>s</i><sub>P</sub> is non-deterministic, in some cases it could
be handled by running the process multiple times, but it is often
easier to control enough inputs to make the compiler deterministic.
Note that the regeneration process is helpful in detecting
undesired non-determinism.</p>
</li>
</ul>
<p>DDC does not determine if the source code is free of malicious
code; DDC can only show if source code corresponds to a given
executable. If the goal is to show that the compiler c<sub>A</sub>
is not malicious, then the source code (<i>s</i><sub>A</sub> and
<i>s</i><sub>P</sub>) must also be reviewed to determine that the
source code is not malicious. This is still an important
change&#8212;it is typically far easier to review source code than
to review executables. In some cases <i>s</i><sub>A</sub> and
<i>s</i><sub>P</sub> are extremely similar; in such cases they can
be simultaneously reviewed by reviewing one and then reviewing
their differences. There is also an important special
case&#8212;when
<i>s</i><sub>P</sub>=<i>s</i><sub>A</sub>&#8212;that is described
in section 4.5.</p>
<p>But first, we must clarify that DDC does <i>not</i> require
something that is unlikely.</p>
<h2 style="font-style: normal"><a name=
"4.4.DDC does not require that different compilers produce identical executables|outline">
</a> 4.4 DDC does not require that different compilers produce
identical executables</h2>
<p>DDC does <i>not</i> require that arbitrary <i>different</i>
compilers produce the same executable output, even given the same
input. Indeed, this would be extremely unlikely for source code the
size of typical compilers. Compiler executables c<sub>A</sub>,
c<sub>P</sub>, and c<sub>T</sub> might even run on or generate code
for different CPU architectures, making identical results extremely
unlikely.</p>
<p>Instead, DDC runs a different executable; under certain
conditions, this must produce the &#8220;same&#8221; result. This
is perhaps best explained by example. Imagine two properly-working
C compilers, both of which are given this source code to print the
result of calculating 2+2:</p>
<pre>
  #include &lt;stdio.h&gt;
  main() {
    printf("%d\n", 2+2);
  }
</pre>
<p>The executables produced by the two compilers are almost
certainly different, but <i>running</i> these two programs on their
respective environments must produce the same result for this line
(once converted into the same text encoding format). Obviously,
this depends on them implementing the same language (for the
purposes of the given Source).</p>
<p>The conditions where this occurs are defined more formally in
chapter 5. In particular, see section 5.7.9, where this is examined
in more detail.</p>
<h2><a name="__RefHeading__42335819"></a><a name=
"4.5.Special case: Self-parenting compiler|outline"></a> 4.5
Special case: Self-parenting compiler</h2>
<p>An important special case is when
<i>s</i><sub>P</sub>=<i>s</i><sub>A</sub>, that is, when the
putative source code of the parent compiler is the same as the
putative source code of the compiler-under-test. There are often
good reasons for releasing executables generated this way. For
example, a compiler typically includes many optimization
operations; each new version of a compiler may add new or improved
optimization operations. By releasing a self-parented compiler (a
compiler generated by setting
<i>s</i><sub>P</sub>=<i>s</i><sub>A</sub> and compiling twice), the
supplier would release a compiler executable that uses the latest
versions of those optimizations, giving the compiler itself maximum
performance. Many existing compilers (including as GCC) use the
compiler bootstrap test (essentially the self-regeneration check)
to test themselves, so a compiler&#8217;s build and test process
may already include an automated way to create a self-parenting
compiler. Figure 3 shows how figure 2 simplifies in this case.</p>
<p>Because this is a common case, the older paper [Wheeler2005]
only considered this case. In contrast, this dissertation considers
the more general case, subsuming self-parenting as a special
case.</p>
<p><a name="figure3"></a><img src="figure3.png" alt="Informal graphical representation of DDC for self-regeneration case." width="635" height="296">
<br clear="left">
<font size="3"><i>Figure 3: Informal graphical representation of
DDC for self-regeneration case</i></font></p>
<p>Having a self-parenting compiler can simplify the application of
DDC. As discussed in more detail below, DDC only shows that source
code and executable correspond, so review of compiler source code
is still required if the goal is to show that there is no malicious
code in an executable. In the general case, both
<i>s</i><sub>A</sub> and <i>s</i><sub>P</sub> must be reviewed.
Since <i>s</i><sub>A</sub>=<i>s</i><sub>P</sub> in a self-parented
compiler, reviewing both <i>s</i><sub>A</sub> and
<i>s</i><sub>P</sub> can be done by reviewing just
<i>s</i><sub>A</sub>, simplifying the use of DDC. Also, when a
compiler is its own parent, a simplified regeneration check may be
used to detect many problems without performing the complete
regeneration test. This test, which can be termed
&#8220;self-regeneration&#8221;, simply uses c<sub>A</sub> to
compile its putative source code <i>s</i><sub>A</sub>; the
regeneration is successful if the generated executable is the same
as the original c<sub>A</sub>.</p>
<p>It is still useful to be able to handle the general case.
Compiler c<sub>P</sub> need not be a radically different compiler;
it might simply be an older version of c<sub>A</sub>, differ only
in its use of different compilation flags, or differ only in that
it embeds a different version of a library executable.
Nevertheless, if c<sub>P</sub> and c<sub>A</sub> are different, the
general form of DDC must be used. Also, it is possible to have a
&#8220;loop&#8221; of compilers that mutually depend on each other
for self-regeneration (e.g., a Java compiler written in C and a C
compiler written in Java might be generated using each other). In
this case, the more general form of DDC is needed to break the
loop.</p>
<h2><a name=
"4.6.Why not always use the trusted compiler_|outline"></a> 4.6 Why
not always use the trusted compiler?</h2>
<p>DDC uses a second &#8220;trusted&#8221; compiler c<sub>T</sub>,
which is trusted in the sense that we have a justified confidence
that c<sub>T</sub> does not have triggers or payloads that affect
recompiling <i>s</i><sub>P</sub> and <i>s</i><sub>A</sub> (see
section 4.3). We can now answer an obvious question: Why not
<i>always</i> use the trusted compiler c<sub>T</sub>?</p>
<p>First, there are many reasons compiler c<sub>T</sub> might not
be suitable for general use. For example, compiler c<sub>T</sub>
may be slow, produce slow code, generate code for a different CPU
architecture than desired, be costly, or have undesirable software
license restrictions. It may lack many useful functions necessary
for general-purpose use (in DDC, trusted compiler c<sub>T</sub>
only needs to be able to compile <i>s</i><sub>P</sub>). It is
possible that the only purpose of the trusted compiler is to
operate as a trusted checker for the more widely-used compiler, in
fact, there are good reasons to do so. It is much easier to verify
(and possibly formally prove) a simple compiler that has limited
functionality and few optimizations; such compilers might not be
suitable for general production use, but would be ideal as trusted
compilers used to check production compilers. The trusted compiler
could even be a &#8220;secret&#8221; compiler that is never
publicly released (as source, executable, or a service); an
attacker would find it extremely difficult to avoid detection by
DDC if such a trusted compiler were used.</p>
<p>Second, using a different trusted compiler c<sub>T</sub> greatly
increases the confidence that the compiler executable c<sub>A</sub>
corresponds with source code <i>s</i><sub>A</sub>. When a second
compiler c<sub>T</sub> is used as part of DDC, an attacker must
subvert <i>multiple</i> executables and executable-generation
processes to perform the &#8220;trusting trust&#8221; attack
without detection. It is true that the trusted compiler
c<sub>T</sub> could be used as a &#8220;trusted bootstrap&#8221;
compiler that would always be used to generate each new version of
c<sub>A</sub>. This could be done even if c<sub>T</sub> is not
suitable for general use. However, if we always generate updated
versions of c<sub>A</sub> this way, and never use DDC, we have
merely moved the trusting trust attack to a different location: We
must now perfectly protect c<sub>T</sub> and the bootstrap process
used to create each new version of c<sub>A</sub>. Should the
protection of c<sub>T</sub> ever fail, an attacker might change
c<sub>T</sub> into a maliciously corrupted compiler
c<sub>T</sub>&#180;, resulting in the potential corruption of
future versions of c<sub>A</sub>. By using DDC with a different
trusted compiler c<sub>T</sub>, c<sub>T</sub> is used as a separate
check, requiring an attacker to subvert <i>two</i> different
compilers and compiler-generation processes to avoid detection.
Indeed, DDC could be performed multiple times using different
compilers as c<sub>T</sub> and/or different environments, requiring
an attacker to subvert <i>all</i> of the DDC processes to avoid
detection. Using DDC with a different compiler c<sub>T</sub>
greatly increases the confidence that c<sub>A</sub> exactly
corresponds with <i>s</i><sub>A</sub>; using DDC multiple times can
increase that confidence still further.</p>
<h2><a name="__RefHeading__38682321"></a><a name=
"4.7.Why is DDC different from N-version programming_|outline"></a>
4.7 Why is DDC different from N-version programming?</h2>
<p>N-version programming &#8220;has been proposed as a method of
incorporating fault tolerance into software. Multiple versions of a
program (i.e., &#8216;N&#8217;) are prepared and executed in
parallel. Their outputs are collected and examined by a voter, and,
if they are not identical, it is assumed that the majority is
correct. This method [assumes] that programs that have been
developed independently will fail independently&#8221;
[Knight1986].</p>
<p>John Knight and Nancy Leveson performed an experiment with
N-version programming and showed that, in their experiment,
&#8220;the assumption of independence of errors that is fundamental
to some analyses of N-version programming does not hold&#8221;
[Knight1986] [Knight1990]. Instead, they found that if one program
has a failure when processing a particular input, there was an
increased likelihood of failure (compared to random failure) for
another program with the same input, given that both programs were
written to the same specification. This is an important result. It
is not hard to see why this might be true; for example, if certain
areas of the specification are unusually complex, two different
programmers might both fail to meet it. However, this result does
not invalidate DDC, because the circumstances in DDC are very
different from this and similar experiments.</p>
<p>In the Knight and Leveson work, N different programs were
developed by different developers attempting to implement the
<i>same</i> specification. In contrast, the purpose of applying DDC
is to detect when two different compiler executables have been
developed to implement <i>different</i> specifications, that is,
when one program is written to attempt to compile source code
accurately, while another program is written to produce corrupted
results in certain cases. However:</p>
<ul>
<li>
<p>These changes are <i>extremely</i> <i>unlikely</i> to happen
<i>unintentionally</i> (and in the same way) in both the trusted
compiler and the original process used to create the
compiler-under-test. Creating a corrupting compiler that is
self-perpetuating and selectively corrupts other programs requires
clever programming [Thompson1984] and significantly changes the
compiler executable (for an example, see the differences shown in
section A.5).</p>
</li>
<li>
<p>These changes are <i>extremely</i> <i>unlikely</i> to happen
<i>intentionally</i> in the trusted compiler and DDC process in
general. This is by definition of the term
&#8220;trusted&#8221;&#8212;we have justified confidence that the
DDC process (including the trusted compiler) is unlikely to have
triggers or payloads that affect DDC results.</p>
</li>
<li>
<p>Since the kind of differences that motivate DDC are extremely
unlikely to occur unintentionally <i>or</i> intentionally, the
entire scenario is extremely unlikely.</p>
</li>
</ul>
<p>Also, in the Knight and Leveson experiment, the issue was to
determine if the different programs would produce identical results
across all permitted inputs to the different programs. Their
experiment simulated use of the N programs using one million test
inputs, corresponding to about twenty years of operational use
&#8220;if the program is executed once per second and unusual
events occur every ten minutes&#8221;. In contrast, in DDC, there
is only <i>one</i> relevant input: the source code pair
<i>s</i><sub>P</sub> and <i>s</i><sub>A</sub>. Granted, these
inputs will have a complex internal structure, but these are the
<i>only</i> inputs that matter, as compared to the wide range of
possible inputs a compiler might accept. Thus, in DDC we do
<i>not</i> have the situation where there is a wide variety of
potential test inputs; we have only one pair of inputs, and they
are the only ones that matter.</p>
<p>There is a special case where the Knight and Leveson results
<i>do</i> directly apply to DDC. This is when the original compiler
and trusted compiler <i>both</i> fail to correctly compile the
source code (<i>s</i><sub>P</sub> and <i>s</i><sub>A</sub>),
<i>and</i> this failure happens to produce the same results. DDC
will not detect that both compilers are performing incorrectly in
the same way. The Knight and Leveson paper shows that such program
failures are not completely statistically independent, and thus
this kind of failure is somewhat more likely than an independence
model would predict. However, there are several reasons to believe
that this special case is rare for mature compilers. First, mature
compilers typically pass a large test suite, reducing the risk of
such defects. Second, compilers are usually part of their own test
suite, reducing the likelihood that a compiler will fail to
correctly compile itself. Third, section 7.1.3demonstrates that
even when a compiler fails to correctly compile itself, DDC may
still detect it. But all of this is beside the point. Since the
purpose of applying DDC is to detect intentional self-perpetuating
attacks, and not to prove total correctness, this special case does
not invalidate the use of DDC to detect and counter the
&#8220;trusting trust&#8221; attack.</p>
<p>Thus, the Knight and Leveson results do not invalidate DDC for
the purpose of detecting and countering the &#8220;trusting
trust&#8221; attack.</p>
<h2><a name=
"4.8.DDC works with randomly-corrupting compilers|outline"></a> 4.8
DDC works with randomly-corrupting compilers</h2>
<p>DDC works even if an ancestor of c<sub>A</sub> randomly corrupts
its results. If the compiler-under-test was not corrupted, DDC will
correctly report this; otherwise, DDC will expose the
corruption.</p>
<h1><a name="__RefHeading__34426845"></a><a name=
"5.Formal proof|outline"></a> 5 Formal proof</h1>
<p>This chapter presents a formal proof of DDC. The first section
presents a more complete graphical model of both the DDC process
and how the compiler-under-test is claimed to have been created.
This is followed by a description of the formal notation used
(first-order logic (FOL) with equality), the rationales used in
proof steps (aka the derivation rules or rules of inference), the
tools used, and various proof conventions. After this, the three
key proofs are presented. Each proof presents a set of predicates,
functions, and assumptions about DDC in the formal notation, and
shows how they lead to the concluding proof goal. The three proofs
are:</p>
<ul>
<li>
<p>Proof #1, goal source_corresponds_to_executable: This is the key
proof for DDC. It shows that given certain assumptions, if stage2
(the result of the DDC process) and c<sub>A</sub> (the original
compiler-under-test) are equal, then the executable c<sub>A</sub>
and the source code <i>s</i><sub>A</sub> exactly correspond.</p>
</li>
<li>
<p>Proof #2, goal always_equal: This proves that, under
&#8220;normal conditions&#8221; (such as when compiler executables
have not been rigged and thus <i>do</i> correspond to their
respective source code), c<sub>A</sub> and stage2 are in fact
always equal. Thus, the first proof is actually useful, because its
assumptions will often hold. This also implies that if
c<sub>A</sub> and stage2 are <i>not</i> equal, then at least one of
its assumptions is <i>not</i> true.</p>
</li>
<li>
<p>Proof #3, goal cP_corresponds_to_sP: The previous
&#8220;always_equal&#8221; proof does not require that a
&#8220;grandparent&#8221; compiler exist, but having one is a
common circumstance. This third proof shows that if there <i>is</i>
a grandparent compiler, one of the assumptions of proof #2 can be
proved given other assumptions that may be easier to verify
(potentially making DDC even easier to apply in this common
case).</p>
</li>
</ul>
<h2><a name="5.1.Graphical model for formal proof |outline"></a>
5.1 Graphical model for formal proof</h2>
<p>Figure 4 graphically represents the DDC stages and how the
compiler-under-test c<sub>A</sub> was putatively created. This is a
more rigorous version of figure 2; the formal model includes more
detail to accurately model potentially-different compilation
environments and the effects these environments have on the
compilation processes.</p>
<p><a name="figure4"></a><img src="figure4.png" alt="Graphical representation of DDC formal model.  This diagram adds more detail, e.g. there are possibly many environments, compilation processes can receive as input effects from the environments, and the source languages are written in specific languages." width="636" height="295">
<br clear="left">
<font size="3"><i>Figure 4: Graphical representation of DDC formal
model</i></font></p>
<p>This dissertation argues that if the DDC process produces a
&#8220;stage2&#8221; that is identical to the c<sub>A</sub>, and
certain other assumptions are true, then the executable stage2
corresponds to the source code <i>s</i><sub>A</sub>. The similarity
of the DDC process and claimed origin figures suggest that this
might be reasonable, but the challenge is to formalize exactly what
those assumptions are, and then prove that this is true from those
assumptions.</p>
<h3><a name="__RefHeading__41356039"></a><a name=
"5.1.1.Types|outline"></a> 5.1.1 Types</h3>
<p>Although types (sorts) are not directly used in the proof, it is
easier to explain the graph and proofs by assigning types to the
various constants used. There are four basic types:</p>
<ul>
<li>
<p><i>Data:</i> For our purposes, data is information that is used
as source code (input) and/or is the resulting executable (output)
of a compilation. Some of the data could be both source and
executable (e.g., a library object file could be executed during
compilation and also copied into the final executable). Thus, as
implied by its definition, data can be either (or both):</p>
<ul>
<li>
<p><i>Executable:</i> Data that can be executed by a computing
environment. Compilers produce executables, and compilers
themselves are executables.</p>
</li>
<li>
<p><i>Source</i>: Data that can be compiled by a compiler to
produce an executable. Any source (aka source code) is written in
some language.</p>
</li>
</ul>
</li>
<li>
<p><i>Environment:</i> A platform that can run executables. This
would include the computer hardware (including the central
processing unit) and any software that supports or could influence
the compiler&#8217;s result (e.g., the operating system). It could
include a byte code interpreter or machine simulator.</p>
</li>
<li>
<p><i>Language</i>: The language, used by some source, that defines
the meaning of the source.</p>
</li>
<li>
<p><i>Effects:</i> All information or execution timing arising from
the environment that can affect the results of a compilation, but
is not part of the input source code. This is used to model random
number generators, thread execution ordering, differences between
platforms allowed by the language, and so on. Note that this is not
simply data in the usual sense, since other issues such as thread
execution ordering are included as effects.</p>
</li>
</ul>
<h3><a name="5.1.2.DDC components|outline"></a>5.1.2 DDC
components</h3>
<p>The DDC process, as shown in figure 4, includes the following
components, with the following types and meanings:</p>
<ul>
<li value="1">
<p>c<sub>T</sub>: Executable. The trusted compiler. It is trusted
in the sense that it is trusted to not have triggers or payloads
that will activate when compiling source <i>s</i><sub>P</sub>.</p>
</li>
<li>
<p><i>s</i><sub>P</sub>: Source. The (putative) source code of the
&#8220;parent&#8221; compiler.</p>
</li>
<li>
<p><i>s</i><sub>A</sub>: Source. The (putative) source code of the
compiler-under-test (c<sub>A</sub>).</p>
</li>
<li>
<p>e1: Environment. The environment that executes compilation step
1, which uses c<sub>T</sub> to compile <i>s</i><sub>P</sub> and
produce stage1.</p>
</li>
<li>
<p>e2: Environment: The environment that executes compilation step
2, which uses stage1 to compile <i>s</i><sub>A</sub> and produce
stage2.</p>
</li>
<li>
<p>eArun: Environment: The environment that stage2 is intended to
run on.</p>
</li>
<li>
<p>lsP, lsA: Language. The languages used by source
<i>s</i><sub>P</sub>. and <i>s</i><sub>A</sub>, respectively.</p>
</li>
<li>
<p>e1effects: Effects. The effects sent from environment e1 to
compilation step 1.</p>
</li>
<li>
<p>e2effects: Effects. The effects sent from environment e2 to
compilation step 2.</p>
</li>
<li>
<p>stage1: Executable. The result of DDC compilation step 1. This
will be defined, using the functional notation below, as
compile(<i>s</i><sub>P</sub>, c<sub>T</sub>, e1effects, e1,
e2).</p>
</li>
<li>
<p>stage2: Executable. The result of DDC compilation step 2. This
will be defined as compile(<i>s</i><sub>A</sub>, stage1, e2effects,
e2, eArun).</p>
</li>
</ul>
<p>Note that <i>s</i><sub>A</sub> may be equal to
<i>s</i><sub>P</sub>, e1 may be equal to e2 or eArun, e2 may be
equal to eArun, and lsA may be equal to lsP. These identities are
permitted but not required by DDC. All processes (including the
compilations and their underlying environments, the process for
acquiring c<sub>A</sub>, and the process for comparing
c<sub>A</sub> and stage2) must be trusted (i.e., they must not have
triggers or payloads that affect their operation during DDC).</p>
<h3><a name="5.1.3.Claimed origin|outline"></a>5.1.3 Claimed
origin</h3>
<p>The compiler-under-test c<sub>A</sub> was putatively developed
by a similar process. This &#8220;claimed origin&#8221; process can
also be modeled, with the following components not already
described in the DDC process:</p>
<ul>
<li value="1">
<p>c<sub>GP</sub>: Executable. The grandparent compiler, if there
is one.</p>
</li>
<li>
<p>eP: Environment. The environment that executes compilation step
o1, which uses c<sub>GP</sub> to compile source
<i>s</i><sub>P</sub> and produce executable c<sub>P</sub>.</p>
</li>
<li>
<p>eA: Environment: The environment that executes compilation step
o2, which uses c<sub>P</sub> to compile <i>s</i><sub>A</sub> and
produce c<sub>A</sub>.</p>
</li>
<li>
<p>ePeffects: Effects. The effects sent from e<sub>P</sub> to
compilation step o1.</p>
</li>
<li>
<p>eAeffects: Effects. The effects sent from e<sub>A</sub> to
compilation step o2.</p>
</li>
<li>
<p>c<sub>P</sub>: Executable. Putative parent compiler.</p>
</li>
<li>
<p>c<sub>A</sub>: Executable. The compiler-under-test, which
putatively was developed by the process above.</p>
</li>
</ul>
<p>Note that compiler-under-test c<sub>A</sub> may, in fact, be
different than if it were really generated through this process.
But if c<sub>A</sub> <i>was</i> generated through this process, we
can prove that certain outcomes will result, given certain
assumptions, as described below.</p>
<h2><a name="__RefHeading__41321302"></a><a name=
"5.2.Formal notation: First-Order Logic (FOL)|outline"></a> 5.2
Formal notation: First-Order Logic (FOL)</h2>
<p>The formal logic used in this dissertation is classical
first-order logic (FOL) with equality, aka first-order predicate
logic. FOL was selected because it is a widely understood and
accepted formal logic system<a class="sdfootnoteanc" name=
"sdfootnote9anc" href="#sdfootnote9sym"><sup>9</sup></a>. This
dissertation uses the FOL notation and conventions defined in
[Huth2004, 93-139]. In FOL, every expression is a <i>term</i> or a
<i>formula</i>.</p>
<p>A <i>term</i> (which denotes an object) is defined as: a
variable, a constant, or a function application of form <img src=
"wheeler-trusting-trust-ddc_html_1bc6c8dc.gif" alt="f(&tau;1, &tau;2, ..., &tau;n)" align="absmiddle" width="104" height="20"> where each of the zero
or more comma-separated parameters is a term. In this dissertation,
variables begin with an uppercase letter, while constants begin
with a lowercase letter (this is the same convention used by
Prolog).</p>
<p>A <i>formula</i> (which denotes a truth value) is defined as:
<img src="wheeler-trusting-trust-ddc_html_4bbe38d9.gif" alt="&not;&Phi;"
align="absmiddle" width="22" height="18">, <img src=
"wheeler-trusting-trust-ddc_html_6786aa9c.gif" alt="&Phi;&rArr;&Psi;" align="absmiddle" width="37" height="18">, <img src=
"wheeler-trusting-trust-ddc_html_4e30f7ad.gif" alt="&Phi;&or;&Psi;" align="absmiddle" width="37" height="18">, <img src=
"wheeler-trusting-trust-ddc_html_m73eba5cc.gif" alt="&Phi;&rArr;&Psi;" align="absmiddle" width="41" height="18">, <img src=
"wheeler-trusting-trust-ddc_html_m2a5c3e44.gif" alt="&forall;&Chi;&Phi;" align="absmiddle" width="39" height="18">&#8288;, <img src=
"wheeler-trusting-trust-ddc_html_6f9b519c.gif" alt="&tau;1=&tau;2" align="absmiddle" width="42" height="20">&#8288;, <img src=
"wheeler-trusting-trust-ddc_html_m7df06018.gif" alt="&tau;1&ne;&tau;2" align="absmiddle" width="42" height="20">&#8288;, or a predicate of
form <img src="wheeler-trusting-trust-ddc_html_m6c3cbfe1.gif" alt="p(&tau;1, &tau;2, ..., &tau;n)" align="absmiddle" width="103" height="20"> where each of
the one or more comma-separated parameters is a term. This
definition requires that <img src=
"wheeler-trusting-trust-ddc_html_4072c6c2.gif" alt="&Phi;"
align="absmiddle" width="11" height="18"> and <img src=
"wheeler-trusting-trust-ddc_html_m5f31e6e0.gif" alt="&Psi;" align="absmiddle" width="13" height="18"> are formulas, <img src=
"wheeler-trusting-trust-ddc_html_m66be899f.gif" alt="&Chi;" align="absmiddle" width="10" height="18"> is an unbound variable,
and anything beginning with <img src=
"wheeler-trusting-trust-ddc_html_1a44bfe9.gif" alt="&tau;" align="absmiddle" width="9" height="18"> is a term.</p>
<p>In some sense, a formula is a boolean expression that represents
true or false, while a term represents any non-boolean type.
Functions and predicates have the same syntax if they have any
parameters. Table 1 shows the traditional FOL notation for FOL
expressions (terms and formulas), an equivalent American Standard
Code for Information Interchange (ASCII) representation, and a
summary of its meaning<a class="sdfootnoteanc" name=
"sdfootnote10anc" href="#sdfootnote10sym"><sup>10</sup></a>:</p>
<p><a name="table1"></a><font size="3"><i>Table 1: FOL
notation</i></font></p>
<table width="100%" border="1" bordercolor="#000000" cellpadding=
"4" cellspacing="0" style="page-break-inside: avoid">
<col width="38*">
<col width="53*">
<col width="165*">
<tr valign="top">
<th width="15%" bgcolor="#C0C0C0">
<p>Traditional Notation</p>
</th>
<th width="21%" bgcolor="#C0C0C0">
<p>ASCII Representation</p>
</th>
<th width="64%" bgcolor="#C0C0C0">
<p>Meaning</p>
</th>
</tr>
<tr valign="top">
<td width="15%">
<p><img src="wheeler-trusting-trust-ddc_html_4bbe38d9.gif" alt="&not;&Phi;"
align="absmiddle" width="22" height="18"></p>
</td>
<td width="21%">
<p>- PHI</p>
</td>
<td width="64%">
<p><i>not</i> <i><img src=
"wheeler-trusting-trust-ddc_html_4072c6c2.gif" alt="&Phi;"
align="absmiddle" width="11" height="18"></i>, aka negation. If
<i><img src="wheeler-trusting-trust-ddc_html_4072c6c2.gif" alt="&Phi;"
align="absmiddle" width="11" height="18"></i> is true,
<img src="wheeler-trusting-trust-ddc_html_4bbe38d9.gif" alt="&not;&Phi;"
align="absmiddle" width="22" height="18"> is false; if
<i><img src="wheeler-trusting-trust-ddc_html_4072c6c2.gif" alt="&Phi;"
align="absmiddle" width="11" height="18"></i> is false,
<img src="wheeler-trusting-trust-ddc_html_4bbe38d9.gif" alt="&not;&Phi;"
align="absmiddle" width="22" height="18"> is true.
<img src="wheeler-trusting-trust-ddc_html_2e4598d8.gif" alt="&not;&not;&Phi;" align="absmiddle" width="32" height="18"> is equivalent
to <i><img src="wheeler-trusting-trust-ddc_html_4072c6c2.gif" alt="&Phi;"
align="absmiddle" width="11" height=
"18"></i><i>.</i></p>
</td>
</tr>
<tr valign="top">
<td width="15%">
<p><img src="wheeler-trusting-trust-ddc_html_6786aa9c.gif" alt="&Phi;&rArr;&Psi;" align="absmiddle" width="37" height="18"></p>
</td>
<td width="21%">
<p>PHI &amp; PSI</p>
</td>
<td width="64%">
<p><i>&#934;</i> <i>and</i> <i>&#936;</i>, aka conjunction, aka
&#8220;logical and&#8221;. Both <i>&#934;</i> and <i>&#936;</i>
must be true for the expression to be true.</p>
</td>
</tr>
<tr valign="top">
<td width="15%">
<p><img src="wheeler-trusting-trust-ddc_html_4e30f7ad.gif" alt="&Phi;&or;&Psi;" align="absmiddle" width="37" height="18"></p>
</td>
<td width="21%">
<p>PHI | PSI</p>
</td>
<td width="64%">
<p><i>&#934;</i> <i>or</i> <i>&#936;</i>, aka disjunction, aka
&#8220;logical inclusive or&#8221;. <i>&#934;</i>, <i>&#936;</i>,
or both must be true for the expression to be true.</p>
</td>
</tr>
<tr valign="top">
<td width="15%">
<p><img src="wheeler-trusting-trust-ddc_html_m73eba5cc.gif" alt="&Phi;&rArr;&Psi;" align="absmiddle" width="41" height="18"></p>
</td>
<td width="21%">
<p>PHI -&gt; PSI</p>
</td>
<td width="64%">
<p><i>&#934;</i> <i>implies</i> <i>&#936;</i>, aka implication,
entailment, or &#8220;if <i>&#934;</i>, then <i>&#936;</i>&#8221;.
Equivalent to <img src=
"wheeler-trusting-trust-ddc_html_4ebdd76f.gif" alt="(&not;&Phi;)&or;&Psi;" align="absmiddle" width="59" height="18">.</p>
</td>
</tr>
<tr valign="top">
<td width="15%">
<p><img src="wheeler-trusting-trust-ddc_html_m2a5c3e44.gif" alt="&forall;&Chi;&Phi;" align="absmiddle" width="39" height="18"></p>
</td>
<td width="21%">
<p>all Chi PHI</p>
</td>
<td width="64%">
<p><i>For-all</i>, aka universal quantification. For all values of
variable <img src="wheeler-trusting-trust-ddc_html_m52fb9d92.gif" alt="&Chi;, &Phi;" align="absmiddle" width="28" height="18"> is true.
In this dissertation, this is optional; all unbound variables are
universally quantified.</p>
</td>
</tr>
<tr valign="top">
<td width="15%">
<p><img src="wheeler-trusting-trust-ddc_html_6f9b519c.gif" alt="&tau;1=&tau;2" align="absmiddle" width="42" height="20"></p>
</td>
<td width="21%">
<p>tau_1 = tau_2</p>
</td>
<td width="64%">
<p><i>&#964;</i><sub><i>1</i></sub> <i>equals</i>
<i>&#964;</i><sub><i>2</i></sub>. If true, &#964;<sub>2</sub> can
substitute for &#964;<sub>1</sub>.</p>
</td>
</tr>
<tr valign="top">
<td width="15%">
<p><img src="wheeler-trusting-trust-ddc_html_m7df06018.gif" alt="&tau;1&ne;&tau;2" align="absmiddle" width="42" height="20"></p>
</td>
<td width="21%">
<p>tau_1 != tau_2</p>
</td>
<td width="64%">
<p><i>&#964;</i><sub><i>1</i></sub> <i>is not equal to</i>
<i>&#964;</i><sub><i>2</i></sub>. Equivalent to <img src=
"wheeler-trusting-trust-ddc_html_3089daf3.gif" alt="&tau;1&ne;&tau;2" align="absmiddle" width="59" height="18">.</p>
</td>
</tr>
<tr valign="top">
<td width="15%">
<p><img src="wheeler-trusting-trust-ddc_html_7d090b06.gif" alt="x(&tau;1,&nbsp;&tau;2,&nbsp;...&tau;n)" align="absmiddle" width="65" height="41"></p>
</td>
<td width="21%">
<p>x(tau_1, tau_2, ..., tau_n)</p>
</td>
<td width="64%">
<p><i>Function or predicate x</i> with terms <img src=
"wheeler-trusting-trust-ddc_html_e3859b6.gif" alt="&tau;1,&nbsp;&tau;2,&nbsp;...&nbsp;&tau;n" align="absmiddle" width="79" height="20">. A predicate is like a
function that returns a boolean.</p>
</td>
</tr>
</table>
<p>Parentheses are used to indicate precedence. FOL also has a
&#8220;there exists&#8221; notation (using <img src=
"wheeler-trusting-trust-ddc_html_m89dec75.gif" alt="&exist;" align="absmiddle" width="11" height="18">) which is not directly
used in this dissertation. A formula is either true or false (this
is the principle of the excluded middle); thus, <img src=
"wheeler-trusting-trust-ddc_html_47170087.gif" alt="&Phi;&or;&not;&Phi;" align="absmiddle" width="46" height="18"> is true for any formula
<img src="wheeler-trusting-trust-ddc_html_4072c6c2.gif" alt="&Phi;"
align="absmiddle" width="11" height="18">. In this
dissertation, a top-level FOL formula is terminated by a
terminating period (&#8220;.&#8221;).</p>
<p>For example, the following FOL formula could represent
&#8220;all men are mortal&#8221;:</p>
<pre>
   man(X) -&gt; mortal(X).
</pre>
<p>This formula can be read as &#8220;for all values of X, if X is
a man, then X is mortal&#8221;. Note that &#8220;X&#8221; is a
variable, not a constant, because it begins with a capital letter.
Also note that since X is not bound, an implied &#8220;all X
...&#8221; surrounds the entire formula.</p>
<p>In addition, the following formula could be used to represent
&#8220;Socrates is a man&#8221;:</p>
<pre>
   man(socrates).
</pre>
<p>From these two formulas, it can be determined that
&#8220;Socrates is mortal&#8221;:</p>
<pre>
   mortal(socrates).
</pre>
<p>FOL is a widely-used general notation, and not designed for
proofs about specific fields (such as compilation). Thus, as with
most uses of FOL, additional &#8220;non-logical&#8221; symbols must
be added before particular problems can be analyzed. In this
dissertation, these additions are the various constant terms in the
graphical model described in 5.1 (above), as well as various
predicates and functions that will be defined below. The proofs
below will introduce these predicates and functions, as well as
various assumptions, and then show that certain important
conclusions (termed &#8220;goals&#8221;) can be formally proved
from them. Some assumptions define a term, predicate, or function;
these assumptions are also called &#8220;definitions&#8221; in this
dissertation.</p>
<p>All formal models, including the one in this dissertation, must
include lowest-level items (such as predicates, functions, and
constants) that are not defined in the formal model itself.
Therefore, it is unreasonable to protest that these lowest-level
items are not defined in this model, since that is necessarily
true. The key is that the lowest-level items should accurately
model the real world, thus forming a rational basis for proving
something about the real world.</p>
<h2 style="font-style: normal"><a name=
"__RefHeading__34163183"></a><a name=
"5.3.Proof step rationales (derivation rules or rules of inference)|outline"></a>
5.3 Proof step rationales (derivation rules or rules of
inference)</h2>
<p>Every step in each formal proof must have a rationale (aka a
derivation rule or rule of inference). In this dissertation, only
the following rationales are permitted in the formal proofs (for
clarity, the terminating &#8220;.&#8221; in top-level formulas is
omitted in this list):</p>
<ul>
<li value="1">
<p><i><b>Assumption</b></i>: Given assumption. All definitions are
assumptions.</p>
</li>
<li>
<p><i><b>Goal</b></i>: The given goal to be proved.</p>
</li>
<li>
<p><i><b>Clausify</b></i>: Transform a previous step (formula) into
a normalized clausal form. In particular, all expressions of the
form <img src="wheeler-trusting-trust-ddc_html_m73eba5cc.gif" alt="&Phi;&rArr;&Psi;" align="absmiddle" width="41" height="18"> are
transformed into <img src=
"wheeler-trusting-trust-ddc_html_4ebdd76f.gif" alt="(&not;&Phi;)&or;&Psi;" align="absmiddle" width="59" height="18">. For example, using the
example in section 5.2, &#8220;man(X) &nbsp;&gt; mortal(X)&#8221;
can be transformed into &#8220;&nbsp;man(X) | mortal(X)&#8221;. See
[McCune2008] and [Duffy1991] for a detailed description.</p>
</li>
<li>
<p><i><b>Copy...flip</b></i>: Copy a previous result but reverse
the order of an equality statement. Thus, given <img src=
"wheeler-trusting-trust-ddc_html_f71bbaf.gif" alt="&Phi;=&Psi;" align="absmiddle" width="37" height="18">, this rationale can
produce <img src="wheeler-trusting-trust-ddc_html_m43e8c081.gif" alt="&Psi;=&Phi;" align="absmiddle" width="38" height="18">.</p>
</li>
<li>
<p><i><b>Deny</b></i>: Negate a previous step; this processes the
goal statement. All formal proofs in this chapter are proofs by
contradiction; the goal is negated by the &#8220;Deny&#8221; rule,
and the rest of the proof shows that this leads to a
contradiction.</p>
</li>
<li>
<p><i><b>Resolve</b></i>: Resolution (aka general resolution), that
is, produce a resolvant from two clauses. Resolution is a
generalized version of ground (propositional) resolution, so to
explain resolution, we will first explain ground resolution.</p>
<p>Ground resolution is a derivation rule that applies to clauses
in propositional logic (a simpler logic than FOL that lacks terms,
predicates, functions, quantification (for-all and there-exists),
and equality; variables are true or false). Ground resolution
requires two ground clauses (formulas) which can be reordered into
the forms <img src="wheeler-trusting-trust-ddc_html_m6e2a86b6.gif" alt="&Lambda;&or;&Phi;" align="absmiddle" width="38" height="18"> and
<img src="wheeler-trusting-trust-ddc_html_6b46faea.gif" alt="&Lambda;'&or;&Psi;" align="absmiddle" width="48" height="18">&#8288;, where
<img src="wheeler-trusting-trust-ddc_html_m3b7e858f.gif" alt="&Lambda;'" align="absmiddle" width="20" height="18"> is a
complement (negation) of formula <img src=
"wheeler-trusting-trust-ddc_html_15640894.gif" alt="&Lambda;" align="absmiddle" width="13" height="18">, and where <img src=
"wheeler-trusting-trust-ddc_html_4072c6c2.gif" alt="&Phi;"
align="absmiddle" width="11" height="18">, <img src=
"wheeler-trusting-trust-ddc_html_m5f31e6e0.gif" alt="&Psi;" align="absmiddle" width="13" height="18">, or both may be empty.
From that, ground resolution can derive <img src=
"wheeler-trusting-trust-ddc_html_m2951f716.gif" alt="&Phi;&or;&Psi;" align="absmiddle" width="45" height="18"> removing any duplicates
(this can be informally viewed as combining the two clauses with
<img src="wheeler-trusting-trust-ddc_html_15640894.gif" alt="&Lambda;" align="absmiddle" width="13" height="18"> and <img src=
"wheeler-trusting-trust-ddc_html_m3b7e858f.gif" alt="&Lambda;'" align="absmiddle" width="20" height="18"> &#8220;canceling&#8221;
each other). If both <img src=
"wheeler-trusting-trust-ddc_html_4072c6c2.gif" alt="&Phi;"
align="absmiddle" width="11" height="18"> and <img src=
"wheeler-trusting-trust-ddc_html_m5f31e6e0.gif" alt="&Psi;" align="absmiddle" width="13" height="18"> are empty, the empty
clause (false) is derived. For example, given both <img src=
"wheeler-trusting-trust-ddc_html_6b4d1fc0.gif" alt="P&or;Q" align="absmiddle" width="37" height="18"> and <img src=
"wheeler-trusting-trust-ddc_html_m61992505.gif" alt="&not;P&or;R" align="absmiddle" width="47" height="18">, ground resolution can
derive <img src="wheeler-trusting-trust-ddc_html_m7f0a06d1.gif" alt="Q&or;R" align="absmiddle" width="37" height="18">. Ground
resolution is a sound rule for reasoning because any formula
<img src="wheeler-trusting-trust-ddc_html_15640894.gif" alt="&Lambda;" align="absmiddle" width="13" height="18"> must be either
true or false: If <img src=
"wheeler-trusting-trust-ddc_html_15640894.gif" alt="&Lambda;" align="absmiddle" width="13" height="18"> is false, and <img src=
"wheeler-trusting-trust-ddc_html_m6e2a86b6.gif" alt="&Lambda;&or;&Phi;" align="absmiddle" width="38" height="18"> is true, then <img src=
"wheeler-trusting-trust-ddc_html_4072c6c2.gif" alt="&Phi;"
align="absmiddle" width="11" height="18"> must be true. If
<img src="wheeler-trusting-trust-ddc_html_15640894.gif" alt="&Lambda;" align="absmiddle" width="13" height="18"> is true, then
<img src="wheeler-trusting-trust-ddc_html_4b27cbbf.gif" alt="&Lambda;'" align="absmiddle" width="22" height="18"> is false, and
since <img src="wheeler-trusting-trust-ddc_html_m518edb54.gif" alt="&Lambda'&or;&Psi;" align="absmiddle" width="49" height="18"> is true,
then <img src="wheeler-trusting-trust-ddc_html_m5f31e6e0.gif" alt="&Psi;" align="absmiddle" width="13" height="18"> must be true.
Since <i>either</i> <img src=
"wheeler-trusting-trust-ddc_html_4072c6c2.gif" alt="&Phi;"
align="absmiddle" width="11" height="18"> or <img src=
"wheeler-trusting-trust-ddc_html_m5f31e6e0.gif" alt="&Psi;" align="absmiddle" width="13" height="18"> <i>must</i> be true, it
follows that <img src=
"wheeler-trusting-trust-ddc_html_4e30f7ad.gif" alt="&Phi;&or;&Psi;" align="absmiddle" width="37" height="18"> is <i>always</i> true.
The traditional logic rule <i>modus ponens</i> (given <img src=
"wheeler-trusting-trust-ddc_html_4072c6c2.gif" alt="&Phi;"
align="absmiddle" width="11" height="18"> and <img src=
"wheeler-trusting-trust-ddc_html_m73eba5cc.gif" alt="&Phi;&rArr;&Psi;" align="absmiddle" width="41" height="18">, then <img src=
"wheeler-trusting-trust-ddc_html_m5f31e6e0.gif" alt="&Psi;" align="absmiddle" width="13" height="18">) is a special case of
ground resolution; <img src=
"wheeler-trusting-trust-ddc_html_m73eba5cc.gif" alt="&Phi;&rArr;&Psi;" align="absmiddle" width="41" height="18"> can be rewritten (using
clausify) as <img src=
"wheeler-trusting-trust-ddc_html_2f3efe16.gif" alt="&not;&Phi;&or;&Psi;" align="absmiddle" width="48" height="18">, and ground resolution
can combine <img src="wheeler-trusting-trust-ddc_html_4072c6c2.gif"
alt="&Phi;" align="absmiddle" width="11" height="18"> with
<img src="wheeler-trusting-trust-ddc_html_2f3efe16.gif" alt="&not;&Phi;&or;&Psi;" align="absmiddle" width="48" height="18"> to derive
<img src="wheeler-trusting-trust-ddc_html_m5f31e6e0.gif" alt="&Psi;" align="absmiddle" width="13" height="18">.</p>
<p>The full resolution rule extends ground resolution so that it
can handle quantifiers and predicates. It does this by using
unification, the process of replacing the variables in the
expressions with terms to make the modified expressions identical
to each other. For details, see section 3.3 of [Duffy1991] or
[Robinson2001].</p>
<p>For example, given &#8220;&nbsp;man(X) | mortal(X)&#8221;, we
can substitute &#8220;X=socrates&#8221; yielding
&#8220;man(socrates)&nbsp;|&nbsp;mortal(socrates)&#8221;; this can then
be combined with &#8220;man(socrates)&#8221; to prove
&#8220;mortal(socrates)&#8221;.</p>
</li>
<li>
<p><i><b>Para</b></i>: Paramodulation, a rule that adds support for
the equality relation. This replaces an expression with another
expression it is equal to, including any parameter substitutions.
For example, given &#8220;f(d,&nbsp;e,&nbsp;X)&#8221; and
&#8220;f(A,&nbsp;B,&nbsp;C)=g(C,&nbsp;B,&nbsp;A)&#8221;,
paramodulation can derive &#8220;g(X,&nbsp;e,&nbsp;d)&#8221;. The
precise definition of this rule is complex (e.g., it handles cases
where the equality holds only under certain conditions); for
details, see section 3.3.7 of [Duffy1991] or [Robinson2001].</p>
</li>
</ul>
<p>These proof step rationales (aka derivation rules or rules of
inference) were used because they are the rationales supported by
the selected proof tools.</p>
<h2><a name=
"5.4.Tools and rationale for confidence in the proofs|outline"></a>
5.4 Tools and rationale for confidence in the proofs</h2>
<h3><a name="5.4.1.Early DDC proof efforts|outline"></a> 5.4.1
Early DDC proof efforts</h3>
<p>Early versions of these proofs were developed by hand.
Unfortunately, it was very difficult to rigorously check or amend
those hand-created proofs<a class="sdfootnoteanc" name=
"sdfootnote11anc" href="#sdfootnote11sym"><sup>11</sup></a>.</p>
<p>The tool named Prototype Verification System (PVS) was then used
for some time, in part because it has a powerful notation that
supports type-checking (which can eliminate some errors) and
higher-order logic [Owre2001]. At the time, it was thought that
higher-order logic would be especially helpful, since a compiler
can be viewed as a computational function that produces a
computational function. However, while PVS is very good at what it
does, and several proofs were created using PVS, PVS required a
large amount of manual effort to produce the proofs. These early
proofs showed that higher-order logic was not necessary or
especially helpful in modeling this particular problem, and that
other logic systems and provers could be used instead. Many other
tools have less powerful notations (e.g., first-order logic without
types) but can better automate proof development.</p>
<h3><a name="5.4.2.Prover9, mace4, and ivy|outline"></a> 5.4.2
Prover9, mace4, and ivy</h3>
<p>The final proofs, as presented in this dissertation, were
developed and checked with the assistance of several related tools:
prover9, mace4, and ivy:</p>
<ul>
<li>
<p>Prover9 is an automated theorem prover for first-order and
equational (classical) logic, which uses an ASCII representation of
FOL. All of the proofs given in this chapter were developed by
prover9 version Aug-2007.</p>
</li>
<li>
<p>Mace4 is a tool paired with prover9 that searches for finite
structures satisfying first-order and equational statements (the
same kind of statement that Prover9 accepts). From a logic point of
view, mace4 produces interpretations which are models of the input
formulas; from a mathematical point of view, mace4 produces
structures satisfying the input formulas. Put simply, mace4 tries
to find an assignment of integers 0..n&nbsp;1 (the
&#8220;domain&#8221;) to each constant term, to each function
(given their possible inputs in the domain), and true/false values
for each predicate that will satisfy the given set of statements.
By default, mace4 starts searching for a structure of domain size
2, and then it increments the size until it succeeds or reaches
some limit.</p>
</li>
<li>
<p>Ivy is a separate proof checker that can accept and verify the
proof as output by prover9. Ivy is written using A (sic)
Computational Logic for Applicative Common Lisp (ACL2) and has
itself been proven sound using ACL2 [McCune2000]. All of the
prover9 proofs were verified by ivy. Indeed, one reason prover9 was
chosen over some other tools was the availability of ivy.</p>
</li>
</ul>
<p>Far more detail about prover9 is provided in [McCune2008]; its
general approach (in particular, information on resolution and
paramodulation) is discussed in detail in texts such as [Duffy1991]
and [Robinson2001]. For purposes of this dissertation, prover9 is
given a set of assumptions and a goal statement, using first-order
logic (FOL) with equality. Prover9 negates the goal, transforms all
assumptions and the goal into simpler clauses, and then attempts to
find a proof by contradiction. Should prover9&#8217;s search
algorithm find a proof, it can print the sequence of steps and the
rationale for each step that leads to the proof.</p>
<h3><a name="5.4.3.Tool limitations|outline"></a>5.4.3 Tool
limitations</h3>
<p>Unlike PVS, traditional FOL and the prover9 tool (which
implements FOL) do not directly support types (sorts). It is
possible to implement types (sorts) using FOL: types of constants
can be declared as assertions (e.g., &#8220;executable(cA)&#8221;
could represent &#8220;c<sub>A</sub> is an executable&#8221;),
assertions about compilers could be modified to state the types of
compiler inputs and outputs, and the goal could be extended to
include type requirements. However, because prover9 does not
directly support type declaration, implementing types in prover9
makes the proofs far more complicated. These complications do not
add value, because the types of compiler input and output are not
in doubt (and thus do not need proof). In this dissertation types
are only used as part of the comments to clarify the proof results,
and are not directly expressed in the proof notation.</p>
<p>It should be noted that these tools did not make creating the
proofs trivial. In particular, prover9 can only find a proof given
a correct goal and assumptions. When prover9 cannot prove a goal,
it either halts with a declaration that it cannot prove the result
or it times out. In either case it is often difficult to determine
<i>why</i> the proof cannot be found. The companion tool mace4 may
be able to find a counter-example, but even then it is often not
obvious what is wrong. In practice, the proofs were developed by
first creating very simplified models of the world, and then
expanding them stepwise to model additional complexities of the
real world.</p>
<p>Prover9 will sometimes use information it does not need, leading
to overly-complicated proofs. To counteract this, each proof was
developed separately and includes only the statements necessary for
the proof.</p>
<h3 style="font-style: normal"><a name=
"5.4.4.Proofs&#8217; conclusions follow from their assumptions|outline">
</a> 5.4.4 Proofs&#8217; conclusions follow from their
assumptions</h3>
<p>There are many reasons to have very high confidence that the
formal proofs&#8217; conclusions follow from their assumptions:</p>
<ul>
<li>
<p>The proofs were automatically generated by an automated tool,
prover9. This eliminates many opportunities for error caused by
manual proofs.</p>
</li>
<li>
<p>The generated proofs were verified by the separate tool ivy. Ivy
cannot create proofs; it is a simple program that checks that each
step is correct. This cross-checking increases the confidence that
the proof is correct.</p>
</li>
<li>
<p>Ivy itself has has been proven sound using ACL2.</p>
</li>
<li>
<p>The source code for prover9, ivy, and ACL2 are all publicly
visible under the terms of the GNU General Public License (GPL).
This public visibility enables widespread public review.</p>
</li>
<li>
<p>The proofs were hand-verified by the author. They have also been
reviewed by several people at the Institute for Defense Analyses
(IDA) and by the PhD committee members.</p>
</li>
</ul>
<p>In short, there are good reasons to have very high confidence
that these proofs correctly prove their goals, given their
assumptions.</p>
<h3 style="font-style: normal"><a name=
"5.4.5.Proofs&#8217; assumptions and goals adequately model the world|outline">
</a> 5.4.5 Proofs&#8217; assumptions and goals adequately model the
world</h3>
<p>A related question is whether or not the formally-stated
assumptions are an adequately accurate model of the real world.
There are good reasons to believe this is also true:</p>
<ul>
<li>
<p>The assumptions have been proven to be consistent using mace4.
In classical logic an inconsistent set of assumptions can be used
to prove any claim, so it is important that a set of assumptions be
consistent. If a set of first-order statements are simultaneously
satisfiable, then that set is consistent (see page 410 of
[Stoll1979] for a proof of this statement). The set of assumptions
in each of the three proofs have been shown by the mace4 tool to be
satisfiable (i.e., for each proof mace4 can create a model that
satisfies the set of assumptions). Therefore, the assumptions used
in each proof are consistent. See appendix C for the mace4 models
that show the assumptions are consistent. For another example of a
project that used mace4 to check for consistency, see
[Schwitter2006].</p>
</li>
<li>
<p>The assumptions and goals are based on the informal
justification previously published in the 2005 ACSAC paper
[Wheeler2005]. This paper passed independent peer review before its
publication, and no one has refuted it since.</p>
</li>
<li>
<p>These assumptions and goals have been reviewed by the author,
several people at the Institute for Defense Analyses (IDA), and all
of the dissertation committee members.</p>
</li>
<li>
<p>All of the outcomes from the demonstrations described in chapter
7 can be explained in terms of these proofs.</p>
</li>
<li>
<p>The formalization process forced the author to clarify that
three proofs were needed, not just one. Originally, the author
intended to only create one proof (proof #1), but as it was
developed, it became clear that multiple proofs were needed. This
suggests that insight was gained through the process of developing
the formal proof, and an author who has gained insight into the
problem is more likely to produce final assumptions and goals that
adequately model the world.</p>
</li>
<li>
<p>The proofs clearly fit together. Proof #3 shows that if there is
a benign environment and a grandparent compiler, then
cP_corresponds_to_sP (to be defined) is true. Proof #2 shows that
if there is a benign environment and cP_corresponds_to_sP is true,
then stage2=c<sub>A</sub>. And finally, proof #1 shows that if
stage2=c<sub>A</sub>, then c<sub>A</sub> and <i>s</i><sub>A</sub>
correspond.</p>
</li>
</ul>
<p>Therefore, there are good reasons to believe that these
assumptions and goals adequately model the real world.</p>
<h2 style="font-style: normal"><a name=
"5.5.Proof conventions|outline"></a> 5.5 Proof conventions</h2>
<p>The notation of prover9 only supports simple ASCII text, and
does not directly support the Unicode characters for logic notation
(such as &#8594;) nor subscripts (such as c<sub>A</sub>) by
default. Thus, the ASCII representation is used for all prover9
representations and results below. Constants with subscripts are
represented by simply appending the subscript value, e.g.,
c<sub>A</sub> is notated as cA. Spaces and newlines are
occasionally inserted to improve readability. All successful
prover9 proofs end with the conclusion &#8220;$F&#8221; (false).
This means that prover9 was able to find a contradiction given the
assumptions and the negation of the goal. Definitions are a kind of
assumption; their names begin with &#8220;definition_&#8221; if
they are of the form &#8220;constant =EXPRESSION&#8221;, and begin
with &#8220;define_&#8221; otherwise. In the prover9 proof,
assumptions and goals are assigned names using the prover9
&#8220;label&#8221; attribute (not shown in this dissertation).</p>
<p>Each of the proofs below begins with a formal statement (using
FOL formulas) of the goal to be proved, along with a textual
explanation. This is followed by sections that introduce the
required predicates, functions, and assumptions, as well as
restating the goal. The predicates and functions are first
described by showing in a fixed-width font the keyword
&#8220;predicate&#8221; or &#8220;function&#8221;, the
predicate/function name, and its parentheses-surrounded parameters
(using initial capital letters). The assumptions (including
definitions) and goal are first described using FOL formulas ending
with a period. Predicates, functions, and assumptions are each
described further in explanatory text. These are followed by a
prover9 proof (verified by ivy), which shows in a table format how
the assumptions prove the goal (using proof by contradiction). The
table includes the rationale for each step. The prover9 proof is
followed by additional discussion about that proof.</p>
<h2><a name=
"5.6.Proof #1: Goal source_corresponds_to_executable|outline"></a>
5.6 Proof #1: Goal source_corresponds_to_executable</h2>
<p>The key proof for DDC is to show that, if stage2 (the result of
the DDC process) and c<sub>A</sub> (the original
compiler-under-test) are equal, then the compiled executable
c<sub>A</sub> and the source code <i>s</i><sub>A</sub> exactly
correspond. This goal is easily represented by the following
formula (using ASCII representation) named
source_corresponds_to_executable:</p>
<pre>
   (stage2 = cA) -&gt; exactly_correspond(cA, sA, lsA, eArun).
</pre>
<p>As with all formal proofs in this dissertation, this proof
introduces various predicates, functions, and assumptions. Since
this first proof is central to the entire dissertation, as each
assumption is introduced it will be shown how it builds toward the
final goal. This is followed by a prover9 table (showing how the
assumptions prove the final goal) and a brief discussion.</p>
<h3 style="font-style: normal"><a name=
"__RefHeading__34675001"></a><a name=
"5.6.1.Predicate &#8220;=&#8221; given two executables|outline"></a>
5.6.1 Predicate &#8220;=&#8221; given two executables</h3>
<p>The predicate &#8220;=&#8221; (equal-to, aka equality) is part
of the goal statement; it compares two executables to determine if
they are equal. It is an infix predicate with this form:</p>
<pre>
        predicate Executable1 = Executable2
</pre>
<p>For purposes of DDC, two executables are equal if they have
<i>exactly</i> the same structure and values as used by the
environment when it runs either executable. When performing DDC,
this test for equality must occur in an environment that is trusted
to accurately report on the equality of two executables (i.e., the
environment and program implementing this equality test must not
have triggers/payloads for the values tested), and the two
executables being compared must have been acquired in a trustworthy
way.</p>
<p>In a traditional operating system with a filesystem, an
executable would normally be one or more files, where each file
would be a stream of zero or more bytes as well as metadata
controlling its execution (including the set of attributes
determining if and how to run the file). The sequence of bytes must
be identical (the same length and at each position the same value),
and the metadata effecting execution must have the same effect in
execution when transferred to its execution environment (e.g., the
&#8220;execution&#8221; flag or equivalent must have the same value
so that they are both executable). The &#8220;have the same
effect&#8221; phrase is stated here because differences that are
<i>not</i> used by the environment during execution are irrelevant.
In particular, many operating systems record &#8220;date
written&#8221; as part of the metadata, and this would typically
not be the same between different compilation runs. Nevertheless,
as long as those differences do not effect program execution, they
do not matter. Indeed, if the differences are only compared in
certain ways, and those relationships are maintained, then they do
not matter. Thus, if a &#8220;makefile&#8221; compares dates, but
only to determine which files came before or later, the specific
dates do not matter as long as the relationships are maintained. In
practice, it is relatively easy to determine what metadata has an
effect by examining the source code <i>s</i><sub>A</sub> and
<i>s</i><sub>P</sub>; if the source code does not use it (directly
or via calls to the environment), then given the other assumptions,
the resulting stage2 executable from DDC will not invoke them
either. This is because the DDC process (though not the original
generation process) is required to not include triggers or payloads
that affect the execution process (as discussed in section
3.2).</p>
<p>If the executables are S-expressions<a class="sdfootnoteanc"
name="sdfootnote12anc" href="#sdfootnote12sym"><sup>12</sup></a>,
the usual definition of S-expression equality is used: Atoms are
only equal to themselves (so 5=5), NIL is only equal to itself, and
lists are equal iff they have the same length and each of their
elements are equal. NIL and an empty list are distinct if and only
if the execution environment can distinguish them. We presume
S-expressions are written out as text and read back before use
(otherwise there may be complications due to pointer
equivalence).</p>
<p>Note that equality is a <i>stricter</i> relationship than
<i>equivalence</i>. Two executables may be considered
<i>equivalent</i> in an environment if they always produce equal
outputs given equal inputs, even if their internal structure and/or
values are different. Two executables that are equal are always
equivalent, but equivalent executables need not be equal.
Unfortunately, determining if two executables E1 and E2 are
equivalent is undecidable in the general case. This is because if
there was any decision procedure D capable of determining
equivalence, it could be invoked by E1 and E2. If found equivalent
they could perform different operations, and if found different
they could act the same [Cohen1984, part 4]. Even in very special
cases it is often difficult to determine the equivalence of two
unequal executables. Instead of focusing on the
difficult-to-determine equivalence relationship, we will instead
focus on the stricter equality relationship, which is a far easier
and more practical test to perform. Proof #2 and proof #3 will show
that under certain common conditions, two executables will be equal
(not just equivalent), so limiting proof #1 to equality does not
significantly limit its practical utility.</p>
<h3 style="font-style: normal"><a name=
"5.6.2.Predicate exactly_correspond|outline"></a> 5.6.2 Predicate
exactly_correspond</h3>
<p>The goal statement makes no sense unless the predicate
&#8220;exactly_correspond&#8221; is defined. Predicate
&#8220;exactly_correspond&#8221; has the following parameters:</p>
<pre>
   predicate exactly_correspond(Executable, Source, Lang, RunOn)
</pre>
<p>This predicate is defined to be true if, and only if, the
Executable <i>exactly</i> implements source code Source when (1)
that Source is interpreted as language Lang and (2) the Executable
is run on environment RunOn. For this predicate to be true, the
Executable must not do anything more, anything less, or anything
different than what is specified by Source (when interpreted as
language Lang). Note that this does <i>not</i> require that Source
is a perfect implementation of some abstractly-defined language. In
section 5.6.8 we will define a condition that will make the
predicate exactly_correspond true.</p>
<h3><a name="5.6.3.Predicate accurately_translates|outline"></a>
5.6.3 Predicate accurately_translates</h3>
<p>A related predicate that must be defined is
accurately_translates, with these parameters:</p>
<pre>
   predicate accurately_translates(Compiler, Lang, Source, EnvEffects,
                RunOn, Target)
</pre>
<p>This predicate is true if and only if the Compiler (an
executable) correctly implements language Lang when compiling a
particular Source and given input EnvEffects (from the
environment), when it is run on environment RunOn and targeting
environment Target. The Target is the environment that the compiler
generates code for (which need not be the same as the environment
the compiler runs in). The EnvEffects parameter models variations
in timing and inputs from the environment, and will be explained
further in the definition of the &#8220;compile&#8221; function in
section 5.6.5.</p>
<h3><a name="__RefHeading__33504460"></a><a name=
"5.6.4.Assumption cT_compiles_sP|outline"></a> 5.6.4 Assumption
cT_compiles_sP</h3>
<p>We must assume that the trusted compiler c<sub>T</sub> is a
compiler for language lsP (the language used by source code
<i>s</i><sub>P</sub>), that c<sub>T</sub> will accurately translate
<i>s</i><sub>P</sub> when run in environment e1, and that
c<sub>T</sub> targets (generates code for) environment e2. This
assumption is named cT_compiles_sP:</p>
<pre>
   all EnvEffects accurately_translates(cT, lsP, sP, EnvEffects, e1, e2).
</pre>
<p>In short, c<sub>T</sub> has to accurately implement the language
lsP, at least sufficiently well to compile <i>s</i><sub>P</sub>.
Otherwise, c<sub>T</sub> can&#8217;t be used to compile
<i>s</i><sub>P</sub>. For example, if <i>s</i><sub>P</sub> was
written in C&#8288;+&#8288;+, then a Java compiler cannot be
directly used as the trusted compiler c<sub>T</sub>. Compiler
c<sub>T</sub> must not have triggers or payloads that activate when
compiling <i>s</i><sub>P</sub>. Neither e1=e2 nor e1&#8800;e2 is
asserted; thus, e1 may but need not be the same as e2. The
&#8220;all&#8221; in the formal statement is optional, but is
included here for emphasis.</p>
<h4><a name="__RefHeading__31261668"></a><a name=
"5.6.4.1.Implications for the language|outline"></a> 5.6.4.1
Implications for the language</h4>
<p>This proof could have been created without mentioning languages
at all; the formal model could simply require that (1)
c<sub>T</sub> will accurately translate <i>s</i><sub>P</sub> when
run in environment e1 and that (2) c<sub>T</sub> targets (generates
code for) environment e2. However, it would have been easy to
misunderstand the proof results. For example, without noting the
different languages, the proof could be easily misunderstood as
requiring that all compilers implement the same language. Noting
the languages clarifies that they <i>can</i> be different, and
clarifies that the languages should be considered when performing
DDC. Including the languages in the proofs also provides a check on
the proof that is similar to type-checking: The proof requires that
in each compilation, the compiler used must support the language of
the source code used as input.</p>
<p>The language lsP <i>must</i> include <i>all</i> of the syntactic
and semantic requirements necessary to correctly interpret
<i>s</i><sub>P</sub>. It <i>may</i>, but need not, include
additional requirements not required to interpret
<i>s</i><sub>P</sub> (as long as they do not interfere with
interpreting <i>s</i><sub>P</sub>). In particular, lsP need not be
the same as the language documented in an official (e.g.,
standardized) language specification, even if one exists. For
example:</p>
<ul>
<li>
<p>lsP may omit any requirements in an official specification, as
long as the source code does not require them. So an official
specification may include support for threading or floating point
numbers, but if they are not needed when compiling the source code,
then they can be safely omitted from lsP.</p>
</li>
<li>
<p>lsP may impose additional requirements that are explicitly left
undefined in an official specification. For example, if an official
language specification permits certain operations to be done in an
arbitrary order (such as right-to-left or left-to-right evaluation
of function parameters), but the given source code requires a
particular order of evaluation, then lsP must add the additional
ordering requirement. Such additional requirements, if any, should
be included in the source code&#8217;s documentation. It is usually
<i>better</i> if the source code only requires what an official
language specification guarantees, because there are likely to be
more alternative compilers. But it&#8217;s quite common for
compiler sources to make assumptions that are not guaranteed by
official specifications, and DDC can still be used in such
cases.</p>
</li>
<li>
<p>lsP may impose additional length or size requirements than those
imposed by an official specification. For example, if the source
code requires support for certain identifier lengths, depth of
parentheses, or size of result, then lsP includes those
requirements.</p>
</li>
<li>
<p>If lsP includes ambiguous requirements, or requirements that are
not fully defined, then those ambiguities or inadequate definitions
must not matter when compiling the source code.</p>
</li>
<li>
<p>lsP may add various extensions as requirements that are not part
of the official specification. Unsurprisingly, if the source code
requires extensions, then the compiler used to compile that source
code must somehow support those extensions.</p>
</li>
<li>
<p>lsP could even directly contravene an official specification on
certain issues; what matters is what is required to correctly
compile the source code.</p>
</li>
</ul>
<p>The language lsP need not be formally specified, nor must it
exist as a single document. If expressed, it is likely to take the
form of a reference to an existing language standard combined with
a description of the permitted omissions, the changes, and the
additions. For proof purposes, the language specification need not
be written at all; all that is required is that the compilers and
source code conform if it <i>were</i> written. Of course, if the
specification is not written, it is difficult to check for
compliance to it.</p>
<p>The &#8220;language&#8221; may even be a set of languages,
including a language for selecting which other language to use
(e.g., the file extension conventions used for selecting between
languages). For example, GNAT (whose name is no longer an acronym)
is an Ada compiler whose front-end is written in Ada, but the rest
of the compiler is written in C. A trusted compiler suite for GNAT
would need to be able to compile both Ada and C, as well as
correctly process the file extension conventions used by the GNAT
source code to differentiate between languages.</p>
<h4><a name=
"5.6.4.2.Implications for the trusted compiler and its environment|outline">
</a> 5.6.4.2 Implications for the trusted compiler and its
environment</h4>
<p>Compiler c<sub>T</sub> need not implement a whole language, as
defined by an official language specification&#8212;it only needs
to implement what is required to compile <i>s</i><sub>P</sub>. So
c<sub>T</sub> may be a very limited compiler. In some cases, some
compiler c<sub>Q</sub> may only be suitable for use as a part of
trusted compiler c<sub>T</sub> if the source code goes through a
preprocessor, or if the resulting executable goes through a
postprocessor. For example, a preprocessor may be needed to convert
nonstandard constructs into constructs that c<sub>Q</sub> can
handle, or perhaps c<sub>Q</sub> implements a different
specification. In this case, the compiler c<sub>T</sub> is the
combination of the preprocessor and c<sub>Q</sub>. In theory
there&#8217;s no limit to how many steps can be chained together to
construct c<sub>T</sub>, but since they are all part of the trusted
compiler they must be sufficiently trustworthy to meet the
assumptions of the proof. In practice, these steps (including the
use of preprocessors and postprocessors) should be limited, to
limit the number and size of tools that are granted such trust.</p>
<p>Note that the trusted compiler (c<sub>T</sub>) and the
environment it executes on (e1) do <i>not</i> need to be completely
defect-free nor non-malicious. This is important, since defect-free
compilers and environments are rare, and ensuring absolute
non-maliciousness is difficult. Compiler c<sub>T</sub> or
environment e1 may be full of bugs, and/or full of triggers and
payloads for inserting corrupted code into other programs
(including itself). We merely require that c<sub>T</sub>, when
executed on e1, perform an accurate translation when it compiles
exactly one program&#8217;s source code: <i>s</i><sub>P</sub>. So
c<sub>T</sub> may have defects &#8211; but they must not affect
compiling <i>s</i><sub>P</sub>. Similarly, c<sub>T</sub> may have
triggers and payloads to create maliciously corrupted executable(s)
&#8211; but c<sub>T</sub> must not have triggers for
<i>s</i><sub>P</sub>, or if it does, its payloads must not affect
the results. Various real-world actions, such spot-checking or
formally verifying the compiler executable c<sub>T</sub>, can
increase confidence that this assumption is true in the real world.
In some cases, a secret compiler (where reading/writing its source,
reading/writing its executable, and using it as a service is
expressly limited to very few trusted people) may be useful as the
trusted compiler; via DDC, it can be used to greatly increase
confidence in the publicly-available compiler.</p>
<p>It is worth noting that one of these potential failures is
memory failure. Recent field studies have found that dynamic random
access memory (DRAM) error rates are orders of magnitude higher
than previously reported, and memory errors are dominated by hard
errors (which corrupt bits in a repeatable manner) rather than soft
errors [Schroeder2009]. The risk of such failures can be greatly
reduced by using memory test programs to check the environment
before performing DDC, and by using memory systems that include
error correcting code(s) (ECC).</p>
<p>There is a subtlety in the formal model that is normally handled
correctly by compiler users, but is noted here for completeness.
That subtlety is that when performing DDC, we typically need to
have different build instructions (as executed by the
&#8220;real&#8221; compilers and environment) than when
<i>s</i><sub>P</sub> and <i>s</i><sub>A</sub> were originally
compiled. At first glance this appears to be a problem, because in
the formal model of DDC, the source code <i>s</i><sub>P</sub> and
<i>s</i><sub>A</sub> that is used in DDC must be <i>exactly</i> the
same as the source code used in its original purported creation
process. Yet the source code may include build instructions,
indeed, nontrivial compilers often include complex build
instructions as part of their source code. But if the build
instructions are part of the source code, and the build
instructions invoke a compiler other than c<sub>T</sub>, how can
trusted compiler c<sub>T</sub> be invoked during DDC? Similarly, if
the environments e1 or e2 are different than the environments eP
and eA (respectively), and/or if the option flags are different
between compilers, how are these changes modeled? And similarly, if
the build systems are substantially different (e.g., there are
different build languages), how can we accurately model translating
the build language? One solution is to consider the build
instructions as not included in the source code, but this is
grossly unrealistic for larger compilers with complex build
instructions.</p>
<p>A better alternative that completely models these circumstances
is to consider the build instructions to be part of the source
code, and also consider the trusted compiler c<sub>T</sub> to be
some &#8220;real&#8221; compiler c<sub>T</sub>&#8207;&#8206;&#8242;
plus a preprocessor. This preprocessor is trusted to correctly
change the build instructions in a way that meets this assumption,
e.g., so that the compilation process invokes
c<sub>T</sub>&#8207;&#8206;&#8242; instead of the original
compilation process. In practice, this preprocessor is likely to be
implemented by a human who modifies the build process (e.g., by
setting an environment variable, modifying a makefile, using a
different set of arguments when invoking &#8220;make&#8221;, or
hand-translating the build instructions to a different build
language). This step is so &#8220;obvious&#8221; to most compiler
users that it would not normally be remarked on. Often this
transformation is so simple that it is easy to forget that it even
occurred. Nevertheless, by acknowledging this step, the formal
model of DDC can accurately model what actually occurs. Since it is
part of the trusted compiler c<sub>T</sub>, this preprocessor step
must be trusted to not include triggers and payloads that would
effect the DDC compilation.</p>
<p>In general, the internal structure of trusted compiler
c<sub>T</sub> is irrelevant for the proof. Many problems in
applying DDC (including modeling necessary changes to the build
process as noted above) can be resolved by combining various
processes (including preprocessors and/or postprocessors) as
necessary to produce the final trusted compiler c<sub>T</sub>. The
only requirement is that all required assumptions (including the
definitions) are met.</p>
<h3><a name="__RefHeading__31481937"></a><a name=
"5.6.5.Function compile|outline"></a> 5.6.5 Function compile</h3>
<p>Unsurprisingly, we must model compiling a program. We will model
compiling as a function that returns an executable (a kind of
data)<a class="sdfootnoteanc" name="sdfootnote13anc" href=
"#sdfootnote13sym"><sup>13</sup></a> and has the following
parameters:</p>
<pre>
   function compile(Source, Compiler, EnvEffects, RunOn, Target)
</pre>
<p>This represents compiling Source with the Compiler, running the
compiler in environment RunOn, and instructing the compiler to
generate an executable for the target environment Target. Note that
Target may or may not be the same as RunOn.</p>
<p>The parameter &#8220;EnvEffects&#8221; overcomes an issue in
typical mathematical notation. In typical mathematical notation, a
function provided with the same inputs will always produce the same
outputs. Without the &#8220;EnvEffects&#8221; parameter, this would
imply that a given compiler executable, when given the same Source,
RunOn, and Target, will always produce exactly the same output
(i.e., that it is <i>deterministic</i>). Unfortunately, this is
<i>not</i> always true for all compilers. Some compilers
<i>will</i> produce different outputs at different times, even when
given the same source code. The reason is that environments can
provide &#8220;effects&#8221;, which are essentially inputs to the
compilation process that affect the outcome but are not part of the
source code. Examples of effects that can cause non-determinism
are:</p>
<ul>
<li>
<p>Random number generators. A compiler&#8217;s code generator or
optimizer might have multiple alternatives, and instead of picking
one deterministically, it might call on a random number generator
to make that determination. If the environment provides different
random numbers each time it is run, the results might be different.
Note that under certain circumstances the GCC compiler will use a
random number generator, but GCC also allows users to select a
seed; if a seed is selected, then the sequence is deterministic and
not random at all.</p>
</li>
<li>
<p>Heap allocation address values. Many systems today randomize
addresses (e.g., of the heap or stack), in an attempt to counter
attackers by making certain kinds of attacks harder to perform.
However, a compiler&#8217;s output may be changed by different
address values. For example, some Java compilers use heap
allocation addresses for hash calculation, and then use those hash
values to control the sort order of some output. As a result, the
output ordering may be different between executions, even given the
same source code, execution environment, and target
environment.</p>
</li>
<li>
<p>Execution order due to threading. Some compilers are
multi-threaded and are only loosely ordered. The environment may
execute the threads in a different order in different executions,
and depending on the compiler, this may affect the output.</p>
</li>
</ul>
<p>Thus, EnvEffects models the inputs from the environment which
may vary between executions while still conforming to the language
definition as used by Source.</p>
<p>As noted earlier, libraries may be modeled by considering them
as part of the compiler (if they are executed) or part of the
source (if they are used as input data but not executed).</p>
<p>In some discussions of DDC, we will occasionally use the simpler
definition:</p>
<pre>
   function compile(Source, Compiler)
</pre>
<p>Of course, this definition cannot represent the different
environments (RunOn and Target), nor can it represent the
possibility that some programs are non-deterministic (which is
modeled by EnvEffects), but in some situations these can be
inferred from context. In some cases the function name
&#8220;c&#8221; is used as an abbreviation for
&#8220;compile&#8221;.</p>
<h3><a name="5.6.6.Assumption sP_compiles_sA|outline"></a> 5.6.6
Assumption sP_compiles_sA</h3>
<p>We must assume that the source code <i>s</i><sub>P</sub>
(written in language lsP) defines a compiler that, if accurately
compiled, would be suitable for compiling <i>s</i><sub>A</sub>. To
formally state this, we will assert that if we have some
GoodCompilerLangP with the right properties, then using
GoodCompilerLangP on <i>s</i><sub>P</sub> will produce a suitable
executable:</p>
<pre>
   accurately_translates(  GoodCompilerLangP, lsP, sP,
                           EnvEffectsMakeP, ExecEnv, TargetEnv) -&gt;
      accurately_translates(
        compile(sP, GoodCompilerLangP, EnvEffectsMakeP,
                ExecEnv, TargetEnv),
        lsA, sA, EnvEffectsP, TargetEnv, eArun).
</pre>
<p>Strictly speaking, the name &#8220;sP_compiles_sA&#8221; is
misleading; there is no guarantee that source code can be directly
executed. However, more-accurate names<a class="sdfootnoteanc"
name="sdfootnote14anc" href="#sdfootnote14sym"><sup>14</sup></a>
tend to be very long and thus hard to read.</p>
<p>Note that by combining this assumption (sP_compiles_sA) and the
previous assumption cT_compiles_sP, we can determine a new derived
result which we will name sP_compiles_sA_result:</p>
<pre>
   accurately_translates(  compile(sP, cT, EnvEffectsMakeP, e1, e2),
                                   lsA, sA, EnvEffectsP, e2, eArun).
</pre>
<p>Note that EnvEffectsMakeP and EnvEffectsP are not bound to any
particular value, so they have an implicit &#8220;for all&#8221;
around them. Since their actual values do not matter, to simplify
these expressions they (and similar dummy values) can be replaced
with arbitrary capital letters:</p>
<pre>
   accurately_translates(compile(sP, cT, A, e1, e2), lsA, sA, B, e2, eArun).
</pre>
<p>Note that <i>s</i><sub>P</sub> (when compiled) does not need to
implement the <i>whole</i> language <i>s</i><sub>A</sub> was
written in, as defined by some official language standard. Instead,
a compiled form of <i>s</i><sub>P</sub> only needs to implement the
syntax and semantics of the language that <i>s</i><sub>A</sub>
requires. This language, lsA, <i>must</i> include <i>all</i> of the
syntactic and semantic requirements necessary to correctly
interpret <i>s</i><sub>A</sub>; it <i>may</i>, but need not,
include additional requirements not required to interpret
<i>s</i><sub>A</sub>. This is fundamentally the same kind of issue
as described in section 5.6.4 (with <i>s</i><sub>A</sub>, lsA, and
the compiled <i>s</i><sub>P</sub> analogous to
<i>s</i><sub>P</sub>,, lsP, and c<sub>T</sub>), and the same
explanation regarding language applies.</p>
<h3><a name="5.6.7.Definition definition_stage1|outline"></a> 5.6.7
Definition definition_stage1</h3>
<p>We must now begin to define the DDC process itself in this
formal notation. As shown in figure 4, the executable
&#8220;stage1&#8221; is created by compiling <i>s</i><sub>P</sub>
using c<sub>T</sub>, running on environment e1 and targeting
environment e2. We will name this definition_stage1, and it is
formally notated as:</p>
<pre>
   stage1 = compile(sP, cT, e1effects, e1, e2).
</pre>
<p>Combining this with sP_compiles_sA_result, we find this result
which we will name as definition_stage1_result1:</p>
<pre>
   accurately_translates(stage1, lsA, sA, A, e2, eArun).
</pre>
<h3><a name="__RefHeading__31381206"></a><a name=
"5.6.8.Definition define_exactly_correspond|outline"></a> 5.6.8
Definition define_exactly_correspond</h3>
<p>There is a key relationship between the predicates
&#8220;exactly_correspond&#8221; and
&#8220;accurately_translates&#8221; that has not yet been
expressed, which also provides insight into what it means when a
source and executable exactly correspond. Fundamentally, if some
Source (written in language Lang) is compiled by a compiler that
accurately translates it, then the resulting executable exactly
corresponds to the original Source. This relationship is named
define_exactly_correspond, and is so central to the notion of
&#8220;exactly_correspond&#8221; that it essentially defines it.
This is expressed as:</p>
<pre>
   accurately_translates(Compiler, Lang, Source, EnvEffects, ExecEnv, TargetEnv)
                -&gt;
        exactly_correspond(compile(Source, Compiler, EnvEffects, ExecEnv, TargetEnv),
                           Source, Lang, TargetEnv).
</pre>
<p>Combining this with the previous result, we can now determine a
result that we will name define_exactly_corresponds_result1:</p>
<pre>
   exactly_correspond(compile(sA, stage1, A, e2, eArun), sA, lsA, eArun).
</pre>
<h3><a name="5.6.9.Definition definition_stage2|outline"></a>5.6.9
Definition definition_stage2</h3>
<p>We now introduce a formal model for how the DDC process
generates stage2, which compiles source <i>s</i><sub>A</sub> using
the executable stage1 and targets environment eArun:</p>
<pre>
   stage2 = compile(sA, stage1, e2effects, e2, eArun).
</pre>
<p>Using the previous result, we can now determine
definition_stage2_result1:</p>
<pre>
   exactly_correspond(stage2, sA, lsA, eArun).
</pre>
<h3><a name=
"5.6.10.Goal source_corresponds_to_executable|outline"></a>5.6.10
Goal source_corresponds_to_executable</h3>
<p>We can now prove our goal, source_corresponds_to_executable.
Recall that this goal is:</p>
<pre>
   (stage2 = cA) -&gt; exactly_correspond(cA, sA, lsA, eArun).
</pre>
<p>But we already know, per definition_stage2_result1, that:</p>
<pre>
   exactly_correspond(stage2, sA, lsA, eArun).
</pre>
<p>If stage2 is exactly the same as c<sub>A</sub> (the left side of
the goal&#8217;s implication), then we can replace stage2 with
c<sub>A</sub>, producing:</p>
<pre style="page-break-before: auto; page-break-after: avoid">
  exactly_correspond(cA, sA, lsA, eArun).
</pre>
<p>QED.</p>
<h3><a name=
"5.6.11.Prover9 proof of source_corresponds_to_executable|outline"></a>
5.6.11 Prover9 proof of source_corresponds_to_executable</h3>
<p>Table 2 presents the proof found by prover9 (see section 5.3 for
more on the rationale).</p>
<p><a name="table2"></a><font size="3"><i>Table 2: Proof #1
(source_corresponds_to_executable) in prover9 format</i></font></p>
<table width="573" border="1" bordercolor="#000000" cellpadding="2"
cellspacing="0" style=
"page-break-before: auto; page-break-inside: avoid">
<col width="23" align="left">
<col width="337" align="left">
<col width="199" align="left">
<tr>
<th width="23" bgcolor="#C0C0C0">
<p>#</p>
</th>
<th width="337" bgcolor="#C0C0C0">
<p>Formula</p>
</th>
<th width="199" bgcolor="#C0C0C0">
<p>Rationale</p>
</th>
</tr>
<tr>
<td width="23">1</td>
<td width="337">accurately_translates(A,B,C,D,E,F) -&gt;
exactly_correspond(compile(C,A,D,E,F),C,B,F)</td>
<td width="199">Assumption define_exactly_correspond</td>
</tr>
<tr>
<td width="23">2</td>
<td width="337">(all A
accurately_translates(cT,lsP,sP,A,e1,e2))</td>
<td width="199">Assumption cT_compiles_sP</td>
</tr>
<tr>
<td width="23">3</td>
<td width="337">accurately_translates(A,lsP,sP,B,C,D) -&gt;
accurately_translates(compile(sP,A,B,C,D),&#8203;lsA,sA,E,D,eArun)</td>
<td width="199">Assumption sP_compiles_sA</td>
</tr>
<tr>
<td width="23">4</td>
<td width="337">stage2 = cA -&gt;
exactly_correspond(cA,sA,lsA,eArun)</td>
<td width="199">Goal
source_corresponds_&#8203;to_&#8203;executable</td>
</tr>
<tr>
<td width="23">5</td>
<td width="337">-accurately_translates(A,B,C,D,E,F) |
exactly_correspond(compile(C,A,D,E,F),C,B,F)</td>
<td width="199">Clausify 1</td>
</tr>
<tr>
<td width="23">6</td>
<td width="337">accurately_translates(cT,lsP,sP,A,e1,e2)</td>
<td width="199">Clausify 2</td>
</tr>
<tr>
<td width="23">7</td>
<td width="337">-accurately_translates(A,lsP,sP,B,C,D) |
accurately_translates(compile(sP,A,B,C,D),&#8203;lsA,sA,E,D,eArun)</td>
<td width="199">Clausify 3</td>
</tr>
<tr>
<td width="23">8</td>
<td width="337">stage1 = compile(sP,cT,e1effects,e1,e2)</td>
<td width="199">Assumption definition_stage1</td>
</tr>
<tr>
<td width="23">9</td>
<td width="337">compile(sP,cT,e1effects,e1,e2) = stage1</td>
<td width="199">Copy 8, flip</td>
</tr>
<tr>
<td width="23">10</td>
<td width="337">stage2 = compile(sA,stage1,e2effects,e2,eArun)</td>
<td width="199">Assumption definition_stage2</td>
</tr>
<tr>
<td width="23">11</td>
<td width="337">compile(sA,stage1,e2effects,e2,eArun) = stage2</td>
<td width="199">Copy 10, flip</td>
</tr>
<tr>
<td width="23">12</td>
<td width="337">cA = stage2</td>
<td width="199">Deny 4</td>
</tr>
<tr>
<td width="23">13</td>
<td width="337">-exactly_correspond(cA,sA,lsA,eArun)</td>
<td width="199">Deny 4</td>
</tr>
<tr>
<td width="23">14</td>
<td width="337">-exactly_correspond(stage2,sA,lsA,eArun)</td>
<td width="199">Para 12 13</td>
</tr>
<tr>
<td width="23">15</td>
<td width="337">
accurately_translates(compile(sP,cT,A,e1,e2),&#8203;lsA,sA,B,e2,eArun)</td>
<td width="199">Resolve 7 6</td>
</tr>
<tr>
<td width="23">16</td>
<td width="337">
accurately_translates(stage1,lsA,sA,A,e2,eArun)</td>
<td width="199">Para 9 15</td>
</tr>
<tr>
<td width="23">17</td>
<td width="337">
exactly_correspond(compile(sA,stage1,A,e2,eArun),&#8203;sA,lsA,eArun)</td>
<td width="199">Resolve 5 16</td>
</tr>
<tr>
<td width="23">18</td>
<td width="337">exactly_correspond(stage2,sA,lsA,eArun)</td>
<td width="199">Para 11 17</td>
</tr>
<tr>
<td width="23">19</td>
<td width="337">$F</td>
<td width="199">Resolve 18 14</td>
</tr>
</table>
<h3><a name="5.6.12.Discussion of proof #1|outline"></a> 5.6.12
Discussion of proof #1</h3>
<p>The existence of stage1 and stage2 implies termination of the
compilation processes that produced them. This doesn&#8217;t limit
the proof&#8217;s utility in the real world; a compilation process
that never finished would not be considered useful, and would
certainly be noticed. Termination implies that <i>s</i><sub>A</sub>
and <i>s</i><sub>P</sub> are computable and implementable, which in
turn implies that the subset of languages lsA and lsP
correspondingly used by <i>s</i><sub>A</sub> and
<i>s</i><sub>P</sub> are also computable and implementable. Thus,
<i>s</i><sub>A</sub> cannot call impossible functions like
&#8220;return_last_digit_of_pi()&#8221;. The languages lsP and lsA
may have many additional capabilities, but for DDC only the proof
assumptions are required.</p>
<p>Reviewers often search to see if a proof works given
&#8220;null&#8221; or &#8220;absurdly small&#8221; cases. Oddly
enough, the proof is still correct in these cases. It is
theoretically possible that one or more of the compilers could be a
one-byte value, a one-bit value, or even null, if the underlying
environment implemented those values according to the proof
assumptions. For example, an environment could theoretically have a
built-in &#8220;compile&#8221; instruction, or implement a
&#8220;compile&#8221; function if it receives an empty sequence.
This is hypothetical; real environments are very unlikely to work
this way. However, there&#8217;s no need to <i>prevent</i> this
possibility, so the proof permits it.</p>
<p>The goal statement compares for equality between stage2 and
c<sub>A</sub>. As noted above, this requires that equality be
correctly implemented; if the equality-checking program is itself
subverted, this proof would not apply, so the equality-checking
program and the environment it runs on must not be subverted.
Similarly, the values stage2 and c<sub>A</sub> that are compared
must be acquired in a trusted manner; if the programs or
environment used to copy them are subverted, then again, the proof
will not apply (because the values the proof applies to might not
be what is being tested).</p>
<p>Note that the converse of the proof #1&#8217;s goal does not
necessarily hold. The converse is:</p>
<pre>
   exactly_correspond(cA,sA,lsA,eArun) -&gt; (stage2 = cA)
</pre>
<p>There are many reasons the converse need not be true. For
example, executable c<sub>A</sub> might have been modified by
adding extra unused information at its end, or had
&#8220;no-operation&#8221; statements inserted into it that do not
change the outputs it produces. Indeed, c<sub>A</sub> could have
been produced by compiling <i>s</i><sub>A</sub> using a different
but trustworthy compiler and environment. In all these cases,
c<sub>A</sub> could exactly correspond to <i>s</i><sub>A</sub>,
even though stage2 is not equal to c<sub>A</sub>. But there
<i>is</i> a common circumstance where stage2 and c<sub>A</sub> must
be equal; showing this is true is the focus of proof #2.</p>
<h2><a name="5.7.Proof #2: Goal always_equal|outline"></a> 5.7
Proof #2: Goal always_equal</h2>
<p>The first proof (source_corresponds_to_executable) shows that if
c<sub>A</sub> and stage2 are equal, then c<sub>A</sub> and
<i>s</i><sub>A</sub> exactly correspond. However, this first proof
is not practically useful if c<sub>A</sub> and stage2 are not
normally equal. So we will next prove that, under &#8220;normal
conditions&#8221;, c<sub>A</sub> and stage2 are in fact always
equal. &#8220;Normal conditions&#8221; is expressed more formally
below, but in particular, this includes the presumption that the
compiler executables have <i>not</i> been tampered with (i.e., that
the compiler executables correspond to their source code). This
proof goal is named &#8220;always_equal&#8221;, and is simply:</p>
<pre>
   cA = stage2.
</pre>
<p>This second proof requires many more assumptions than the
previous proof (9 instead of 5). It reuses 4 previous assumptions:
definition_stage1, definition_stage2, define_exactly_correspond,
and cT_compiles_sP. The new assumptions are definition_cA,
cP_corresponds_to_sP, define_compile,
sP_portable_and_deterministic, and define_determinism, as defined
below. We will avoid making any assumptions about c<sub>GP</sub>, a
possible &#8220;grandparent&#8221; compiler, since there may not
<i>be</i> a grandparent compiler. Proof #3, to follow, will examine
the common case when there <i>is</i> a grandparent compiler.</p>
<p>Interestingly, we do not need the assumption sP_compiles_sA for
this proof. The assumption definition_cA requires, as a
side-effect, that <i>s</i><sub>P</sub> terminate when it compiles
<i>s</i><sub>A</sub>. If <i>s</i><sub>P</sub> terminates but fails
to compile <i>s</i><sub>A</sub>, the results will still be equal;
in this case the processes will produce equal error messages, which
is probably not useful but it does not invalidate the proof. If
<i>s</i><sub>P</sub> terminates and successfully compiles
<i>s</i><sub>A</sub>, then again, the results will be equal if this
section&#8217;s assumptions hold. This would be true even if
<i>s</i><sub>P</sub> has one or more defects that affect compiling
<i>s</i><sub>A</sub>; in such a case, if all the assumptions of
proof #2 hold, then compiler-under-test c<sub>A</sub> and the DDC
result stage2 will be identical and have the same defects. Again,
this does not invalidate DDC; the purpose of DDC is to determine if
source and executable correspond, not to prevent all possible
defects.</p>
<p>In this second proof, the predicates, functions, and assumptions
will now be presented, along with their ramifications. This will be
followed by the complete prover9 proof and a discussion.</p>
<h3><a name="__RefHeading__35672240"></a><a name=
"5.7.1.Reused definitions define_exactly_correspond, definition_stage1, and definition_stage2|outline"></a>
5.7.1 Reused definitions define_exactly_correspond,
definition_stage1, and definition_stage2</h3>
<p>We will reuse several definitions. Here is definition
define_exactly_correspond:</p>
<pre>
   accurately_translates(Compiler, Lang, Source, EnvEffects, ExecEnv,
                         TargetEnv) -&gt; 
        exactly_correspond(compile(Source, Compiler, EnvEffects, ExecEnv,
                                   TargetEnv), Source, Lang, TargetEnv).
</pre>
<p>Definition definition_stage1:</p>
<pre>
   stage1 = compile(sP, cT, e1effects, e1, e2).
</pre>
<p>Definition definition_stage2:</p>
<pre style="font-style: normal">
        stage2 = compile(sA, stage1, e2effects, e2, eArun).
</pre>
<h3><a name="__RefHeading__35635404"></a><a name=
"5.7.2.Assumption cT_compiles_sP|outline"></a> 5.7.2 Assumption
cT_compiles_sP</h3>
<p>We will also reuse assumption cT_compiles_sP from section
5.6.4:</p>
<pre>
   all EnvEffects accurately_translates(cT, lsP, sP, EnvEffects, e1, e2).
</pre>
<h3><a name="__RefHeading__42595127"></a><a name=
"5.7.3.Predicate deterministic_and_portable|outline"></a> 5.7.3
Predicate deterministic_and_portable</h3>
<p>We define a new predicate:</p>
<pre>
   predicate deterministic_and_portable(Source, Language, Input)
</pre>
<p>This predicate is defined to be true if, and only if, the given
Source (when compiled by a correct compiler for Language) is
both:</p>
<ul>
<li>
<p>deterministic (when correctly compiled for an environment, and
run on that environment, it will always produce the same specific
output given the same input Input), and</p>
</li>
<li>
<p>portable (the above is true across the environments used by DDC
and the claimed origin).</p>
</li>
</ul>
<p>A deterministic and portable executable always produces the same
outputs, given the same inputs, in various environments; in this
case, we only care if it is deterministic and portable for a given
environment, and only for a specific input (Input).</p>
<p>A compiler need not be deterministic. For example, when there
are optimization alternatives, a compiler could call a random
number generator in the environment, and use that value to
determine which alternative to choose.</p>
<p>In practice, many compilers are deterministic, or can be
executed in a way that makes them deterministic, because it is much
more difficult to test non-deterministic compilers. Indeed, some
compilers (such as GCC) use self-regeneration as a
self-test&#8212;and such tests require determinism. For example,
GCC&#8217;s C&#8288;+&#8288;+ compiler includes the ability to
control the random number seed used during compilation,
specifically to cause its non-deterministic behavior to become
deterministic. One exception is embedded timestamps: Some object
code formats embed compilation timestamps in the file. If
timestamps are only stored in intermediate formats, and not a final
format, an easy solution is to only compare the final results (see
section 8.6).</p>
<p>Many real-world languages include intentionally non-portable
constructs that provide direct access to the underlying environment
and/or use compiler extensions not supported by other compilers.
For example, languages may provide nonstandard methods for opening
files. However, we must compile the same program using different
compilers, in potentially different environments. Thus, we must
avoid such constructs for DDC, or add those additional requirements
to the language specification and ensure that all the
implementations used in DDC and the claimed origin of the compiler
support them as necessary.</p>
<h3 style="font-style: normal"><a name=
"5.7.4.Function run|outline"></a> 5.7.4 Function run</h3>
<p>Previously we could treat compiling as a &#8220;black
box&#8221;, but for this proof more detail about compilation is
needed. In particular, we must model executing a program. Thus:</p>
<pre>
   function run(Executable, Input, EnvEffects, Environment)
</pre>
<p>is a function that returns data. This data (the output) is the
result of running Executable in Environment, giving it Input and
the various environmental effects EnvEffects. The parameter
&#8220;EnvEffects&#8221; models whatever the language allows the
environment to vary that could have an effect on the results of
running Executable, such as random number generator values or
thread scheduling.</p>
<p>The results include standard out, standard error, and any files
(file names, locations, and contents) generated or modified by its
execution. Since different runs could have different environmental
effects as input (e.g., the random number generator from the
environment might produce something different), it is possible that
running the same executable with the same Input could produce
different results.</p>
<h3 style="font-style: normal"><a name=
"5.7.5.Function converttext|outline"></a> 5.7.5 Function
converttext</h3>
<p>Function converttext models an unfortunate complicating issue in
the real world: Different environments may encode text in different
ways. Function</p>
<pre>
   function converttext(Data, Environment1, Environment2)
</pre>
<p>takes Data, where all text is in the standard text encoding of
Environment1, and returns the same Data but with all text converted
to the standard text encoding of Environment2.</p>
<p>In particular, a new line may be encoded differently by
different environments. Common conventions, and some systems that
use those conventions, include:</p>
<ul>
<li>
<p>Linefeed (#x0A): Unix, GNU/Linux, Mac OS X, Multics.</p>
</li>
<li>
<p>Carriage Return (#x0D): Apple II Disk Operating System (DOS) and
Professional Disk Operating System (ProDOS), Mac OS version 9 and
earlier.</p>
</li>
<li>
<p>Carriage return + Linefeed (#x0D #x0A): Control Program for
Microcomputers (CP/M), Microsoft Disk Operating System (MS-DOS),
Microsoft Windows.</p>
</li>
<li>
<p>Newline NEL (#x85): IBM System/390 operating-system (OS/390)
[Malaika2001].</p>
</li>
</ul>
<p>Similarly, not all computer systems encode text characters the
same way. They may use (for example) ASCII, 8-bit (UCS)/Unicode
Transformation Format UTF-8<a class="sdfootnoteanc" name=
"sdfootnote15anc" href="#sdfootnote15sym"><sup>15</sup></a>, UTF-16
(which may be little-endian or big-endian), a locale-specific
encoding, or even EBCDIC.</p>
<p>Since we will later compare values for exact equality, modeling
these differences is necessary.</p>
<h3 style="font-style: normal"><a name=
"5.7.6.Function extract|outline"></a> 5.7.6 Function extract</h3>
<p>Function extract accepts data, and returns a subset of that
data:</p>
<pre>
   function extract(Data)
</pre>
<p>More specifically, function extract() extracts <i>only</i> the
executable produced by a compiler, and silently throws away the
rest (e.g., warning and error reports made during the compilation
process). A compilation process runs a compiler, and a compiler
produces many outputs &#8211; but we only want the data that will
be later used for execution. In a typical compilation environment,
extract() will produce just the generated executable files, and not
outputs to standard out, standard error, and/or log files.</p>
<h3 style="font-style: normal"><a name=
"5.7.7.Function retarget|outline"></a> 5.7.7 Function retarget</h3>
<p>Function retarget accepts source and target, and returns
possibly modified source:</p>
<pre>
   function retarget(Source, Target)
</pre>
<p>Retarget represents any modifications to the source code Source
that are necessary to change it so it will compile to run on the
target environment Target. In many circumstances, Source will
include various flags to the compiler that determine what
environment the compiled executable will run on. If a different
execution environment is to be used, the Source may need to be
modified. If no such modifications are needed, retarget simply
returns Source.</p>
<h3><a name="__RefHeading__33162692"></a><a name=
"5.7.8.Assumption sP_portable_and_deterministic|outline"></a> 5.7.8
Assumption sP_portable_and_deterministic</h3>
<p>We will assume that source <i>s</i><sub>P</sub>, when compiled,
describes a portable and deterministic program, when used to
compile <i>s</i><sub>A</sub> (once it is retargeted to generate
code for eArun):</p>
<pre>
   portable_and_deterministic(sP, lsP, retarget(sA, eArun)).
</pre>
<p>This means that:</p>
<ul>
<li>
<p>Source <i>s</i><sub>P</sub> must avoid all non-portable
capabilities of language lsP, or use them only in ways that will
not affect the output of the program when compiling
<i>s</i><sub>A</sub>.. For example, if a &#8220;+&#8221; operator
is used in the source code, then the language must include this
operator, the language must provide the semantics required by the
source code (e.g., &#8220;add two integers&#8221; if
<i>s</i><sub>P</sub> requires this meaning), and the language must
require support for the domain of values used as inputs to the
operator when processing Input. As noted in section 5.6.4.1, the
language noted here is not necessarily an official standard; it
might, for example, be a subset and/or superset of a official
standard.</p>
</li>
<li>
<p>Source <i>s</i><sub>P</sub> may use constructs that are
individually non-deterministic (such as threads with
non-deterministic scheduling), but if it does it must use
mechanisms to make to ensure that the output will be the same on
each execution given the same input (for example, it could use
locks to ensure that thread scheduling variation does not cause
variation in the results). In some cases, setting the random number
seed and algorithm for &#8220;randomness&#8221; may be necessary to
ensure determinism.</p>
</li>
</ul>
<p>Note that we do <i>not</i> require that c<sub>T</sub> or the
grandparent compiler c<sub>GP</sub> (if it exists) be portable or
deterministic. They <i>could</i> be portable and/or deterministic,
and often will be, but this is not necessary.</p>
<p>It is possible that some constructs in <i>s</i><sub>P</sub> are
non-deterministic or non-portable; this is acceptable as long as
they do not affect the use of <i>s</i><sub>P</sub> to compile the
retargeted <i>s</i><sub>A</sub>. However, even if
<i>s</i><sub>P</sub> includes non-deterministic or non-portable
constructs, definition_stage1 (see section 5.7.1) still requires
that the trusted compiler c<sub>T</sub> must be able to
<i>compile</i><i>s</i><sub>P</sub>.</p>
<h3><a name="__RefHeading__34391297"></a><a name=
"5.7.9.Definition define_portable_and_deterministic|outline"></a>
5.7.9 Definition define_portable_and_deterministic</h3>
<p>Under certain conditions, the same source code can be compiled
by different compilers, and when the different executables are run
with the same inputs, they must produce the same outputs. More
precisely, if the source code uses only the portable and
deterministic capabilities of a language when properly compiled and
run to process a specific input Input, then given two executables
that exactly correspond to that same source code (possibly running
in different environments), then those executables&#8212;when given
the same input Input&#8212;will produce the same output (other than
text format differences). This is expressed as follows:</p>
<pre>
 ( portable_and_deterministic(Source, Language, Input) &amp;
   exactly_correspond(Executable1, Source, Language, Environment1) &amp;
   exactly_correspond(Executable2, Source, Language, Environment2)) -&gt;
     ( converttext(run(Executable1, Input, EnvEffects1, Environment1),
                   Environment1, Target) =
       converttext(run(Executable2, Input, EnvEffects2, Environment2),
                   Environment2, Target))
</pre>
<p>This is perhaps best explained by a sequence of two examples.
Let us first consider this simple C program, which computes 2+2 and
prints the result:</p>
<pre>
   #include &lt;stdio.h&gt;
   main() {
     printf("%d\n", 2+2);
   }
</pre>
<p>Now imagine two different properly-working C compilers given
this code. The two executables produced by the two different C
compilers will almost certainly be different. However,
<i>running</i> these two executables on their respective
environments <i>must</i> produce the same result &#8220;4&#8221;
(once text encoding is taken into account).</p>
<p>Now consider this program; it reads a number, adds one to it,
and prints the result:</p>
<pre>
   #include &lt;stdio.h&gt;
   main() {
    int x;
    scanf("%d", &amp;x);
    x++;
    printf("%d\n", x);
   }
</pre>
<p>Again, after using different properly-working C compilers, the
two executables produced will almost certainly be different. Will
<i>running</i> the two executables always produce the same outputs?
It turns out that this depends on the inputs. Running these two
executables on their respective environments, with the same input
&#8220;5&#8221;, must produce the same result &#8220;6&#8221; (once
text encoding is taken into account), because the language
definition requires that implementations be able to correctly read
in 5, add one (producing 6), and be able to print it.</p>
<p>However, this is <i>not</i> necessarily true with a different
input. The C language specification only guarantees that an
&#8220;int&#8221; can store and process integers within the range
of a 16-bit twos-complement signed integer [ISO1999, section
5.2.4.2.1]. Thus, if 2147483648 (2<sup>31</sup>) is provided as
input, we cannot be certain that the executables will do the same
thing. It would be quite possible for the different executables to
produce different results in such cases, because processing such
input is not within the portable range defined by the language.</p>
<p>In this particular example, we could change to another language
which required this particular input to be processed identically
(e.g., the language could be &#8220;Standard C, but int must be at
least 64 bits long&#8221;). In practice, many language
specifications include limits on what is portable and
deterministic, and the inputs must not exceed those limits for the
result to be portable and deterministic.</p>
<h3><a name="__RefHeading__38162266"></a><a name=
"5.7.10.Assumption cP_corresponds_to_sP|outline"></a> 5.7.10
Assumption cP_corresponds_to_sP</h3>
<p>How was compiler-under-test c<sub>A</sub> created? The putative
origin of c<sub>A</sub> is that it was compiled by compiler
c<sub>P</sub>, and that c<sub>P</sub>&#8217;s executable exactly
corresponds to source <i>s</i><sub>P</sub>. For the moment, we will
simply assume this, as this is true for the benign case we are
considering in proof #2:</p>
<pre>
   exactly_correspond(cP, sP, lsP, eA).
</pre>
<p>In many cases c<sub>P</sub> will have been created by compiling
<i>s</i><sub>P</sub> using some grandparent compiler
c<sub>GP</sub>. Proof #3 will show that this assumption
(cP_corresponds_to_sP) can be proven given certain other plausible
assumptions, including the existence of a grandparent compiler.
However, by making this a simple assumption in proof #2, proof #2
is more general. For example, it is possible that c<sub>P</sub> was
created by hand-translating <i>s</i><sub>P</sub> into an
executable; in this case, there may be no executable that is the
grandparent compiler (since a human acted as the grandparent
compiler), yet it may still be possible to accept this
assumption.</p>
<h3><a name="5.7.11.Definition define_compile|outline"></a> 5.7.11
Definition define_compile</h3>
<p>In the previous proof we had simply accepted
&#8220;compile&#8221; as a function that produced data:</p>
<pre>
   compile(Source, Compiler, EnvEffects, RunOn, Target)
</pre>
<p>This represents compiling Source with the Compiler, running it
in environment RunOn, but targeting the result for environment
Target.</p>
<p>However, for this proof, more detail about the compilation
process is needed, so the compilation process will now be modeled
using more primitive functions:</p>
<pre>
   compile(Source, Compiler, EnvEffects, RunOn, Target) =
           extract(converttext(run(Compiler, retarget(Source, Target),
                   EnvEffects, RunOn), RunOn, Target)).
</pre>
<p>This is easier to explain by beginning on the right-hand-side,
going from the inside expressions out. First, the Source is
retargeted so that it will compile for environment Target (this
typically involves changing compiler flags so that they will
specify the new target). Then run the Compiler on the environment
RunOn with the retargeted Source code as input; note that if
Compiler is a non-deterministic compiler, the environmental
EnvEffects may have an effect on the results. The output will
probably include text results (such as warnings, errors, and
possibly the resulting executable depending on the kind of compiler
it is). This text is then converted to Target&#8217;s standard text
format. Finally, the portions of the compilation results that can
be run later are extracted; the rest of the material (such as
warning text) is thrown away.</p>
<p>In practice, converttext only needs to be applied to text that
will be extracted. If it will be thrown away, then there&#8217;s no
need to actually perform the conversion. But this is merely an
optimization, and not necessary for the proof; it is easier to
model as shown above.</p>
<h3><a name="__RefHeading__38181080"></a><a name=
"5.7.12.Definition definition_cA|outline"></a> 5.7.12 Definition
definition_cA</h3>
<p>How was compiler-under-test c<sub>A</sub> generated? Putatively
it was generated by compiling source <i>s</i><sub>A</sub>, using
compiler c<sub>P</sub>. This is easily modeled, in a manner similar
to stage1 and stage2:</p>
<pre>
   cA = compile(sA, cP, eAeffects, eA, eArun).
</pre>
<p>It&#8217;s quite possible that this assumption is not true,
e.g., perhaps the executable of the compiler-under-test was
recently replaced by a corrupt executable (such as a maliciously
corrupted executable). But for proof #2, we are considering what
happens in the benign circumstance (where the putative origins are
true), to show that a benign environment <i>must</i> produce a
match.</p>
<h3><a name="5.7.13.Goal always_equal|outline"></a>5.7.13 Goal
always_equal</h3>
<p>Recall that the goal is to prove, given the preceding
assumptions:</p>
<pre>
   cA = stage2.
</pre>
<h3><a name=
"5.7.14.Prover9 proof of always_equal|outline"></a>5.7.14 Prover9
proof of always_equal</h3>
<p>Table 3 presents the proof found by prover9.</p>
<p><a name="table3"></a><font size="3"><i>Table 3: Proof #2
(always_equal) in prover9 format</i></font></p>
<table width="576" border="1" bordercolor="#000000" cellpadding="2"
cellspacing="0">
<col width="15">
<col width="468">
<col width="79">
<tr>
<th width="15" bgcolor="#C0C0C0">
<p>#</p>
</th>
<th width="468" bgcolor="#C0C0C0">
<p>Formula</p>
</th>
<th width="79" bgcolor="#C0C0C0">
<p>Rationale</p>
</th>
</tr>
<tr>
<td width="15">1</td>
<td width="468">portable_and_deterministic(A,B,C) &amp;
exactly_correspond(D,A,B,E) &amp; exactly_correspond(F,A,B,V6)
-&gt; converttext(run(D,C,V7,E),E,V8)
=converttext(run(F,C,V9,V6),V6,V8)</td>
<td width="79">Assumption
define_&#8203;portable_&#8203;and_&#8203;deterministic</td>
</tr>
<tr>
<td width="15">2</td>
<td width="468">accurately_translates(A,B,C,D,E,F) -&gt;
exactly_correspond(compile(C,A,D,E,F),C,B,F)</td>
<td width="79">Assumption
define_&#8203;exactly_&#8203;correspond</td>
</tr>
<tr>
<td width="15">3</td>
<td width="468">(all A
accurately_translates(cT,lsP,sP,A,e1,e2))</td>
<td width="79">Assumption cT_&#8203;compiles_&#8203;sP</td>
</tr>
<tr>
<td width="15">4</td>
<td width="468">cA = stage2</td>
<td width="79">Goal always_&#8203;equal</td>
</tr>
<tr>
<td width="15">5</td>
<td width="468">
portable_and_deterministic(sP,lsP,retarget(sA,eArun))</td>
<td width="79">Assumption
sP_&#8203;portable_&#8203;and_&#8203;deterministic</td>
</tr>
<tr>
<td width="15">6</td>
<td width="468">-portable_and_deterministic(A,B,C) |
-exactly_correspond(D,A,B,E) | -exactly_correspond(F,A,B,V6) |
converttext(run(F,C,V7,V6),V6,V8)
=converttext(run(D,C,V9,E),E,V8)</td>
<td width="79">Clausify 1</td>
</tr>
<tr>
<td width="15">7</td>
<td width="468">accurately_translates(cT,lsP,sP,A,e1,e2)</td>
<td width="79">Clausify 3</td>
</tr>
<tr>
<td width="15">8</td>
<td width="468">-accurately_translates(A,B,C,D,E,F) |
exactly_correspond(compile(C,A,D,E,F),C,B,F)</td>
<td width="79">Clausify 2</td>
</tr>
<tr>
<td width="15">9</td>
<td width="468">exactly_correspond(cP,sP,lsP,eA)</td>
<td width="79">Assumption
cP_&#8203;corresponds_&#8203;to_&#8203;sP</td>
</tr>
<tr>
<td width="15">10</td>
<td width="468">compile(A,B,C,D,E)
=extract(converttext(run(B,retarget(A,E),C,D),D,E))</td>
<td width="79">Assumption
cP_&#8203;corresponds_&#8203;to_&#8203;sP</td>
</tr>
<tr>
<td width="15">11</td>
<td width="468">stage1 = compile(sP,cT,e1effects,e1,e2)</td>
<td width="79">Assumption definition_&#8203;stage1</td>
</tr>
<tr>
<td width="15">12</td>
<td width="468">stage1
=extract(converttext(run(cT,retarget(sP,e2),e1effects,e1),e1,e2))</td>
<td width="79">Para 10 11</td>
</tr>
<tr>
<td width="15">13</td>
<td width="468">
extract(converttext(run(cT,retarget(sP,e2),e1effects,e1),e1,e2)) =
stage1</td>
<td width="79">Copy 12, flip</td>
</tr>
<tr>
<td width="15">14</td>
<td width="468">stage2 = compile(sA,stage1,e2effects,e2,eArun)</td>
<td width="79">Assumption definition_&#8203;stage2</td>
</tr>
<tr>
<td width="15">15</td>
<td width="468">stage2
=extract(converttext(run(stage1,retarget(sA,eArun),e2effects,e2),e2,eArun))</td>
<td width="79">Para 10 14</td>
</tr>
<tr>
<td width="15">16</td>
<td width="468">cA = compile(sA,cP,eAeffects,eA,eArun)</td>
<td width="79">Assumption definition_&#8203;cA</td>
</tr>
<tr>
<td width="15">17</td>
<td width="468">cA
=extract(converttext(run(cP,retarget(sA,eArun),eAeffects,eA),eA,eArun))</td>
<td width="79">Para 10 16</td>
</tr>
<tr>
<td width="15">18</td>
<td width="468">cA != stage2</td>
<td width="79">Deny 4</td>
</tr>
<tr>
<td width="15">19</td>
<td width="468">
extract(converttext(run(cP,retarget(sA,eArun),eAeffects,eA),eA,eArun))
!= stage2</td>
<td width="79">Para 17 18</td>
</tr>
<tr>
<td width="15">20</td>
<td width="468">
extract(converttext(run(cP,retarget(sA,eArun),eAeffects,eA),eA,eArun))
!=extract(converttext(run(stage1,retarget(sA,eArun),e2effects,e2),e2,eArun))</td>
<td width="79">Para 15 19</td>
</tr>
<tr>
<td width="15">21</td>
<td width="468">
extract(converttext(run(stage1,retarget(sA,eArun),e2effects,e2),e2,eArun))
!=extract(converttext(run(cP,retarget(sA,eArun),eAeffects,eA),eA,eArun))</td>
<td width="79">Copy 20, flip</td>
</tr>
<tr>
<td width="15">22</td>
<td width="468">-exactly_correspond(A,sP,lsP,B) |
-exactly_correspond(C,sP,lsP,D) |
converttext(run(C,retarget(sA,eArun),E,D),D,F)
=converttext(run(A,retarget(sA,eArun),V6,B),B,F)</td>
<td width="79">Resolve 5 6</td>
</tr>
<tr>
<td width="15">23</td>
<td width="468">
exactly_correspond(compile(sP,cT,A,e1,e2),sP,lsP,e2)</td>
<td width="79">Resolve 7 8</td>
</tr>
<tr>
<td width="15">24</td>
<td width="468">
exactly_correspond(extract(converttext(run(cT,retarget(sP,e2),A,e1),e1,e2)),&#8203;sP,lsP,e2)</td>
<td width="79">Para 10 23</td>
</tr>
<tr>
<td width="15">25</td>
<td width="468">exactly_correspond(stage1,sP,lsP,e2)</td>
<td width="79">Para 13 24</td>
</tr>
<tr>
<td width="15">26</td>
<td width="468">-exactly_correspond(A,sP,lsP,B) |
converttext(run(A,retarget(sA,eArun),C,B),B,D)
=converttext(run(cP,retarget(sA,eArun),E,eA),eA,D)</td>
<td width="79">Resolve 22 9</td>
</tr>
<tr>
<td width="15">27</td>
<td width="468">
converttext(run(stage1,retarget(sA,eArun),A,e2),e2,B)
=converttext(run(cP,retarget(sA,eArun),C,eA),eA,B)</td>
<td width="79">Resolve 26 25</td>
</tr>
<tr>
<td width="15">28</td>
<td width="468">compile(sA,stage1,A,e2,eArun)
=extract(converttext(run(cP,retarget(sA,eArun),B,eA),eA,eArun))</td>
<td width="79">Para 27 10</td>
</tr>
<tr>
<td width="15">29</td>
<td width="468">
extract(converttext(run(stage1,retarget(sA,eArun),A,e2),e2,eArun))
=extract(converttext(run(cP,retarget(sA,eArun),B,eA),eA,eArun))</td>
<td width="79">Para 10 28</td>
</tr>
<tr>
<td width="15">30</td>
<td width="468">$F</td>
<td width="79">Resolve 29 21</td>
</tr>
</table>
<h3><a name="5.7.15.Discussion of proof #2|outline"></a> 5.7.15
Discussion of proof #2</h3>
<p>Note that proof #2&#8217;s goal <i>could</i> be true, even if
some of proof #2&#8217;s assumptions (above) are false. First, note
that the goal of proof #2 is:</p>
<pre>
   stage2 = cA.
</pre>
<p>This equality <i>could</i>, in theory, have occurred by other
means. As an extreme example, perhaps c<sub>A</sub> was created by
randomly generating data of the same length and then using it as an
executable. In practice, even minor changes (other than changing
comments) that invalidate any of proof #2&#8217;s assumptions will
tend to make this goal fail. As shown in chapter 7, DDC is
extremely sensitive to even very minor deviations that make one of
proof #2&#8217;s assumptions false.</p>
<p>Since c<sub>A</sub>=stage2 when proof #2&#8217;s assumptions are
true, then if c<sub>A</sub>&#8800;stage2, then at least one of the
assumptions of proof #2 <i>must</i> be false. For example, if
c<sub>A</sub>&#8800;stage2, perhaps compiler executable
c<sub>P</sub> is corrupted; this would mean assumption
cP_exactly_corresponds is false. Similarly, perhaps compiler
executable c<sub>A</sub> is corrupted (e.g., it was replaced by
some corrupt executable); this would mean that assumption
definition_cA is false. If we only know that
c<sub>A</sub>&#8800;stage2, we cannot determine from this proof
<i>which</i> assumption(s) are false. However, once we know that
c<sub>A</sub>&#8800;stage2, we can then try to obtain other
information to determine the cause(s).</p>
<p>Note that this proof permits
<i>s</i><sub>P</sub>&#8800;<i>s</i><sub>A</sub> and
c<sub>P</sub>&#8800;c<sub>A</sub>, but it does not <i>require</i>
it. Thus, it&#8217;s quite possible that
<i>s</i><sub>P</sub>=<i>s</i><sub>A</sub> and/or
c<sub>P</sub>=c<sub>A</sub>.</p>
<h2><a name="5.8.Proof #3: Goal cP_corresponds_to_sP|outline"></a>
5.8 Proof #3: Goal cP_corresponds_to_sP</h2>
<p>Proof #2 is intentionally designed to not require that a
grandparent compiler c<sub>GP</sub> exist in the putative origins
of c<sub>A</sub>. But having a grandparent compiler is a common
circumstance, and in this circumstance, one of the assumptions of
proof #2 can be proved using other assumptions that may be easier
to confirm.</p>
<p>Proof #2 depended on assumption cP_corresponds_to_sP (see
section 5.7.10):</p>
<pre>
   exactly_correspond(cP, sP, lsP, eA).
</pre>
<p>If a putative grandparent compiler c<sub>GP</sub> <i>does</i>
exist, this assumption is easily proven given some different
assumptions. Simply reuse define_exactly_correspond as already
defined, and add definition definition_cP and assumption
cGP_compiles_sP as described below.</p>
<h3><a name="5.8.1.Definition definition_cP|outline"></a> 5.8.1
Definition definition_cP</h3>
<p>First, we must define how cP was putatively generated &#8211; by
grandparent compiler c<sub>GP</sub>:</p>
<pre>
   cP = compile(sP, cGP, ePeffects, eP, eA).
</pre>
<p>Note the strong similarity to definition_cA used earlier in
section 5.7.12.</p>
<h3><a name="__RefHeading__34623629"></a><a name=
"5.8.2.Assumption cGP_compiles_sP|outline"></a> 5.8.2 Assumption
cGP_compiles_sP</h3>
<p>We also need to assume that the grandparent compiler cGP will
accurately translate the source code <i>s</i><sub>P</sub>:</p>
<pre>
   all EnvEffects accurately_translates(cGP, lsP, sP, EnvEffects, eP, eA).
</pre>
<p>Note the strong similarity to cT_compiles_sP in section
5.6.4.</p>
<h3><a name="5.8.3.Goal cP_corresponds_to_sP|outline"></a> 5.8.3
Goal cP_corresponds_to_sP</h3>
<p>Given define_exactly_correspond, definition_cP, and
cGP_compiles_sP, as described above, the goal is trivially proved
by prover9 (as shown below). Recall that the goal is:</p>
<pre>
   exactly_correspond(cP, sP, lsP, eA).
</pre>
<h3><a name=
"5.8.4.Prover9 proof of cP_corresponds_to_sP|outline"></a>5.8.4
Prover9 proof of cP_corresponds_to_sP</h3>
<p>Table 4 presents the proof found by prover9.</p>
<p><a name="table4"></a><font size="3"><i>Table 4: Proof #3
(cP_corresponds_to_sP) in prover9 format</i></font></p>
<table width="574" border="1" bordercolor="#000000" cellpadding="2"
cellspacing="0" style="page-break-inside: avoid">
<col width="23">
<col width="380">
<col width="157">
<tr>
<th width="23" bgcolor="#C0C0C0">
<p>#</p>
</th>
<th width="380" bgcolor="#C0C0C0">
<p>Formula</p>
</th>
<th width="157" bgcolor="#C0C0C0">
<p>Rationale</p>
</th>
</tr>
<tr>
<td width="23">1</td>
<td width="380">(all A
accurately_translates(cGP,lsP,sP,A,eP,eA))</td>
<td width="157">Assumption cGP_compiles_sP</td>
</tr>
<tr>
<td width="23">2</td>
<td width="380">accurately_translates(A,B,C,D,E,F) -&gt;
exactly_correspond(compile(C,A,D,E,F),C,B,F)</td>
<td width="157">Assumption
define_&#8203;exactly_&#8203;correspond</td>
</tr>
<tr>
<td width="23">3</td>
<td width="380">exactly_correspond(cP,sP,lsP,eA)</td>
<td width="157">Goal cP_corresponds_&#8203;to_sP</td>
</tr>
<tr>
<td width="23">4</td>
<td width="380">-accurately_translates(A,B,C,D,E,F) |
exactly_correspond(compile(C,A,D,E,F),C,B,F)</td>
<td width="157">Clausify 2</td>
</tr>
<tr>
<td width="23">5</td>
<td width="380">accurately_translates(cGP,lsP,sP,A,eP,eA)</td>
<td width="157">Clausify 1</td>
</tr>
<tr>
<td width="23">6</td>
<td width="380">cP = compile(sP,cGP,ePeffects,eP,eA)</td>
<td width="157">Assumption definition_cP</td>
</tr>
<tr>
<td width="23">7</td>
<td width="380">-exactly_correspond(cP,sP,lsP,eA)</td>
<td width="157">Deny 3</td>
</tr>
<tr>
<td width="23">8</td>
<td width="380">
-exactly_correspond(compile(sP,cGP,ePeffects,eP,eA),&#8203;sP,lsP,eA)</td>
<td width="157">Para 6 7</td>
</tr>
<tr>
<td width="23">9</td>
<td width="380">
exactly_correspond(compile(sP,cGP,A,eP,eA),sP,lsP,eA)</td>
<td width="157">Resolve 4 5</td>
</tr>
<tr>
<td width="23">10</td>
<td width="380">$F</td>
<td width="157">Resolve 9 8</td>
</tr>
</table>
<h3><a name="5.8.5.Discussion of proof #3|outline"></a> 5.8.5
Discussion of proof #3</h3>
<p>Proof #3 shows that, when a grandfather compiler is used as part
of a benign environment, an assumption of proof #2
(cP_corresponds_to_sP) is true.</p>
<h1><a name="__RefHeading__36132387"></a><a name=
"6.Methods to increase diversity|outline"></a> 6 Methods to
increase diversity</h1>
<p>As discussed in section 4.3, DDC must be executed using only
&#8220;trusted&#8221; processes and programs. Something is trusted
to the extent that there is justified confidence that it does not
have triggers and payloads that would affect the results of
DDC.</p>
<p>This confidence can be gained in a variety of ways. One method
to gain such confidence is to perform a complete formal proof of
the compiler executable c<sub>T</sub> and of the environments used
in DDC, along with evidence that what actually runs is what was
proved. But such proofs are difficult to perform with compilers
typically used in industry. Another method to gain such confidence
is to re-apply DDC on compiler c<sub>T</sub> and/or the DDC
environments; this can help, but re-applying DDC would require the
use of yet <i>another</i> trusted compiler and environments, and
this application of DDC would repeat until there was (1) a
&#8220;final&#8221; trusted compiler and environments, or (2) a
loop of trusted compilers and environments. In either case, at that
point some <i>other</i> method is needed to increase confidence in
the trusted compiler and environments.</p>
<p>A simple method to gain such confidence is through diversity.
Diversity can <i>greatly</i> reduce the likelihood that trusted
compiler c<sub>T</sub> and the DDC environments have relevant
triggers and payloads, often at far less cost than other
approaches. There are many ways we can gain diversity; these
include diversity in compiler implementation, in time, in
environment, and in input source code. These can be combined to
further increase confidence that relevant triggers and payloads
will not activate.</p>
<h2><a name="__RefHeading__38285263"></a><a name=
"6.1.Diversity in compiler implementation|outline"></a>6.1
Diversity in compiler implementation</h2>
<p>Compiler c<sub>T</sub>&#8217;s executable could be a completely
different implementation than compiler c<sub>A</sub> or
c<sub>P</sub>. This means it would have no (or little) shared code
or data structures. It would be best if the source code of
c<sub>T</sub> did not have a common ancestor with c<sub>A</sub> or
c<sub>P</sub>, since having a common ancestor greatly increases the
likelihood of shared code or data structures. Using a completely
different implementation reduces the risk that c<sub>T</sub>
includes triggers or payloads that affect c<sub>P</sub> or
c<sub>A</sub>. Compiler c<sub>T</sub>&#8217;s executable could
include triggers and payloads for compilers other than
c<sub>T</sub>, but this is less likely.</p>
<p>Ideally, no previous version of compiler c<sub>T</sub> would
have been compiled by any version of compiler c<sub>A</sub> or
c<sub>P</sub>, even in c<sub>T</sub>&#8217;s initial bootstrap.
This is because compiler c<sub>A</sub> or c<sub>P</sub> could
insert into the executable code some routines to check for any
processing of compiler c<sub>A</sub> or c<sub>P</sub> so that it
can later &#8220;re-infect&#8221; itself. This kind of attack is
difficult to do, especially since bootstrapping is usually done
very early in a compiler&#8217;s development and an attacker may
not even be aware of compiler c<sub>T</sub>&#8217;s existence. One
of the most obvious locations where this might be practical might
be in the input/output (I/O) routines. However, I/O routines are
more likely to be viewed at the assembly or machine level than some
other routines (e.g., to do performance analysis), so an attacker
risks discovery if they subvert I/O routines.</p>
<h2><a name="__RefHeading__43512020"></a><a name=
"6.2.Diversity in time|outline"></a>6.2 Diversity in time</h2>
<p>If compiler c<sub>T</sub> and the DDC environment were developed
long before the compiler c<sub>P</sub> and c<sub>A</sub>, and they
do not share a common implementation heritage, it is improbable
that compiler c<sub>T</sub> or its environment would include
relevant triggers for a not-yet-implemented compiler. Magdsick
makes a similar point [Magdsick2003]. In theory, a compiler author
could attempt to develop a newer compiler&#8217;s source code so
that it would be subverted by older compiler executables, but this
requires control over the newer compiler&#8217;s source code,
explicit knowledge of the triggers and payloads of the older
compiler, and triggers and payloads in the older compiler that
would be relevant to a newer, different compiler.</p>
<p>The reverse (using a newer compiler executable to check an older
compiler executable) gains less confidence. This is because it is
easier for a recently-released compiler executable to include
triggers and payloads for many older compilers, including
completely different compilers. Nevertheless, this can still
increase confidence somewhat, since to avoid detection by DDC the
attacker must successfully subvert multiple compiler
executables.</p>
<p>Diversity in time can only provide significant confidence if it
can be clearly verified that the &#8220;older&#8221; materials are
truly the ones that existed at the earlier time. This is because a
resourceful attacker could tamper with those copies if given an
opportunity to do so. Instead, protected copies of the original
media should be preferred to reduce the risk of tampering. Multiple
independently-maintained copies can be compared with each other to
verify that the data used is correct. Cryptographic hashes can be
used to verify the media; multiple hash algorithms should be used,
in case a hash algorithm is broken.</p>
<p>An older executable version of compiler c<sub>A</sub> or
c<sub>P</sub> can be used as compiler c<sub>T</sub> if there is
reason to believe that the older version is not corrupt or that any
Trojan horse in the older version of c<sub>A</sub> will not be
triggered by <i>s</i><sub>A</sub>. Note that this is a weaker test;
the common ancestor could have been subverted. This technique gives
greater confidence if the changes in the compiler have been so
significant that the newer version is in essence a different
compiler, but it would be best if compiler c<sub>T</sub> were truly
a separate implementation.</p>
<h2><a name="6.3.Diversity in environment|outline"></a>6.3
Diversity in environment</h2>
<p>Different environments could be used in the DDC process than
were used for the original generation of c<sub>A</sub>. The term
&#8220;environment&#8221; here means the entire infrastructure
supporting the compiler including the CPU architecture, operating
system, supporting libraries, and so on. Using a completely
different environment counters Trojan horses whose triggers and
payloads are actually in the executables of the environment, as
well as countering triggers and payloads that only work on a
specific operating system or CPU architecture.</p>
<p>These benefits could be partly achieved through emulation of a
different system. There is always the risk that the emulation
system or underlying environment could be subverted specifically to
give misleading results, but attackers will often find this
difficult to achieve, particularly if the emulation system is
developed specifically for this test (an attacker might have to
develop the attack before the system was built!).</p>
<p>In any case, the environment used to execute the DDC process
should be isolated from other tasks. It should not be running any
other processes (which might try to use kernel vulnerabilities to
detect a compilation and subvert it), and it should have limited
(or no) network access.</p>
<h2><a name="6.4.Diversity in source code input|outline"></a>6.4
Diversity in source code input</h2>
<p>Another way to add diversity would be to use mutated source code
[Draper1984] [McDermott1988]. The purpose of mutating source code
is to make it less likely that triggers designed to attack the
compilation of <i>s</i><sub>P</sub> or <i>s</i><sub>A</sub> will
activate, and if they do, to reduce the likelihood that any
payloads will be effective.</p>
<p>In terms of DDC, compiler c<sub>T</sub> would become a source
code transform (the mutator), a compiler (possibly an original
compiler) c<sub>X</sub>, and possibly a postprocessing step. These
mutations could be implemented by automated tools, or even
manually. The resulting c<sub>T</sub> must be trusted, so trust
must be given to the mutator(s), and the mutators must cause
sufficient change so that any triggers or payloads in c<sub>X</sub>
will not have an effect when used as part of DDC.</p>
<p>There are two major types of mutations of source code:
semantics-preserving and non-semantics preserving:</p>
<ul>
<li value="1">
<p>In semantics-preserving mutations, the source code is changed to
an equivalent program (that is, it will continue to produce the
same outputs given the same inputs). This could include mutations
such as renaming items (such as variables, functions, and/or
filenames), reordering statements where the order is irrelevant,
and regrouping statements. It can also include much more
substantive changes, such as translating the source code into a
different programming language. Even trivial changes, such as
changing whitespace, slightly increases diversity (though typically
not enough by itself to justify a claim that all potential triggers
and payloads are disabled). Forrest discusses several methods for
introducing diversity [Forrest1997].</p>
</li>
<li>
<p>In non-semantics-preserving mutations, the original semantics of
the source code as presented to the compiler are <i>not</i>
preserved. Instead, the goal is to preserve the necessary semantics
of the source code when executed with the addition of preprocessing
of its input to the execution and/or postprocessing of the
execution output. Often this involves adding extraneous
functionality to the source code, whose output is removed by the
postprocessor, in the hope that this will cause triggers and
payloads to fail. For example, the mutator may insert an additional
text formatter that generates formatted output as well as an
executable; the postprocessor must then remove or throw out that
extraneous information. One challenge of this approach is that
since semantics are no longer preserved, the postprocessing must
remove changes that would affect DDC. McDermott discusses the
advantage of this approach [McDermott1988].</p>
</li>
</ul>
<p>Mutations can also be used to determine the specification of
language lsP with greater precision<a class="sdfootnoteanc" name=
"sdfootnote16anc" href="#sdfootnote16sym"><sup>16</sup></a>.
Presume that we have a non-mutated <i>s</i><sub>P</sub> and that we
can verify c<sub>A</sub> using DDC. We can then apply successive
semantics-preserving mutations to <i>s</i><sub>P</sub> (e.g.,
focusing on areas that the language specification leaves undefined)
and see if they cause a false negative. If a mutation causes a
false negative, that mutation reveals an undocumented requirement
of language lsP.</p>
<h1><a name="__RefHeading__32545344"></a><a name=
"7.Demonstrations of DDC|outline"></a> 7 Demonstrations of DDC</h1>
<p>The formal proof only shows that if something <i>could</i> be
done, it would produce certain specific results. This chapter
documents several demonstrations showing that DDC <i>can</i> be
performed in the real world, and is thus a <i>practical</i>
technique. This chapter presents results from tcc (a small C
compiler), ported versions of Goerigk&#8217;s Lisp compilers (one
of which is known to be a maliciously corrupted executable), and
the widely-used industrial-strength GNU Compiler Collection (GCC) C
compiler. In some cases, it will be important to track certain
libraries separately from the &#8220;compiler source code&#8221; as
it is traditionally defined; in such cases, the figures will show
them as separate inputs.</p>
<h2><a name="7.1.tcc|outline"></a>7.1 tcc</h2>
<p>Before [Wheeler2005], there had been no public evidence that DDC
had been used. One 2004 GCC mailing list posting stated,
&#8220;I&#8217;m not aware of any ongoing effort,&#8221;
[Lord2004]; another responded, &#8220;I guess we all sorta hope
someone else is doing it.&#8221; [Jendrissek2004]. This section
describes its first demonstration (from [Wheeler2005]).</p>
<p>A public demonstration requires a compiler whose source code is
publicly available. Other ideal traits for the initial test case
included being relatively small and self-contained, running quickly
(so that test runs would be rapid), having an open source software
license (so the experiment could be repeated and changes could be
publicly redistributed [Wheeler2005]), and being easily compiled by
another compiler. The compiler needed to be relatively defect-free,
since defects would interfere with these tests. The Tiny C
Compiler, abbreviated as TinyCC or tcc, was chosen as it appeared
to meet these criteria.</p>
<p>The compiler tcc was developed by Fabrice Bellard and is
available from its website at <a href=
"http://www.tinycc.org/">http://www.tinycc.org</a>/. This project
began as the Obfuscated Tiny C Compiler, a very small C compiler
Bellard wrote to win the International Obfuscated C Code Contest in
2002. He then expanded this small compiler so that it now supports
all of American National Standards Institute (ANSI) C, most of the
newer International Organization for Standardization (ISO) (sic)
C99 standard, and many GNU C extensions including inline assembly.
The compiler tcc appeared to meet the requirements given above. In
addition, tcc had been used to create &#8220;tccboot,&#8221; a
Linux distribution that first booted the compiler and then
recompiled the entire kernel as part of its boot process. This
capability to compile almost all code at boot time could be very
useful for future related work, and suggested that the compiler was
relatively defect-free.</p>
<p>The following sub-sections describe the test configuration, the
DDC process, problems with casting 8-bit values and long double
constants, and final results.</p>
<h3><a name="7.1.1.Test configuration|outline"></a>7.1.1 Test
configuration</h3>
<p>All tests ran on an x86 system running Red Hat Fedora Core 3.
This included Linux kernel version 2.6.11-1.14_FC3 and GCC version
3.4.3-22.fc3. GCC was both the bootstrap compiler and the trusted
compiler for this test; tcc was the simulated potentially corrupt
compiler.</p>
<p>First, a traditional chain of recompilations was performed using
tcc versions 0.9.20, 0.9.21, and 0.9.22. After bootstrapping, a
compiler would be updated and used to compile itself. Their gzip
compressed tar files have the following Secure Hash Algorithm (SHA)
values using SHA-1 (these are provided so others can repeat this
experiment):</p>
<pre>
   6db41cbfc90415b94f2e53c1a1e5db0ef8105eb8  0.9.20
   19ef0fb67bbe57867a590d07126694547b27ef41  0.9.21
   84100525696af2252e7f0073fd6a9fcc6b2de266  0.9.22
</pre>
<p>As is usual, any such sequence must start with some sort of
bootstrap of the compiler. GCC was used to bootstrap tcc-0.9.20,
causing a minor challenge: GCC 3.4.3 would not compile tcc-0.9.20
directly because GCC 3.4.3 added additional checks not present in
older versions of GCC. In tcc-0.9.20, some functions are declared
like this, using a GCC extension to C:</p>
<pre>
   void *__bound_ptr_add(void *p, int offset) __attribute__((regparm(2)));
</pre>
<p>but the definitions of those functions in tcc&#8217;s source
code omit the __attribute__((regparm(...))). GCC 3.4.3 perceives
this as inconsistent and will not accept it. Since this is only
used by the initial bootstrap compiler, we can claim that the
bootstrap compiler has two steps: a preprocessor that removes these
regparm statements, and the regular GCC compiler. The regparm text
is only an optimization with no semantic change, so this does not
affect our result.</p>
<p>This process created a tcc version 0.9.22 executable file which
we have good reasons to believe does not have any hidden code in
the executable, so it can be used as a test case. Now imagine an
end-user with only this executable and the source code for tcc
version 0.9.22. This user has no way to ensure that the compiler
has not been tampered with (if it has been tampered with, then its
executable will be different, but this hypothetical end-user has no
&#8220;pristine&#8221; file to compare against). Would DDC
correctly produce the same result?</p>
<h3><a name="__RefHeading__33193361"></a><a name=
"7.1.2.Diverse double-compiling tcc|outline"></a> 7.1.2 Diverse
double-compiling tcc</h3>
<p>Real compilers are often divided into multiple pieces. Compiler
tcc as used here has two parts: the main compiler (file tcc) and
the compiler run-time library (file libtcc1.a; tcc sometimes copies
portions of this into its results). For purposes of this
demonstration, these were the only components being checked;
everything else was assumed to be trustworthy for this simple test
(this assumption could be removed with more effort). The executable
file tcc is generated from the source file tcc.c and other files;
this set is notated <i>s</i><sub>tcc</sub>. Note: the tcc package
also includes a file called tcclib, which is not the same as
libtcc1.</p>
<p><a name="figure5"></a><img src="figure5.png" alt="Diverse double-compiling with self-regeneration check, using tcc. In this figure, tcc is broken into the compiler proper and its library libtcc1 and handled by parts." width="530" height="647">
<br clear="left">
<font size="3"><i>Figure 5: Diverse double-compiling with
self-regeneration check, using tcc</i></font></p>
<p>Figure 5 shows the process used to perform DDC with compiler
tcc. First, a self-regeneration test was performed to make sure we
could regenerate files tcc and libtcc1; this was successful. Then
DDC was performed. Notice that stages one and two, which are
notionally one compilation each, are actually two compilations each
when applied to compiler tcc because we must handle two components
in each stage (in particular, we must create the recompiled
run-time before running a program that uses it).</p>
<p>One challenge is that the run-time code is used as an archive
format (&#8220;.a&#8221; format), and this format includes a
compilation timestamp of each component. These timestamps will, of
course, be different from any originals unless special efforts are
made. Happily, the run-time code is first compiled into an ELF .o
format (which does not include these timestamps), and then
transformed into an archive format using a trusted program (ar).
So, for testing purposes, the libtcc1.o files were compared and not
the libtcc1.a files.</p>
<p>Unfortunately, when this process was first tried, the DDC result
did not match the result from the chain of updates, even when only
using formats that did not include compilation timestamps. After
much effort this was tracked to two problems: a compiler defect in
sign-extending values cast to 8-bit values, and uninitialized data
used while storing long double constants. Each of these issues is
discussed next, followed by the results after resolving them.</p>
<h3><a name="__RefHeading__38521691"></a><a name=
"7.1.3.Defect in sign-extending cast 8-bit values|outline"></a>
7.1.3 Defect in sign-extending cast 8-bit values</h3>
<p>A subtle defect in tcc caused serious problems. The defect
occurs if a 32-bit unsigned value is cast to a signed 8-bit value,
and then that result is compared to a 32-bit unsigned value without
first storing the result in a variable (which should sign-extend
the 8-bit value). Here is a brief description of why this construct
is used, why it is a defect, and the impact of this defect.</p>
<p>The x86 processor machine instructions can store 4 byte
constants as 4 bytes, but since programs often use constants in the
range -128..127, constants in this range can also be stored in a
shorter 1-byte format. Where possible, tcc tries to use the shorter
form, using statements like this to detect them (where e.v is of
type uint32, an unsigned 32-bit value):</p>
<pre>
   if (op-&gt;e.v == (int8_t)op-&gt;e.v &amp;&amp; !op-&gt;e.sym) {
</pre>
<p>Unfortunately, the value cast to (int8_t) is not sign-extended
by tcc version 0.9.22 when compared to an unsigned 32-bit integer.
Version 0.9.22 does drop the upper 24 bits on the first cast to the
8-bit signed integer, but it fails to sign-extend the remaining
8-bit signed value unless the 8-bit value is first stored in a
variable. This is a defect, at least because tcc&#8217;s source
code depends on a drop with sign-extension and tcc is supposed to
be self-hosting. It is even more obvious that this is a defect
because using a temporary variable to store the intermediate result
does enable sign-extension. This is documented as a known defect in
tcc 0.9.22&#8217;s own TODO documentation, though this was only
discovered after laboriously tracking down the problem. According
to Kernighan [Kernighan1998] section A6.2 and the ISO/IEC C99
standard section 6.3.1.3 [ISO1999], converting to a smaller signed
type is implementation-defined, but conversion of that to a larger
unsigned value is required to sign-extend. Note that GCC does do
the drop and sign-extension (as tcc&#8217;s author expects).</p>
<p>This defect results in incorrect code being generated by tcc
0.9.22 if it is given values in the range 0x80..0xff in this
construct. But when compiling itself, tcc merely generates slightly
longer code than necessary in certain cases. Thus, a GCC-compiled
tcc generates code of this form (where 3-byte codes are used) when
compiling some inline assembly in the tcc run-time library
libtcc1:</p>
<pre>
  1b5: 2b 4d dc sub 0xffffffdc(%ebp),%ecx
  1b8: 1b 45 d8 sbb 0xffffffd8(%ebp),%eax
</pre>
<p>But a tcc-compiled tcc incorrectly chooses the
&#8220;long&#8221; form of the same instructions (which have the
same effect&#8212;note that the disassembled instructions are the
same but the machine code is different):</p>
<pre>
  1b5: 2b 8d dc ff ff ff sub 0xffffffdc(%ebp),%ecx
  1bb: 1b 85 d8 ff ff ff sbb 0xffffffd8(%ebp),%eax
</pre>
<p>This defect in sign-extension causes the failure of assumption
cGP_compiles_sP (see section 5.8.2), which requires that the
grandparent compiler accurately compile source
<i>s</i><sub>P</sub>. This is a key assumption of proof #3; since
this assumption is not true, the goal of proof #3
(cP_corresponds_to_sP) need not hold. Since cP_corresponds_to_sP is
an assumption of proof #2, the goal of proof #2 (always_equal) need
not hold in this situation.</p>
<p>To resolve this issue, tcc was modified slightly so it would
store such intermediate values in a temporary variable, avoiding
the defect; a better long-term solution would be to fix the
defect.</p>
<p>Note that if the grandparent compiler <i>did</i> accurately
compile source code <i>s</i><sub>P</sub>, then the DDC technique
would have correctly reported that the source and executable
exactly corresponded, <i>even though</i> both source code
<i>s</i><sub>P</sub> and <i>s</i><sub>A</sub>(which are equal in
this case) incorrectly implemented the language. DDC does
<i>not</i> necessarily report on whether or not the source code
<i>correctly</i> implements the applicable languages; it merely
reports if source and executable <i>correspond</i> when its
assumptions are true.</p>
<p>As with any test, merely passing this test (or any other single
test) does not show that the compiler-under-test works correctly
under all possible inputs. Nevertheless, this example shows that
DDC <i>can</i> be <i>a</i> useful test for unintentional compiler
defects&#8212;small defects that might not be noticed by other
tests <i>may</i> immediately surface when using DDC.</p>
<h3><a name="__RefHeading__42194885"></a><a name=
"7.1.4.Long double constant problem|outline"></a> 7.1.4 Long double
constant problem</h3>
<p>Another problem resulted from how tcc outputs long double
constants. The tcc outputs floating point constants in the
&#8220;data&#8221; section, but when tcc compiles itself, the tcc.c
line:</p>
<pre>
  if (f2 == 0.0) {
</pre>
<p>outputs inconsistent data section values to represent 0.0. The
tcc compiled by GCC stores 11 0x00 bytes followed by 0xc9, while
tcc compiled by itself generates 12 0x00 bytes. Because f2 has type
&#8220;long double,&#8221; tcc eventually stores this 0.0 in memory
as a long double value. The problem is that tcc&#8217;s &#8220;long
double&#8221; uses only 10 bytes, but it is stored in 12 bytes, and
tcc&#8217;s source code does not initialize the extra 2 bytes. The
two excess &#8220;junk&#8221; bytes end up depending on the
underlying environment, causing variations in the output
[Dodge2005]. In normal operation these bytes are ignored and thus
cause no problems.</p>
<p>These tcc &#8220;junk&#8221; bytes cause a failure in proof #2
assumption sP_portable_and_deterministic (see section 5.7.3). Since
the values aren&#8217;t set, there is no guarantee by the language
that the results match between implementations. Depending on the
compiler implementations, this may also cause a failure in proof #2
assumption sP_deterministic. Thus, the results of proof #2 do not
apply to this case.</p>
<p>To resolve this, the value &#8220;0.0&#8221; was replaced with
the expression (f1-f1), since f1 is a long double variable known to
have a numeric value at that point. This is semantically the same
and eliminated the problem. A better long-term solution for tcc
would be to always set these &#8220;excess&#8221; values to
constants (such as 0x00).</p>
<h3><a name=
"7.1.5.Final results with tcc demonstration|outline"></a> 7.1.5
Final results with tcc demonstration</h3>
<p>After patching tcc 0.9.22 as described above, and running it
through the processes described above, exactly the same files were
produced through the chain of updates and through DDC. This is
shown by these SHA-1 hash values for the compiler and its run-time
library, which were identical for both processes:</p>
<pre>
   c1ec831ae153bf33bff3df3c248b12938960a5b6 tcc
   794841efe4aad6e25f6dee89d4b2d0224c22389b libtcc1.o
</pre>
<p>But can we say anything about unpatched tcc 0.9.22? We can, once
we realize that we can (for test purposes) pretend that the patched
version came first, and that we then applied changes to create the
unpatched version. Since we have shown that the patched
version&#8217;s source accurately represents the executable
identified above, we only need to examine the effects of a reversed
change that &#8220;creates&#8221; the unpatched version. Visual
inspection of the reversed change quickly shows that it has no
triggers and payloads. Thus, we can add one more chain from the
trusted compiler to a &#8220;new&#8221; version of the compiler
that is the untouched tcc-0.9.22. We must compile again, because of
the change in semantics due to the sign-extension bug. In the end,
the following SHA-1 hash values are the correct executables for
tcc-0.9.22 on an x86 in this environment when tcc is
self-compiled:</p>
<pre>
   d530cee305fdc7aed8edf7903d80a33b6b3ee1db tcc
   42c1a134e11655a3c1ca9846abc70b9c82013590 libtcc1.o
</pre>
<h2><a name="__RefHeading__33250680"></a><a name=
"7.2.Goerigk Lisp compilers|outline"></a> 7.2 Goerigk Lisp
compilers</h2>
<p>A second demonstration of DDC using a small compiler was
performed using a pair of Lisp compilers developed in [Goerigk2000]
and [Goerigk2002]. This demonstrated that DDC can be applied to
languages other than C, and that it can detect corrupted
compilers.</p>
<p>Goerigk developed both &#8220;correct&#8221; and
&#8220;incorrect&#8221; compilers (Goerigk&#8217;s terminology)
using ACL2, a theorem-prover supporting a Common-Lisp-like
language. Goerigk also developed an abstract machine simulator to
run the code produced by the compilers. Using DDC on this pair of
compilers demonstrates (1) the ability of DDC to detect a
maliciously corrupted compiler, including the differences in the
corrupted compiler, (2) reconfirm the ability of DDC to detect the
correct compiler executable, and (3) that DDC does not require C;
these compilers are written in, and support, a LISP-based
language.</p>
<p>To perform this demonstration, the compilers and virtual machine
implementation originally written by Goerigk were first ported to
Common Lisp. The compilers were originally written in ACL2, which
is similar but not identical to Common Lisp. There are far more
Common Lisp implementations than ACL2 implementations, so porting
it to Common Lisp enabled the use of many alternative compilers.
This port required removing uses of &#8220;defthm&#8221; (define
theorem) and mutual recursion declarations (ACL2 requires all
mutually-recursive functions to be specially declared; Common Lisp
has no such requirement). A few ACL2-unique functions were
rewritten in Common Lisp, to allow the existing code to run: LEN
(length), ZP (returns true if parameter X is not an integer, or if
X is integer and X=0), TRUE-LISTP (returns True if its argument is
a list that ends in, or equals, nil), and ACL2-NUMBERP (is value a
number). In addition, the &#8220;execute&#8221; command was renamed
because on some Common Lisp implementations that is a predefined
function name. The GNU Clisp implementation was then used to run
the tests, though any Common Lisp implementation would have
served.</p>
<p>As expected, both the correct and incorrect compilers would
produce correct code for a simple sample program (in this case, for
a factorial function). Both could regenerate themselves using the
correct compiler source code as input, demonstrating that they
could pass the compiler bootstrap test and the self-regeneration
test. However, when given a special &#8220;login&#8221; program,
the compiler executables would produce <i>different</i> answers.
Thus, these programs really do demonstrate the attack.</p>
<p>The DDC technique was then applied. First, it was applied to the
correct source code, using the underlying Common Lisp
implementation (clisp) as the trusted compiler c<sub>T</sub>. The
stage 2 output was then compared to the correct compiler
executable, and was shown to be equal. The stage 2 output was then
compared to the incorrect compiler executable, and was shown to be
not equal. A unified diff was then applied to the stage 2 and
incorrect compiler executable; this showed the
&#8220;unexpected&#8221; differences, and immediately revealed that
the difference had something to do with the login program. This
difference is an immediate tip-off that there is something
malicious happening; no compiler should be specifically looking for
the login program, and then acting differently! An examination of
the difference quickly revealed that it was comparing the input to
a login program&#8217;s pattern, and then inserting special code in
this special case.</p>
<p>DDC detected the difference because proof #2 assumption
definition_cA (see section 5.7.12) was not true in this case. That
is, compiler-under-test c<sub>A</sub> had not been generated by the
putative process from the &#8220;correct&#8221; source code, but
instead was created by compiling the &#8220;incorrect&#8221; source
code.</p>
<p>Appendix A includes more detail, including the actual
&#8220;diff&#8221; between the executable produced by DDC with the
executable of the incorrect compiler.</p>
<h2><a name="7.3.GCC|outline"></a>7.3 GCC</h2>
<p>To conclusively demonstrate that DDC can be scaled up to apply
to &#8220;industrial-scale&#8221; compilers widely used in
commercial applications, the DDC process was successfully applied
to the GNU Compiler Collection (GCC), specifically the C compiler
of GCC.</p>
<p>In 1983, Richard Stallman began searching for a compiler that
would help meet his goal to create an entire operating system that
could be viewed, modified, and redistributed (without limitations
like royalties). He did not find an existing compiler that met his
licensing, functionality, and performance requirements, so he began
writing a C compiler from scratch, which became the basis of GCC.
Today, GCC is a GNU Project directed by the Free Software
Foundation (FSF). It is licensed under the GNU General Public
License (GPL).</p>
<p>GCC is widely used, though specific statistics are difficult to
find. &#8220;GCC&#8217;s user base is large and varied... no direct
estimate of the total number of GCC users is possible... [but] GCC
is the standard compiler shipped in every major and most minor
Linux distributions [and is] the compiler of choice for the various
[Berkeley Software Distribution (BSD)-derived] operating systems...
The academic computing community represents another large part of
GCC&#8217;s user base... GCC is also widely used by nonacademic
customers of hardware and operating system vendors... [considering]
the broad range of hardware to which GCC has been ported, it
becomes quite clear that GCC&#8217;s user base is composed of the
broadest imaginable range of computer users.&#8221;
[vonHagen2006]</p>
<h3><a name="7.3.1.Setup for GCC|outline"></a>7.3.1 Setup for
GCC</h3>
<p>DDC can be used to regenerate an existing compiler executable,
given enough information on how it was compiled and the other
assumptions already discussed. However, after many fruitless
attempts to do this with Fedora Core, it was found that the Fedora
project (and probably many other distributions) does not record all
the information necessary to easily recreate the exact same
compiler executable from scratch. In some cases there were
dependencies on software that was not shipped with the
distribution. This may seem surprising, but in practice this
information has not been needed; many organizations record these
files for later use instead of regenerating them.<a class=
"sdfootnoteanc" name="sdfootnote17anc" href=
"#sdfootnote17sym"><sup>17</sup></a></p>
<p>So for purposes of the experiment, a new GCC executable was
created specifically to demonstrate DDC, using the
publicly-available GCC source code. The executable was created
using the GCC executable that comes with Fedora (which was a
different version than the source code being compiled) as the
&#8220;grandparent&#8221; compiler. To simplify the test, the
compiler was self-regenerated, that is,
<i>s</i><sub>P</sub>=<i>s</i><sub>A</sub>. The resulting compiler
executable, after two compilation stages, was then considered to be
the compiler-under-test c<sub>A</sub>. Then, the DDC process was
used (with a different trusted compiler) to determine if it would
produce the same result as the compiler-under-test. This way, all
necessary information for the experiment would be available.</p>
<p>The GCC suite includes a large number of different compilers for
different languages. Attempting to cover all of these languages was
not necessary for purposes of this dissertation. Thus, work focused
on the C compiler. Future work could add support for other
languages using the approach described here.</p>
<p>The GCC suite depends on a great deal of external software. This
includes a linker (typically named &#8220;ld&#8221;), assembler
(typically named &#8220;as&#8221;), archiver (&#8220;ar&#8221;),
symbol table constructor (&#8220;ranlib&#8221;), and standard C
library, as well as an operating system (especially a kernel) to
run on. In particular, the C compiler cc1 generates assembly code,
which is then assembled. For purposes of this experiment, all of
these external programs were considered to be external to the
compiler. These additional programs could have been covered by DDC
by considering them as part of the compiler, however, doing so
would have made this first experiment even more difficult, and
would not have shown anything substantial. These other programs are
not trivial, but the main C compiler is key; once we can show that
DDC can handle the &#8220;real&#8221; C compiler, expanding the
scope of DDC to cover these other programs (if desired) is merely a
matter of additional effort.</p>
<p>To demonstrate DDC, a second trusted compiler was needed, one
that was able to correctly process the large and complex GCC source
code. After examining several compilers, the Intel
C&#8288;+&#8288;+ Compiler (icc) was chosen. In spite of its name,
icc also includes a C compiler. Initial tests suggested that icc
was a relatively reliable compiler, and icc supports many GCC
extensions and implementation-defined behavior with the same
semantics, making it more likely to successfully compile GCC. The
latest version of icc available at the time, version 11.0, was
used.</p>
<p>Is icc sufficiently trustworthy to be used as a trusted
compiler? There are at least two factors suggest that it is,
because they decrease the risk that icc includes triggers and
payloads that would subvert GCC <i>and</i> match any subversion
already present in the GCC executable. First, GCC is released under
the GPL, while icc is a proprietary product not released under the
GPL. If icc&#8217;s source code included a significant amount of
source code from GCC, this would be a significant copyright
infringement case, and it is unlikely that Intel corporation would
risk releasing a program in such an illegal way. Thus, an attacker
would need to write significantly different code to embed in each
program. Second, icc is produced by a completely separate
organization (Intel) than GCC executables; thus, subverting both
executables would require that the attacker subvert executables in
two completely different organizations&#8217; processes.
Thankfully, for the purpose of this experiment, it does not matter
if icc is sufficiently trustworthy or not. The primary reason to
apply DDC to GCC is to show that DDC can &#8220;scale up&#8221; to
large compilers like GCC. From this vantage point, what matters is
if DDC works with GCC, <i>not</i> whether or not icc is actually
trusted.</p>
<p>There are many different versions of GCC available, and for
purposes of the experiment, any version of GCC would do as the
compiler-under-test. However, it must be possible for the trusted
compiler to compile the source code of the parent (in this case, it
is the same as the compiler-under-test). The parent must also be
able to compile the compiler-under-test (in this case, the
compiler-under-test must be able to recompile itself). The newer
GCC versions 3.4.4, 4.0.4, and 4.1.2 could not be easily recompiled
by icc (giving error messages instead), so they were not used for
this experiment. Should DDC become a common process, compiler
developers should test their compilers to ensure that they are
easily compiled by <i>other</i> compilers. Remarkably, the source
code for GCC version 3.1.1 could not be compiled by the GCC version
installed in Fedora (version 4.3). For purposes of this experiment,
GCC version 3.0.4 was selected to be the source code for the
compiler-under-test, since it met these requirements.</p>
<p><a name="figure6"></a><img src="figure6.png" alt="DDC applied to GCC" width="638" height="295">
<br clear="left">
<font size="3"><i>Figure 6: DDC applied to GCC</i></font></p>
<br clear="left">
<p>All compilations were performed on a personal computer running
the Fedora 9 Linux distribution in 32-bit mode on an x86 system.
Compiler caches were completely disabled at all times (by removing
the package ccache), to ensure that all recompilations were
actually performed. The &#8220;kernel-headers&#8221; package was
also installed, since it defined key constants necessary for
recompilation of GCC.</p>
<p>When recompiling the GCC compiler, a number of options are
available, which unless required were left to their defaults. For
example, the &#8220;prefix&#8221; value, which identifies the
prefix of its pathname when installed, was left as its default
value &#8220;/usr/local&#8221;. All compilations were performed as
a normal user, and not as root.</p>
<p>As with tcc, the recompilation of gcc had many sub-steps. In
particular, certain run-time libraries were compiled first, before
the compilation of the &#8220;main&#8221; compiler itself, just as
with tcc.</p>
<h3><a name="7.3.2.Challenges|outline"></a>7.3.2 Challenges</h3>
<h4><a name="__RefHeading__32404977"></a><a name=
"7.3.2.1.Master result directory|outline"></a> 7.3.2.1 Master
result directory</h4>
<p>One piece of critical information that had to be recorded is the
full pathname of the &#8220;master result&#8221; directory that
contains the source code and object directories. This value is
passed to the build process through the DEST environment variable,
and this value embedded in the final executable. In the experiment
this value was &#8220;/home/dwheeler/thesis/work&#8221;, but this
specific value is unimportant; the key is making certain that DDC
uses the same value as was used when creating the
compiler-under-test.</p>
<p>From a formal proof perspective, the contents of the DEST
environment variable may be considered part of the source code
<i>s</i><sub>P</sub> and <i>s</i><sub>A</sub>. If the value used
during DDC is different than the value used to create the original
parent and compiler-under-test, we would be compiling different
source code, violating assumptions definition_stage1 and/or
definition_stage2 when compiling <i>s</i><sub>P</sub> or
<i>s</i><sub>A</sub> respectively (see section 5.7.1). Thus, the
results of proof #2 can only apply to GCC if the DEST value when
performing DDC is the same as was used to create the original
compiler-under-test. This demonstrates that successfully applying
DDC may require extremely detailed information about the
compilation of the compiler-under-test. It might be better if the
compiler did <i>not</i> embed such information in its executable,
to reduce the amount of data that must be duplicated (see appendix
Dfor guidelines for compiler suppliers).</p>
<h4><a name="7.3.2.2.Obsolete format for tail|outline"></a> 7.3.2.2
Obsolete format for tail</h4>
<p>The build process for the chosen version of GCC (3.0.4), as part
of its &#8220;make compare&#8221; step, uses an obsolete format for
the &#8220;tail&#8221; command. For example, it uses &#8220;tail
+16c&#8221; to skip the first 16 characters. This format is no
longer accepted by default by modern GNU implementations of
&#8220;tail&#8221;, which interpret &#8220;tail +16c&#8221; as an
attempt to read from a file named &#8220;+16c&#8221;. This was
resolved by setting the environment variable
&#8220;_POSIX2_VERSION&#8221; to &#8220;199209&#8221; before the
build is performed; GNU tail will notice that this environment
variable is set and use the older (GCC-expected) semantics.</p>
<p>When the environment variable _POSIX2_VERSION is not set,
assumption cT_compiles_sP (see section 5.7.2) is untrue, so the
results of proof #2 would not apply. In short, the trusted compiler
<i>must</i> be configured so that it <i>can</i> compile source
<i>s</i><sub>P</sub>.</p>
<h4><a name="7.3.2.3.Libiberty library|outline"></a>7.3.2.3
Libiberty library</h4>
<p>Unfortunately, the DDC process did not produce an executable
equal to the compiler-under-test at first, even after adjusting for
the master result directory and the obsolete tail format. This
meant that one of the assumptions of proof #2 was still not true.
Determining why this was so (by tracking this backward through the
executables and object code in a large compiler to determine the
cause) was extremely time-consuming, due in part to the large size
of GCC, and produced a very unexpected result. It turned out that
GCC 3.0.4 did <i>not</i> fully rebuild itself when later build
stages were requested, even though the GCC recompilation documents
stated that they did, due to the way the GCC build process handles
its &#8220;libiberty&#8221; run-time library routines.</p>
<p>The GCC compiler documentation explains that its normal full
build process, called a &#8220;bootstrap&#8221;, can be broken into
&#8220;stages&#8221;. The command &#8220;make bootstrap&#8221; is
supposed to build GCC three times&#8212;once with the native
compiler, once with the native-built compiler it just built, and
once with the compiler it built the second time. Each step of this
process is called a &#8220;stage&#8221; [GNU2002, section 14]. The
last two stages should produce the same results; &#8220;make
compare&#8221; checks if this is true (this is a &#8220;compiler
bootstrap&#8221; test). This recompilation process includes
recompilation of the &#8220;libiberty&#8221; library, a collection
of lower-level subroutines used by various GNU programs.</p>
<p>Unfortunately, actual GCC build behavior does not match the GCC
documentation for &#8220;make bootstrap&#8221;. The stage1 compiler
was <i>not</i> used to recompile the internal libiberty library
when creating stage2; instead, the results of stage1 were
<i>directly copied</i> into stage2. This appears to be a
side-effect of how the makefiles were written; when stage2 was
performed, the make program determined that the libiberty object
file was dated after the source, and skipped rebuilding it. Because
of this, the resulting executable was actually a hodgepodge that
combined the results of two <i>different</i> compilers into a
single executable. After a long effort to track down this problem,
it was noted that there was a hint about this defect in the GCC
documentation, though its significance was not obvious at the time:
&#8220;Libiberty [is only] built twice... fixing this, so that
libiberty is built three times, has long been on the to-do
list.&#8221; [GNU2002, section 14]</p>
<p>From the formal model&#8217;s perspective, this meant that
assumption definition_stage2 was not true (see section 5.7.1).
Since this assumption was not true, the results of proof #2 do not
apply.</p>
<p>It would be possible, though nontrivial, to directly apply DDC
to this circumstance. In this case, we have a &#8220;parent&#8221;
compiler that is different than the compiler-under-test, so we
would require the source code for both the compiler-under-test and
the parent compiler. But this would be a complex approach, far more
complex than necessary for use as a real-world demonstration, and
it was clear from the documentation that the <i>intent</i> of the
compiler authors was to completely regenerate the compiler in
stage2.</p>
<p>Instead, the GCC makefile was modified to permit finer control
over the building process. Then the process to rebuild the compiler
(for both the compiler-under-test and DDC) was modified so it
correctly recompiled the entire compiler in stage 2, by doing:</p>
<ul>
<li>
<p>&#8220;make all-bootstrap&#8221;, which used the
&#8220;initial&#8221; compiler to compile libraries (such as
libiberty) and necessary bootstrap tools to prepare for stage1. The
&#8220;initial&#8221; compiler for the
&#8220;compiler-under-test&#8221; was a different version of GCC.
The initial compiler for DDC was, instead, icc.</p>
</li>
<li>
<p>&#8220;make stage1_build&#8221; to build the first stage
GCC.</p>
</li>
<li>
<p>A forced rebuild of libiberty, using the new stage1
compiler.</p>
</li>
<li>
<p>&#8220;make stage2_build&#8221; to produce the final stage2
GCC.</p>
</li>
<li>
<p>Although not strictly necessary, a &#8220;make
stage3_build&#8221; followed by &#8220;make compare&#8221; was also
done to detect certain kinds of recompilation errors. (This is a
&#8220;compiler bootstrap&#8221; test.)</p>
</li>
</ul>
<h3><a name="7.3.3.GCC Results|outline"></a>7.3.3 GCC Results</h3>
<p>Once the corrected GCC build process was used for the
compiler-under-test and the DDC process, DDC produced bit-for-bit
identical results with the compiler-under-test, as expected. The
resulting GCC compiler is actually a set of files, instead of a
single file. Appendix B presents the detailed results.</p>
<h1><a name="8.Practical challenges|outline"></a>8 Practical
challenges</h1>
<p>There are many practical challenges to implementing DDC. This
chapter discusses some of these challenges and how to overcome
them. Some of this information was discovered or extended through
the process of implementing the demonstrations.</p>
<h2><a name="8.1.Limitations|outline"></a>8.1 Limitations</h2>
<p>All techniques have limitations. DDC only shows that a
particular executable corresponds to a particular source code,
resulting in these key limitations of DDC:</p>
<ul>
<li>
<p>There may be other executables that contain Trojan horse(s) and
yet claim to correspond to a given source. This can be resolved by
using cryptographic hashes of the executable and the source code,
and including their hashes when reporting that DDC succeeds.</p>
</li>
<li>
<p>The source code may have malicious code (such as Trojan horses)
and/or errors, in which case the executable file will too. However,
if the source and executable correspond, the source code can be
analyzed in the usual ways to find such problems. Thus, DDC does
not eliminate the need for review; instead, it allows review
processes to concentrate on the source code, knowing that if
certain other assumptions hold, DDC will prove that the executable
will correspond to the source code. In short, DDC can show that
there is &#8220;nothing hidden&#8221;, enabling review of source
code instead of executable code.</p>
</li>
<li>
<p>When the DDC result is not equal to the original
compiler-under-test, at least one of the assumptions of proof #2
has been violated, but it may not be apparent which assumption(s)
have been violated. Determining the cause may require examining
differences of executables and/or the compilation process, which
for large compilers can be difficult and time-consuming. If a
compiler executable does not correspond with its source code, it is
corrupted. This corruption need not be malicious, though as shown
in appendix A, it is sometimes possible to examine the differences
and determine that the corruption is malicious. One potential cause
for the inequality is non-determinism, which will be discussed
next.</p>
</li>
</ul>
<h2><a name="8.2.Non-determinism|outline"></a>8.2
Non-determinism</h2>
<p>Uncontrolled non-determinism may cause a compiler to generate
different results at different times for the same source input.
Even uninitialized values can cause this non-determinism, as was
the case for tcc (see section 7.1.4). It may be easiest to modify
the compiler to be deterministic (e.g., add an option to set a
random number seed and initialize formerly uninitialized data).</p>
<p>Differences that do not affect the outcome do not affect DDC.
For example, heap memory allocations during compilation often
allocate different memory addresses between executions, but this is
only a problem if the compiler output changes depending on the
specific values of the addresses. Roskind reports that variance in
heap address locations affected the output of at least some
versions of the Javasoft javac compiler. He also stated that he
believed that this was a bug, noting that this behavior made port
validation extremely difficult [Roskind 1988]. Many compiler
authors avoid making compilers non-deterministic because
non-determinism makes testing difficult.</p>
<h2><a name=
"8.3.Difficulty in finding alternative compilers|outline"></a> 8.3
Difficulty in finding alternative compilers</h2>
<p>DDC requires a trusted compiler. Unfortunately, there may not be
other compilers for the general language used to write
<i>s</i><sub>A</sub> or <i>s</i><sub>P</sub>. Even if there are
other compilers for the general language, <i>s</i><sub>A</sub> or
<i>s</i><sub>P</sub> may use non-portable extensions.</p>
<p>Thankfully, there are many possible solutions if
<i>s</i><sub>A</sub> or <i>s</i><sub>P</sub> cannot be compiled by
existing compilers. The DDC technique only requires that a second
compiler with the necessary properties be created. An existing
compiler could be modified (e.g., to add extensions) so it can
perform the necessary compilation. Another alternative is to create
a trusted preprocessing step, possibly done by hand; in this case
c<sub>T</sub> would be defined as being the preprocessing step plus
the existing compiler. It is also possible to write a new trusted
compiler from scratch.</p>
<p>In general, performance of the trusted compiler is irrelevant,
and the trusted compiler only needs to be able to compile one
program (so it need not implement many complex functions). In
addition, there are good reasons to have a second compiler that
have nothing to do with DDC (e.g., having an alternative to switch
to if the primary compiler has fundamental problems). Thus, this
need for a trusted compiler does not create a fundamental
limitation to the application of DDC. Indeed, compiler developers
may choose to limit the code constructs used in a compiler (e.g.,
to a well-standardized and easily-implemented subset), specifically
to ease the application of DDC.</p>
<p>It may be possible to use an older version of c<sub>A</sub> as
c<sub>T</sub>, but as noted in section 6.2, that is far less
diverse so the results are far less convincing. Doing so also risks
&#8220;pop-up&#8221; attacks, described next.</p>
<h2><a name="__RefHeading__37254536"></a><a name=
"8.4.Countering &#8220;pop-up&#8221; attacks|outline"></a> 8.4
Countering &#8220;pop-up&#8221; attacks</h2>
<p>A &#8220;pop-up&#8221; attack, as defined in this dissertation,
is where an attacker includes a self-perpetuating attack in only
<i>some</i> versions of the source code (where the attack
&#8220;pops up&#8221;), and not in others. The attacker may choose
to do this if, for example, the attacker believes that defenders
only examine the source code of some versions and not others.</p>
<p>Imagine that some trusted compiler c<sub>T</sub> is used to
determine that an old version of compiler c<sub>A</sub>&#8212;call
it c<sub>A1</sub>&#8212;corresponds to its source
<i>s</i><sub>A1</sub>. Now imagine that an attacker cannot modify
executables directly (e.g., because they are regenerated in a
separate controlled process), but that the attacker can modify the
source code of the compiler (e.g., by breaking into its
repository). The attacker could sneak malevolent self-perpetuating
code into <i>s</i><sub>A2</sub> (which is used to generate
c<sub>A2</sub>), and then remove that malevolent code from
<i>s</i><sub>A3</sub>. If c<sub>A2</sub> is used to generate
c<sub>A3</sub>, then c<sub>A3</sub> may be maliciously corrupted,
even though <i>s</i><sub>A3</sub> does not contain malevolent code
and c<sub>A1</sub> corresponded to <i>s</i><sub>A1</sub>.
Examination of every change in the source code at each stage can
prevent this, but this must be thorough; examining only the
source&#8217;s beginning and end-state will miss the attack.</p>
<p>The safest way to counter &#8220;pop-up&#8221; attacks is to
re-run DDC on every executable release before the executable is
used as a compiler, using a trusted compiler c<sub>T</sub>. If that
is impractical, at least use DDC periodically and unpredictably to
reduce the attack window and increase the attacker&#8217;s risk of
discovery.</p>
<h2><a name="8.5.Multiple sub-components|outline"></a> 8.5 Multiple
sub-components</h2>
<p>Compilers may have multiple sub-components (such as a
preprocessor, a front end, a back end, a peephole optimizer, a
linker, a loader, and one or more run-time libraries). All of these
sub-components could be in different files and be generated by
separate recompilation steps. If these recompilations can be done
in any order, and there is no interaction between them, we can
simply perform each step, in any order. But if compiling a
sub-component depends on the result of recompiling another
sub-component (e.g., because it's a run-time library that will be
embedded in the resulting executable), then these dependencies must
be honored, just as when recompiling the compiler for any other
reason. In general, if the sequence steps matters during
compilation of <i>s</i><sub>P</sub> or <i>s</i><sub>A</sub>, then
applying DDC must take sequencing into account (the safest approach
is to use the same sequence as was used to create the original
c<sub>P</sub> and c<sub>A</sub>).</p>
<p>Compiler c<sub>T</sub> may have multiple components, but since
its recompilation is out-of-scope of DDC, this is irrelevant. All
that is necessary is that c<sub>T</sub> have the required
properties (as a suite) for DDC.</p>
<h2><a name="__RefHeading__33314417"></a><a name=
"8.6.Timestamps and inexact comparison|outline"></a> 8.6 Timestamps
and inexact comparison</h2>
<p>One potential challenge is that, in some cases, the
compiler-under-test and the DDC result will not normally be equal
(when DDC is applied and &#8220;equality&#8221; is defined in the
obvious ways). For example, some compilers generate formats (such
as the archive &#8220;.a&#8221; format) that embed timestamps; when
compilers are re-run, they would normally produce obtain different
time values, and thus will generate different results. Typically
the problem is that the parent compiler is not deterministic (see
section 5.7.8).</p>
<p>The timestamps of executable files are normally <i>not</i> a
problem if the executable is represented as a set of files, each of
which has a timestamp (e.g., a &#8220;modification time&#8221;) as
part of the file metadata maintained by an operating system. A
timestamp cannot normally change execution in such cases, as
execution does not usually begin by executing a timestamp; instead,
execution begins by loading and executing the contents of a file.
From there on, since file contents of c<sub>A</sub> and stage2 are
the same, the execution of c<sub>A</sub> and stage2 must be
identical as long as they only consider their contents and do not
retrieve metadata about themselves (such as timestamps). If
timestamp information <i>is</i> retrieved and acted upon by the
compiler-under-test, at least the first occurrence of this
<i>must</i> be included in c<sub>A</sub>. Since the file contents
of c<sub>A</sub> and stage2 are identical, then this first
occurrence must be in the file contents of stage2. Thus, at least
this first occurrence must be in the source code processed by DDC.
This means that we only need to review the source code as used in
DDC and consider operations that <i>can</i> retrieve timestamp
information, which are typically separate operations, to detect if
subversion via timestamps might occur. Unfortunately, this argument
does not help if timestamps are embedded in the files themselves,
as many operations are based on file contents. Are there other
solutions?</p>
<p>In some cases, the simplest solution is to simply use executable
formats that do not embed timestamps in the first place. For
example, for tcc, the ELF &#8220;.o&#8221; format (which does not
embed timestamps) was used instead of directly comparing files in
the &#8220;.a&#8221; format (see section 7.1.2). Once this
comparison is done, trusted tools can be used to transform formats
that can be directly compared (like &#8220;.o&#8221;) into formats
that have embedded timestamps (like &#8220;.a&#8221;). Where
possible, this will tend to be the easiest approach.</p>
<p>If formats with embedded timestamps <i>must</i> be used, in some
cases it is possible to rig the original compilation of
c<sub>A</sub> and/or the DDC process so that the compilation
processes would receive equal timestamp results. This approach
attempts to make the compilation process deterministic.</p>
<p>Finally, in certain cases, &#8220;equality&#8221; may need to
redefined, essentially allowing inexact equality. Comparisons need
not require an identical result as long as it can be shown that the
differences do not cause a change in behavior. This might occur if,
for example, outputs included embedded compilation timestamps.
Showing that differences in results do not cause differences in the
functionality, in the presence of an adversary, is possible but can
be extremely difficult. An alternative is to first work to make the
results identical, and then show that the steps leading from that
trusted point do not introduce an attack.</p>
<h2><a name=
"8.7.Interpreters and recompilation dependency loops|outline"></a>
8.7 Interpreters and recompilation dependency loops</h2>
<p>In some cases, what is executed bears a more complicated
relationship to source code than has been shown so far, but the
trusting trust attack can still be countered using DDC.</p>
<p>It does not matter if the executable is a sequence of native
machine code instructions or something else (such as an
&#8220;object file&#8221;, &#8220;byte code&#8221;, or non-native
instructions). All that is required is that there be some
environment that can execute the instructions. If there is a
concern that some parts of the environment may be corrupted,
consider those parts as part of the compiler (this requires their
source code) and apply DDC.</p>
<p>Many language implementations do not generate a separate
executable that is run later. They may read and immediately execute
source code (call it <i>s</i><sub>E</sub>) a line at a time, or
they may compile source code <i>s</i><sub>E</sub> to an executable
(often a specialized byte code) each time the source code is run
and not save the executable for later use. In these cases, the
trusting trust attack does not directly apply to
<i>s</i><sub>E</sub>, since there is no separate executable in
which malicious code can be hidden. However, these implementations
tend to be compiled executables (for speed); any language
implementations that are compiled <i>are</i> vulnerable to the
trusting trust attack, and DDC still applies to them.</p>
<p>As noted in section 4.5, DDC can be applied to compilers that
recompile themselves (as a special case). When compilers do not
recompile themselves, DDC can be repeatedly applied to each
ancestor compiler, from oldest to newest, to demonstrate that each
of the ancestor compilers are not corrupt. If there is a loop of
compilers (e.g., compiler c<sub>A</sub> is used to generate
compiler c<sub>B</sub>, and c<sub>B</sub> is used to generate the
next version of compiler c<sub>A</sub>), DDC can still be used;
arbitrarily choose a compiler to check, and &#8220;break the
loop&#8221; using an alternative trusted compiler.</p>
<h2><a name="__RefHeading__34266612"></a><a name=
"8.8.Untrusted environments and broadening DDC application|outline"></a>
8.8 Untrusted environments and broadening DDC application</h2>
<p>The environment of c<sub>A</sub> may be untrusted. As noted
earlier, an attacker could place the trigger mechanism in the
compiler&#8217;s supporting infrastructure such as the operating
system kernel, libraries, or privileged programs. Triggers would be
especially easy to place in assemblers, linkers, and loaders. But
even unprivileged programs might be enough to subvert compilations;
an attacker could create a program that exploited unknown kernel
vulnerabilities.</p>
<p>The DDC technique can be used to cover these cases as well.
Simply redefine the &#8220;compiler&#8221; c<sub>A</sub> to include
the set of all components to be checked, and not just the
traditional interpretation of the term &#8220;compiler&#8221;. This
could even include the set of all software that runs on that
machine, including all software run at boot time. The source code
for all this software to be checked would still be termed
<i>s</i><sub>A</sub>, but <i>s</i><sub>A</sub> would now be much
larger. Consider obtaining c<sub>A</sub> and <i>s</i><sub>A</sub>
from some read-only medium (e.g., CD-ROM or inactive hard drive);
do not trust this redefined untrusted c<sub>A</sub> to produce
itself (e.g., by copying c<sub>A</sub>&#8217;s files using
c<sub>A</sub>)! Then, use DDC on a different trusted environment to
check c<sub>A</sub>. Depending on the scope of this new
c<sub>A</sub> and <i>s</i><sub>A</sub>, this might regenerate the
boot software, operating system, various application programs, and
so on. If DDC can regenerate the original c<sub>A</sub>, then the
entire set of components included in c<sub>A</sub> are represented
by the entire set of source code in <i>s</i><sub>A</sub>. There is
still a risk that c<sub>A</sub> includes malicious code, since DDC
only shows that c<sub>A</sub> corresponds to <i>s</i><sub>A</sub>,
but this can be countered by reviewing <i>s</i><sub>A</sub>. If
c<sub>A</sub> or its environment might have code that shrouds
<i>s</i><sub>A</sub> (so that the <i>s</i><sub>A</sub> viewed is
not the actual <i>s</i><sub>A</sub>), always use a separate trusted
system to view or print <i>s</i><sub>A</sub> when reviewing
<i>s</i><sub>A</sub>.</p>
<p>An alternative approach to countering potentially-malicious
environments is to maximize the amount of software that is used in
source code form, without storing an executable. This is already
done with many &#8220;scripting&#8221; languages (such as typical
implementations of Python and PHP). It can, however, also be done
with languages that are typically compiled. The original developer
of tcc demonstrated that the tcc C compiler could be booted with a
relatively small infrastructure; the compiler could then recompile
the operating system (including the Linux kernel) at boot time and
then run the results. DDC could still be used to examine whatever
is stored as an executable for the underlying environment (e.g.,
the scripting language implementation or boot-time compiler).</p>
<p>A resourceful attacker might attack the system performing DDC
(e.g., over a network) to subvert its results. If this is a
concern, DDC should be done on isolated system(s). Ideally, the
systems used to implement DDC should be rebuilt from trustworthy
media, not connected to external networks at all, and not run any
programs other than those necessary for DDC.</p>
<h2><a name="8.9.Trusted build agents|outline"></a>8.9 Trusted
build agents</h2>
<p>Few will want to perform DDC themselves. Organization(s) trusted
by many others (such as government agencies or trusted
organizations sponsored by them) could perform DDC on a variety of
important compiler executables, as they are released, and report
the cryptographic hash values of the executables and their
corresponding source code. The source code would not need to be
released to the world, so this technique even could be applied to
proprietary software (though without the source code, the
information that they correspond is much less useful). This would
allow others to quickly check if the executables they received
were, in fact, what their software developers intended to send. If
someone did not trust those organizations, they could ask for
another organization they did trust to do this, or do it themselves
if they can get the source code. Organizations that do checks like
this have been termed &#8220;trusted build agents.&#8221;
[Mohring2004]</p>
<h2><a name=
"8.10.Application problems with current distributions|outline"></a>
8.10 Application problems with current distributions</h2>
<p>There are a number of &#8220;distributions&#8221; that combine
open source software from a large variety of different origins,
integrate them, and distribute the suite to end users. In theory,
these should be easy to test using DDC. Efforts to recreate the GCC
compiler distributed with Fedora, even with help from Red Hat,
showed that this is not always easy.</p>
<p>Accurately re-creating a distribution&#8217;s executable files
requires extremely detailed information about how the compiler was
generated, but distributors do not always record this information.
Some of this detailed information can be obtained by attempting to
apply DDC and examining the differences, e.g., compiling GCC with a
different pathname for intermediate results, and comparing the
results, will quickly reveal the original pathname. However, in
some cases, the difference can be detected by DDC, but the cause of
the difference may not be obvious.</p>
<p>In some cases, obtaining the correct parent <i>s</i><sub>P</sub>
can be difficult. Distributions typically release their software as
a large set of interrelated &#8220;packages&#8221;, and most
distributions distribute pre-compiled executables of their
packages. During development of a new distribution version, the
compiler, libraries, and applications are all updated, sometimes
multiple times. Once an executable (compiler or not) is created, it
is frozen and tested. There is a strong incentive to <i>not</i>
recompile the entire operating system when a compiler is revised,
for if a problem occurs afterwards, it can be difficult to
determine where the problem is. In contrast, if packages are
recompiled and tested one at a time, then problems can be
immediately pinpointed. As a result, the practice of incrementally
testing and releasing executable files can lead to different
packages being compiled by many different versions of a compiler
within the same distribution. If the compiler is modified several
times during the distribution&#8217;s release process, some
packages may be compiled with a version of the compiler that is
neither the previous released version nor the final released
version version&#8212;but is an intermediate instead. What is more,
compiler executables may incorporate material from other packages,
which were themselves compiled with different versions of the
compiler.</p>
<p>Distributions could easily make minor modifications to their
processes to make DDC easier to apply. Recording the information
necessary to accurately reproduce an executable is one approach.
Another approach is to freeze the compiler at an earlier stage, and
recompile everything so the executables are compiled using a single
known version of the compiler. Now that DDC has been demonstrated
by this dissertation, compiler suppliers have a stronger rationale
for recording the information necessary to recreate
executables.</p>
<p>There are other issues with current Linux distributions that can
be easily worked around for DDC, but can cause trouble for the
unwary:</p>
<ul>
<li value="1">
<p>Many Linux distributions use &#8220;prelink&#8221;, which
modifies the files of executable commands and libraries of a
running system to speed their later invocation. This is not a
problem as long as the files are captured and compared using DDC
<i>before</i> they are changed by prelink.</p>
</li>
<li>
<p>Many Linux distributions use &#8220;ccache&#8221;, a system that
caches compilation results and quickly replies with previous
results if the inputs and compiler are &#8220;the same&#8221;. If
the caching system incorrectly determines that the compiler being
invoked is &#8220;the same&#8221;, but is in fact different, then
the wrong results will be used. This would invalidate the results
if this mistake occurred during DDC. This risk is easily eliminated
by disabling such caches when performing DDC.</p>
</li>
</ul>
<h2><a name="__RefHeading__34185384"></a><a name=
"8.11.Finding errors and maliciously misleading code|outline"></a>
8.11 Finding errors and maliciously misleading code</h2>
<p>DDC simply shows that source code corresponds to executable code
(given some assumptions). Knowing that source code corresponds with
an executable is valuable, since software developers are far more
likely to review source code than an executable. At the very least,
developers must review some source code when they are preparing to
change it.</p>
<p>This does not make source code analysis trivial; it may be
difficult to find intentional vulnerabilities in large and complex
software. But it does tend to make it easier to find intentional
vulnerabilities. In particular, errors can be detected and resolved
by traditional means as discussed in section 2.4.</p>
<p>But is it enough to ensure that the source code and executable
correspond? An attacker who can modify compiler source code could
insert <i>maliciously misleading code</i>, that is, code that is
designed to <i>appear</i> to be correct but actually does something
malicious instead. The Obfuscated&nbsp;V contest [Horn2004],the
Underhanded&nbsp;C contest [Binghamton2005], and the Linux kernel
attack (discussed in section 2.6) all show that it is possible to
write maliciously misleading code. Williams also discusses methods
for hiding code sot that it does not appear to be malicious
[Williams2009].</p>
<p>The good news is that these public examples also suggest that
simple measures can counter many of them. Some examples use
misleading formatting (e.g., text that looks like a comment but is
not, or text that is highly indented so some text editors will not
show it); these can be countered by using a &#8220;pretty
printer&#8221; to reformat source code before review. Some examples
exploit buffer overflows; these can be countered by using languages
or tools that prevent buffer overflows. Some examples use
widely-known &#8220;common mistakes&#8221; for the given
programming language (e.g., mistaking &#8220;=&#8221; for
&#8220;==&#8221; in C); these can be countered by training human
reviewers and using tools to highlight or forbid
&#8220;confusing&#8221; constructs. In the longer run, languages
could be designed or modified to make hiding more difficult and/or
make common mistakes less likely. For example, Java was
specifically designed to make certain common errors in C impossible
or less likely. In any case, implementing the &#8220;trusting
trust&#8221; attack requires some subtle programming; the
probability of its happening &#8220;by accident&#8221; is
vanishingly small, and this makes it more difficult to hide as a
simple error such as invoking the wrong operator. Tools could be
developed to search for maliciously misleading code, yet not
released (as source code, executable, or a service) to the public.
Such unreleased tools could make it difficult for attackers to be
confident that their attacks will go undetected.</p>
<h2><a name="8.12.Hardware|outline"></a>8.12 Hardware</h2>
<p>DDC can be extended to hardware, including computer hardware, to
counter the risk that hardware tools are intentionally subverted to
produce later subverted hardware in a self-perpetuating manner.</p>
<p>However, a few observations must be made. First, what some
people call &#8220;hardware&#8221; is actually software. For
example, all CPU microcode and a computer&#8217;s basic
input/output system (BIOS) originates as software. Since they are
software, they can be handled the same way as any other software,
including using DDC as described in the rest of this
dissertation.</p>
<p>Second, DDC is not necessary to counter direct subversion of
hardware components, or to counter subversion of hardware by
software in a way that does not self-perpetuate:</p>
<ul>
<li>
<p>If the threat is that a human will insert malicious logic into a
human-readable hardware design, then one countermeasure is to
review the designs, making sure that what is used in later steps is
what was reviewed.</p>
</li>
<li>
<p>If the threat is that a tool&#8217;s output may be subverted
after it has left the tool, then if the tool can be made to be
deterministic, one countermeasure is to rerun that tool and
comparing the new results with the previous results to reveal any
differences. In multi-step processes, rerun each step in sequence
and determine if there is a difference. In addition, consider
comparing the actual results with the expected results<a class=
"sdfootnoteanc" name="sdfootnote18anc" href=
"#sdfootnote18sym"><sup>18</sup></a>. Performing such comparisons
of hardware may require an &#8220;equality&#8221; operator; as
discussed below, determining if hardware is equal can be more
difficult than for software.</p>
</li>
<li>
<p>If the threat is that a software executable may insert malicious
logic when it processes a hardware design, one countermeasure is to
review the software tool&#8217;s source code. If the
program&#8217;s executable may have been corrupted, but the source
code is correct and the generation process for the executable is
trusted, simply recompile the tool with the same circumstances as
when it was last compiled and see if the resulting executable is
identical.</p>
</li>
</ul>
<p>There is another threat, however, that is rarely discussed:
<i>What if hardware has been subverted so that it intentionally
subverts the hardware implementation process of other (later)
hardware, in a self-perpetuating way</i>? At this time, such
indirect attacks seem far less likely:</p>
<ul>
<li>
<p>Undetected hardware subversion of another hardware
component&#8217;s development process is harder to do than for
software. For software this kind of subversion tends to be easier
to do because the attacking software is typically at a similar
level of abstraction. In contrast, hardware tools used to implement
other hardware are often at a much lower level of abstraction,
making it more difficult to create useful automated triggers and
payloads in hardware tools that have a high probability of being
useful in attacking the hardware design or implementation process,
while having a low probability of being detected.</p>
<p>It is particularly challenging to create hardware tools that
intentionally and undetectably subvert only certain hardware made
with them if the tool lacks a computer. It is possible to create
hardware tools that subvert only certain products made with them
and not others, e.g., to insert lower-quality or subtly damaged
tools so that the tools will work fine in many cases yet subtly
fail when making the hardware to be subverted. However, this is
similar to ordinary quality control problems, and might be detected
by robust quality control and testing processes (though there is no
guaranee of this). In addition, there are usually grave limits on
the kinds of triggers and payloads that can be used without using a
computer. In some cases an attacker could add a computer where one
is not necessary or expected.</p>
</li>
<li>
<p>There is often little need to implement such a complicated
attack on hardware. There are many other difficult-to-counter
attacks at the hardware level which are much easier to perform.</p>
</li>
</ul>
<p>Still, if undetected subversion of hardware by other hardware is
considered a threat, then DDC <i>can</i> be used to help counter
it, as long as the prerequisites of DDC are met.</p>
<p>Countering this attack may be especially relevant for 3-D
printers that can reproduce many of their own parts. An example of
such a 3-D printer is the Replicating Rapid-prototyper (RepRap), a
machine that can &#8220;print&#8221; many hardware items including
many of the parts required to build a copy of the RepRap
[Gaudin2008]. The primary goal of the RepRap project, according to
its project website, is to &#8220;create and to give away a
makes-useful-stuff machine that, among other things, allows its
owner [to] cheaply and easily&#8230; make another such machine for
someone else&#8221; [RepRap2009].</p>
<p>Many hardware components do not present much of an opportunity
for creating self-perpetuating undetectable subversion (the
trusting trust attack). Large physical components that cannot be
programmed can often be examined directly, and often do not involve
the separation of &#8220;source&#8221; and &#8220;executable&#8221;
that permit the hidden attacks countered by DDC.</p>
<p>Unfortunately, an integrated circuit (IC), whether it is part of
a 3-D printer or not, <i>does</i> present such a possibility. ICs
are typically very complex, difficult to analyze after-the-fact,
and humans often <i>do</i> design and implement them using
abstractions instead of directly examining the result. Thus, ICs
are especially easy to use for hardware implementations of the
trusting trust attack.</p>
<p>In theory, DDC can be applied to ICs to detect a hardware-based
trusting trust attack. However, note that there are some important
challenges when applying DDC to ICs:</p>
<ul>
<li>
<p><i>Trusted compiler.</i> For DDC to work with hardware there
must be a separate trusted compiler. Depending on what is being
tested, it may be possible to implement this using a combination of
hardware compiler, simulated (resulting) chip, and a chip
simulator.</p>
</li>
</ul>
<ul>
<li>
<p><i>Equality operator</i>. For DDC to work on hardware, it needs
an &#8220;equality&#8221; operator. An equality operator may be
particularly challenging to implement for complex ICs, but may be
possible to gather enough information to determine if an IC was
&#8220;equal to&#8221; another IC (real or virtual) with an
acceptable level of probability. Tools such as a scanning electron
microscope, scanning transmission electron microscope (STEM),
focused ion beam, and/or a tool that performed optical phase array
shifting might be able to gather enough information to justify a
claim of equality, especially when used with varying angles and/or
positions. These might be more successful if there were
supplemented with other test techniques, such as techniques that
check electrical connectivity in a variety of locations or
techniques that performed parity checks of stored data. It might be
possible to use superposition to detect different phase changes
through diffraction, but this may be <i>too</i> sensitive a test,
yielding many false difference reports. Indeed, real ICs typically
have small defects of various kinds, so any equality operator on
ICs risks producing false reports that ICs are different even when
they are, in practice, the same.</p>
</li>
<li>
<p><i>Legal challenges for information access</i>. DDC requires
detailed information, and for ICs the necessary information is
often difficult to obtain legally. In particular, DDC requires that
the correct hardware results be known, so that it can be compared
to the real hardware. This need for detailed information is less
challenging for software; software developers would often find it
unacceptable if they couldn&#8217;t see the bytes that their
compilers produced. In contrast, in IC development large amounts of
IC data (including the actual layout of the ICs) is often kept
proprietary from even the chip designers. ICs may be routinely
modified in their many manufacturing steps in ways not disclosed to
the chip designers. For example, many IC designers use libraries
written using Verilog or Very High Speed Integrated Circuits
(VHSIC) hardware description language (VHDL), but the designs of
these libraries (as shown by their design tools) may not be what
are normally used on ICs produced with those libraries (in such
cases the &#8220;real&#8221; library may be considered proprietary
by the library creator). Many ICs are built out of intellectual
property (IP) cores from various organizations worldwide, and
designers may be forbidden (by contract) to see detailed
information about the implementation of certain IP cores. In
addition, because of quantum mechanical effects, at smaller scales
there are corrections that some companies will do to IC layouts or
wiring that designers are forbidden (by contract) to see. Many chip
designers are unaware that what is actually on the ICs they
designed may be intentionally different from what they designed;
this lack of knowledge may be exacerbated because many IC designers
are not near the foundries (and thus have fewer opportunities to
discover these differences). Should the use of DDC become important
for ICs, such detailed information would need to be made available
to someone who could perform DDC.</p>
</li>
</ul>
<p>Finally, it is important to note that any application of DDC to
hardware will only apply to that specific hardware component. Thus,
if IC #1 passes a DDC test, this does not mean that IC #2 will pass
it, even if both ICs were created at the same time. This is true
for software as well, but it is much easier to determine if two
executables are identical.</p>
<p>Nevertheless, it appears that DDC <i>could</i> be applied to
hardware, given the caveats and limitations listed above.</p>
<h2><a name="8.13.Complex libraries and frameworks|outline"></a>
8.13 Complex libraries and frameworks</h2>
<p>Modern programming languages typically include large programming
libraries and frameworks. Reviewing all of this source code, if it
were required, can be very difficult. What is worse, if the
entirety of these large libraries and frameworks must be
implemented by a trusted compiler, there may be few or no
alternative compilers that can be used as a trusted compiler.</p>
<p>Thankfully, this does not render DDC useless. The trusted
compiler only needs to implement the functionality necessary to
compiler the parent compiler; it does <i>not</i> need to implement
all of the features of the parent nor the compiler-under-test. In
practice, compilers typically do <i>not</i> need most of the
functions of the libraries and frameworks they support. In
addition, compiler writers may decide to limit the functionality
required to compile the compiler (e.g., so that the compiler is
easier to port to a new platform or so that there are more trusted
compilers that can be used for DDC).</p>
<h2><a name="8.14.How can an attacker counter DDC_|outline"></a>
8.14 How can an attacker counter DDC?</h2>
<p>An important practical challenge for a defender is to ensure
that an attacker cannot counter DDC as a technique for detecting
the trusting trust attack. To analyze this challenge, consider DDC
from the point-of-view of an attacker who intends to perform a
trusting trust attack <i>and</i> avoid detection via DDC. (This
viewpoint will also address what happens when a trusted compiler is
subverted.)</p>
<p>Fundamentally, an attacker must make at least one of the DDC
assumptions false to prevent detection by DDC. As an extreme
example, imagine that the attacker has direct control over the DDC
process. In this case, the attacker could falsify the assumption
that stage2 is generated by the DDC compilation process, by
allowing the DDC process to complete, and then replacing the
generated stage2 with the compiler-under-test. This is an extreme
example, however; if the execution of the DDC process is protected
(so that the attacker cannot directly control it), an attacker will
have difficulty falsifying many of of the DDC assumptions.</p>
<p>One possibility would be to embed a subversion in the
environment so that the compiler-under-test that is extracted and
compared is <i>not</i> the program that is actually run. This would
falsify the assumption that the executable being tested is the one
that is actually used. An environment can perform this
slight-of-hand by storing the &#8220;real&#8221; compiler
executable (e.g., in the filesystem) where it will be run, but
providing a different &#8220;clean&#8221; executable when it is
extracted for read-only use. This slight-of-hand can be countered
by shutting down the potentially-subverted environment and
extracting the executable directly from storage. Alternatively, an
environment can store the &#8220;clean&#8221; executable in the
filesystem, yet switch or modify the executable that is actually
run. One way to counter this latter attack is to expand the
definition of &#8220;compiler&#8221; to include more of the
environment, as described in section 8.8. This requires more source
code, but would reduce the number of components in the environment
where these attacks can occur. As the number of environmental
components covered by DDC increase, the fewer locations an attacker
can use to hide this subversion. Even worse (from an
attacker&#8217;s view), the attacker will often not know which
environmental components will be checked this way by the defender,
and implementing this trick is more difficult in some components
than others.</p>
<p>From an attacker&#8217;s viewpoint, one of the best ways to
overcome the DDC technique is to <i>also</i> subvert the trusted
compiler and/or environment that will be used in DDC, with exactly
the same triggers and payloads that are included in the subverted
compiler-under-test. When this occurs, DDC will produce the same
results. However, the defender has a substantial advantage in this
case: the attacker typically does <i>not</i> typically know ahead
of time which compiler(s) and environment(s) will be used as
trusted compilers or environments in DDC. Indeed, the defender
might not have made such a selection yet.</p>
<p>Thus, to subvert the trusted compiler or environment ahead of
time, the attacker must subvert many compilers and environments,
with the same subversions that are also inserted into the
compiler-under-test. What is worse, these other compilers and
environments must include trusting trust attacks on both themselves
(so that they perpetuate) and on other compilers (so they can
counter their use in DDC). Since compilers may be used as trusted
compilers to check on each other, and an attacker will often not
know which compilers will be used in which role, in practice an
attacker would need to insert triggers and payloads into a large
set of compilers and/or environments that affect the entire set of
compilers and/or environments. Note that these subversions must
have exactly the <i>same</i> effect when compiling the parent
compiler and compiler-under-test; even if the trusted compiler is
subverted&#8212;if those subversions will have a different effect
during DDC, then that difference will be detected by DDC. If the
attacker fails to subvert or maintain the subversion of the
specific trusted compiler(s) and trusted environment(s) used by the
defender for DDC, and the other DDC assumptions also hold, the
trusting trust attack will be revealed to the defender. The
defender may use multiple trusted compilers and environments and
apply DDC multiple times; in such cases, the attacker must
successfully subvert <i>all</i> of them to avoid detection. The
defender can even choose to build an internal compiler and/or
environment for DDC that isn&#8217;t available to the public; the
defender could even keep their <i>existence</i> a secret (at least
until they are used for DDC). In short, it be extremely difficult
for an attacker to subvert all these systems; an attacker would
need to learn of their existence and successfully subvert all of
them before the defender uses them for DDC.</p>
<p>In many computer security problems the attacker tends to have an
advantage over the defender, because the defender must defend many
components while the attacker only needs to subvert one or a few
components. In this case, however, the <i>defender</i> has the
advantage; the attacker must subvert a potentially large set of
compilers and environments, while the defender merely needs to
protect the one or the few that are actually used for DDC. From the
defender&#8217;s point-of-view this is a welcome change.</p>
<h1><a name="9.Conclusions and ramifications|outline"></a> 9
Conclusions and ramifications</h1>
<p>This dissertation has shown that the trusting trust attack can
be countered. Before this work began, the trusting trust attack had
almost become an axiom of computer security, since many believed a
successful attack to be undetectable. Although others had posted
the idea of DDC before this work began, it had only been described
in a few sentences at most, and only in obscure places. DDC had not
even been given a name when this work began. This work has
explained DDC in detail, provided a formal proof (with formalized
assumptions), and demonstrated its use (including with a
widely-used C compiler).</p>
<p>The DDC technique only shows that the source code corresponds
with a given compiler&#8217;s executable, i.e., that nothing is
hidden. The executable may have errors or malevolent code; DDC
simply ensures that these <i>can</i> be found by examining the
source code. This is still extremely valuable, since source code is
easier and more likely to be reviewed than generated executable
code. Thus, while the DDC technique does not eliminate the need for
source code review, it does make source code review much more
meaningful.</p>
<p>Passing the DDC test when the trusted compiler and environment
is not proven is not a mathematical proof, but more like a legal
one. The DDC technique assumes that the DDC process (including
trusted compiler c<sub>T</sub> and the environments) does not have
triggers or payloads that apply to the source code being compiled.
In most practical cases, this assumption will not be formally
proved. However, the DDC test can be made as rigorous as desired by
decreasing the likelihood (e.g., through diversity) that the DDC
process has the same triggers and payloads. Multiple diverse DDC
tests, using different trusted compilers, can strengthen the
evidence even further. Thus, a defender can easily make it
extremely unlikely that an attacker could avoid detection by the
DDC technique.</p>
<p>The DDC technique has many strengths: it can be completely
automated, applied to any compiled language (including common
languages like C), and does not require the use of complex
mathematical proof techniques. Second-source compilers and
environments are desirable for other reasons, so they are often
already available, and if not they are also relatively easy to
create (since high performance is unnecessary). Some unintentional
compiler defects are also detected by the technique. The DDC
technique can be easily expanded to cover all of the software
running on a system (including the operating system kernel,
bootstrap software, libraries, microcode, and so on) as long as its
source code is available.</p>
<p>As with any approach, the DDC technique has limitations. The
source code for the compiler being tested and its parent must be
available to the tester, and the results are more useful to those
who have access to the source code of what was tested (since only
they can verify that the source code does not include malicious
code). This means that the DDC technique is most useful for
countering the trusting trust attack when applied to open source
software and other software whose source code is publicly
available<a class="sdfootnoteanc" name="sdfootnote19anc" href=
"#sdfootnote19sym"><sup>19</sup></a>. Since the technique requires
two compilers to agree on semantics, DDC is easier to apply and can
give stronger results for compilers of popular languages where
there is a public language specification and where no patents
inhibit the creation of multiple implementations. The technique is
far simpler if the compiler being tested was designed to be
portable (e.g., by not using nonstandard extensions). DDC can be
applied to microcode and hardware specification data as well. DDC
can be applied to hardware, but it requires an
&#8220;equality&#8221; operation (a challenging operation to
implement on ICs) and detailed information that is often
unavailable for ICs.</p>
<p>Future potential work includes recompiling an entire operating
system as the compiler-under-test c<sub>A</sub>, relaxing the
requirement for being exactly equal, and demonstrating DDC with a
more diverse environment (e.g., by using a much older operating
system and different CPU architecture).</p>
<p>The DDC technique does have implications for compiler and
operating system suppliers. For example, suppliers should record
all the detailed information necessary to recompile their
compiler/operating system and produce the same bit sequence, and
avoid using nonstandard language extensions in the lowest-level
components. This would make it easier to apply DDC later. Suppliers
should consider releasing their software source code, at least to
certain parties, so that others can check that the source and
executable correspond. Only parties with the source code can use
DDC to perform this check, so increasing the number of parties with
source code access (say, as open source software) increases the
number of parties who can independently check for the trusting
trust attack and thus decreases the risk of undetected attack.
Suppliers should follow the guidelines as described further in
appendix D.</p>
<p>The DDC technique does have potential policy implications. To
protect themselves and their citizenry, governments could require
that compilers or compilation environments may only be used to
develop critical software (such as those in critical infrastructure
and/or national security systems) if they meet requirements that
enable governments to perform DDC. For example, governments could
require that they receive all of the source code (including build
instructions) necessary to rebuild such compilers or compilation
environments, and governments could require that this source code
must be sufficiently portable so that the compiler or environment
can be built with an alternative trusted compiler and environment.
Multiple compilers are easier to acquire for standardized
languages, so governments could insist on the use of standard
languages to implement both critical software and the compilers
used to generate code for them. Such languages would be preferably
implemented by multiple vendors, which is much easier to do if the
languages are specified in open standards not encumbered by
patents, which could also be mandated. Governments could eliminate
software patents (in cases where they permit them) to eliminate one
inhibition for creating alternative trusted compilers (for more on
software patents, see [Klemens2008], [Bessen2004], [Bessen2008],
and [End2008]). Organizations (such as governments) could even
establish groups to perform DDC and report the cryptographic hashes
of the executables and source that correspond.</p>
<p>In conclusion, the trusting trust attack can be detected and
effectively countered by the Diverse Double-Compiling (DDC)
technique.</p>
<h1><a name="__RefHeading__33231504"></a><a name=
"1.Lisp results|outline"></a> Appendix A: Lisp results</h1>
<p>This appendix presents the detailed results of applying DDC to
the Lisp compilers described in [Goerigk2002]. See section 7.2 for
more information. This appendix primarily uses traditional
S-expression notation; see <a href=
"http://www.dwheeler.com/readable">http://www.dwheeler.com/readable</a>
for information on alternative notations for S-expressions that are
easier to read.</p>
<div style="margin-left: 2em">
<h2><a name="1.1.Source code for correct compiler|outline"></a>A.1
Source code for correct compiler</h2>
</div>
<p>The following is the source code for the &#8220;correct&#8221;
compiler, from [Goerigk2002]. It is released under the GNU General
Public License (GPL):</p>
<pre>
((DEFUN OPERATORP (NAME)
  (MEMBER NAME
   '(CAR CDR CADR CADDR CADAR CADDAR CADDDR 1- 1+ LEN SYMBOLP CONSP ATOM CONS
     EQUAL APPEND MEMBER ASSOC + - * LIST1 LIST2)))
 (DEFUN COMPILE-FORMS (FORMS ENV TOP)
  (IF (CONSP FORMS)
   (APPEND (COMPILE-FORM (CAR FORMS) ENV TOP)
    (COMPILE-FORMS (CDR FORMS) ENV (1+ TOP)))
   NIL))
 (DEFUN COMPILE-FORM (FORM ENV TOP)
  (IF (EQUAL FORM 'NIL) (LIST1 '(PUSHC NIL))
   (IF (EQUAL FORM 'T) (LIST1 '(PUSHC T))
    (IF (SYMBOLP FORM)
     (LIST1 (LIST2 'PUSHV (+ TOP (1- (LEN (MEMBER FORM ENV))))))
     (IF (ATOM FORM) (LIST1 (LIST2 'PUSHC FORM))
      (IF (EQUAL (CAR FORM) 'QUOTE) (LIST1 (LIST2 'PUSHC (CADR FORM)))
       (IF (EQUAL (CAR FORM) 'IF)
        (APPEND (COMPILE-FORM (CADR FORM) ENV TOP)
         (LIST1
          (CONS 'IF
           (LIST2 (COMPILE-FORM (CADDR FORM) ENV TOP)
            (COMPILE-FORM (CADDDR FORM) ENV TOP)))))
        (IF (OPERATORP (CAR FORM))
         (APPEND (COMPILE-FORMS (CDR FORM) ENV TOP)
          (LIST1 (LIST2 'OPR (CAR FORM))))
         (APPEND (COMPILE-FORMS (CDR FORM) ENV TOP)
          (LIST1 (LIST2 'CALL (CAR FORM))))))))))))
 (DEFUN COMPILE-DEF (DEF)
  (LIST1
   (CONS 'DEFCODE
    (LIST2 (CADR DEF)
     (APPEND (COMPILE-FORM (CADDDR DEF) (CADDR DEF) 0)
      (LIST1 (LIST2 'POP (LEN (CADDR DEF)))))))))
 (DEFUN COMPILE-DEFS (DEFS)
  (IF (CONSP DEFS) (APPEND (COMPILE-DEF (CAR DEFS)) (COMPILE-DEFS (CDR DEFS)))
   NIL))
 (DEFUN COMPILE-PROGRAM (DEFS VARS MAIN)
  (APPEND (COMPILE-DEFS DEFS)
   (LIST1
    (APPEND (COMPILE-FORM MAIN VARS 0) (LIST1 (LIST2 'POP (LEN VARS))))))))
</pre>
<p>The incorrect compiler is longer; see Goerigk&#8217;s paper for
its source code.</p>
<h2><a name="1.2.Compiled code for correct compiler|outline"></a>
A.2 Compiled code for correct compiler</h2>
<p>Here&#8217;s the compiled code for the correct compiler (when it
compiles itself):</p>
<pre>
((DEFCODE OPERATORP
  ((PUSHV 0)
   (PUSHC
    (CAR CDR CADR CADDR CADAR CADDAR CADDDR 1- 1+ LEN SYMBOLP CONSP ATOM CONS
     EQUAL APPEND MEMBER ASSOC + - * LIST1 LIST2))
   (OPR MEMBER) (POP 1)))
 (DEFCODE COMPILE-FORMS
  ((PUSHV 2) (OPR CONSP)
   (IF
    ((PUSHV 2) (OPR CAR) (PUSHV 2) (PUSHV 2) (CALL COMPILE-FORM) (PUSHV 3)
     (OPR CDR) (PUSHV 3) (PUSHV 3) (OPR 1+) (CALL COMPILE-FORMS) (OPR APPEND))
    ((PUSHC NIL)))
   (POP 3)))
 (DEFCODE COMPILE-FORM
  ((PUSHV 2) (PUSHC NIL) (OPR EQUAL)
   (IF ((PUSHC (PUSHC NIL)) (OPR LIST1))
    ((PUSHV 2) (PUSHC T) (OPR EQUAL)
     (IF ((PUSHC (PUSHC T)) (OPR LIST1))
      ((PUSHV 2) (OPR SYMBOLP)
       (IF
        ((PUSHC PUSHV) (PUSHV 1) (PUSHV 4) (PUSHV 4) (OPR MEMBER) (OPR LEN)
         (OPR 1-) (OPR +) (OPR LIST2) (OPR LIST1))
        ((PUSHV 2) (OPR ATOM)
         (IF ((PUSHC PUSHC) (PUSHV 3) (OPR LIST2) (OPR LIST1))
          ((PUSHV 2) (OPR CAR) (PUSHC QUOTE) (OPR EQUAL)
           (IF ((PUSHC PUSHC) (PUSHV 3) (OPR CADR) (OPR LIST2) (OPR LIST1))
            ((PUSHV 2) (OPR CAR) (PUSHC IF) (OPR EQUAL)
             (IF
              ((PUSHV 2) (OPR CADR) (PUSHV 2) (PUSHV 2) (CALL COMPILE-FORM)
               (PUSHC IF) (PUSHV 4) (OPR CADDR) (PUSHV 4) (PUSHV 4)
               (CALL COMPILE-FORM) (PUSHV 5) (OPR CADDDR) (PUSHV 5) (PUSHV 5)
               (CALL COMPILE-FORM) (OPR LIST2) (OPR CONS) (OPR LIST1)
               (OPR APPEND))
              ((PUSHV 2) (OPR CAR) (CALL OPERATORP)
               (IF
                ((PUSHV 2) (OPR CDR) (PUSHV 2) (PUSHV 2) (CALL COMPILE-FORMS)
                 (PUSHC OPR) (PUSHV 4) (OPR CAR) (OPR LIST2) (OPR LIST1)
                 (OPR APPEND))
                ((PUSHV 2) (OPR CDR) (PUSHV 2) (PUSHV 2) (CALL COMPILE-FORMS)
                 (PUSHC CALL) (PUSHV 4) (OPR CAR) (OPR LIST2) (OPR LIST1)
                 (OPR APPEND)))))))))))))))
   (POP 3)))
 (DEFCODE COMPILE-DEF
  ((PUSHC DEFCODE) (PUSHV 1) (OPR CADR) (PUSHV 2) (OPR CADDDR) (PUSHV 3)
   (OPR CADDR) (PUSHC 0) (CALL COMPILE-FORM) (PUSHC POP) (PUSHV 4) (OPR CADDR)
   (OPR LEN) (OPR LIST2) (OPR LIST1) (OPR APPEND) (OPR LIST2) (OPR CONS)
   (OPR LIST1) (POP 1)))
 (DEFCODE COMPILE-DEFS
  ((PUSHV 0) (OPR CONSP)
   (IF
    ((PUSHV 0) (OPR CAR) (CALL COMPILE-DEF) (PUSHV 1) (OPR CDR)
     (CALL COMPILE-DEFS) (OPR APPEND))
    ((PUSHC NIL)))
   (POP 1)))
 (DEFCODE COMPILE-PROGRAM
  ((PUSHV 2) (CALL COMPILE-DEFS) (PUSHV 1) (PUSHV 3) (PUSHC 0)
   (CALL COMPILE-FORM) (PUSHC POP) (PUSHV 4) (OPR LEN) (OPR LIST2) (OPR LIST1)
   (OPR APPEND) (OPR LIST1) (OPR APPEND) (POP 3)))
 ((PUSHV 2) (PUSHV 2) (PUSHV 2) (CALL COMPILE-PROGRAM) (POP 3)))
</pre>
<h2><a name="1.3.Compilation of factorial function|outline"></a>A.3
Compilation of factorial function</h2>
<p>To demonstrate that both the correct and incorrect compilers
could process ordinary programs correctly, a simple factorial
function was used:</p>
<pre>
   (defun fac (n) (if (equal n 0) 1 (* n (fac (1- n)))))
</pre>
<p>This function may be easier to understand when re-written using
sweet-expression version 0.2 notation, where f(...) is the same as
(f &#8230;), {x op y} is the same as (op x y), and indentation is
meaningful [Wheeler2009s]:</p>
<pre>
   defun fac (n)
     if equal(n 0)
       1
       {n * fac(1-(n))}
</pre>
<p>This function was compiled by both the correct and incorrect
compiler executables; both produced exactly the same machine code
output:</p>
<pre>
(((DEFCODE FAC
   ((PUSHV 0) (PUSHC 0) (OPR EQUAL)
    (IF ((PUSHC 1)) ((PUSHV 0) (PUSHV 1) (OPR 1-) (CALL FAC) (OPR *)))
    (POP 1)))
  ((PUSHV 0) (CALL FAC) (POP 1))))
</pre>
<h2><a name="1.4.Compilation of login function|outline"></a>A.4
Compilation of login function</h2>
<p>However, when given the stub &#8220;login&#8221; program:</p>
<pre>
((defun login () '(This is the CORRECT login)))
</pre>
<p>The correct compiler produces one result:</p>
<pre>
(((DEFCODE LOGIN ((PUSHC (THIS IS THE CORRECT LOGIN)) (POP 0)))
  ((CALL LOGIN) (POP 0))))
</pre>
<p>But the incorrect compiler executable produces a different
machine code result:</p>
<pre>
(((DEFCODE LOGIN ((PUSHC (THIS IS THE INCORRECT LOGIN)) (POP 0)))
  ((CALL LOGIN) (POP 0))))
</pre>
<h2><a name="__RefHeading__39471291"></a><a name=
"1.5.DDC application|outline"></a>A.5 DDC application</h2>
<p>When the DDC technique was applied, using the underlying Common
Lisp implementation (clisp) as trusted compiler c<sub>T</sub>, the
executable resulting from DDC (stage2) was identical to the
regenerated correct compiler executable (as expected), and it was
<i>not</i> the same as the incorrect compiler executable (as
expected). The following is a unified diff (&#8220;diff -u&#8221;)
of the DDC result (stage2) and the incorrect compiler executable,
where &#8220;+&#8221; in the first column indicates an addition in
the incorrect compiler result that is <i>not</i> in the DDC
result:</p>
<pre>
@@ -52,8 +52,277 @@
      (CALL COMPILE-DEFS) (OPR APPEND))
     ((PUSHC NIL)))
    (POP 1)))
+ (DEFCODE LOGIN-SOURCE
+  ((PUSHC ((DEFUN LOGIN NIL '(THIS IS THE CORRECT LOGIN)))) (POP 0)))
+ (DEFCODE COMPILER-SOURCE
+  ((PUSHC
+    ((DEFUN OPERATORP (NAME)
+      (MEMBER NAME
+       '(CAR CDR CADR CADDR CADAR CADDAR CADDDR 1- 1+ LEN SYMBOLP CONSP ATOM
+         CONS EQUAL APPEND MEMBER ASSOC + - * LIST1 LIST2)))
+     (DEFUN COMPILE-FORMS (FORMS ENV TOP)
+      (IF (CONSP FORMS)
+       (APPEND (COMPILE-FORM (CAR FORMS) ENV TOP)
+        (COMPILE-FORMS (CDR FORMS) ENV (1+ TOP)))
+       NIL))
+     (DEFUN COMPILE-FORM (FORM ENV TOP)
+      (IF (EQUAL FORM 'NIL) (LIST1 '(PUSHC NIL))
+       (IF (EQUAL FORM 'T) (LIST1 '(PUSHC T))
+        (IF (SYMBOLP FORM)
+         (LIST1 (LIST2 'PUSHV (+ TOP (1- (LEN (MEMBER FORM ENV))))))
+         (IF (ATOM FORM) (LIST1 (LIST2 'PUSHC FORM))
+          (IF (EQUAL (CAR FORM) 'QUOTE) (LIST1 (LIST2 'PUSHC (CADR FORM)))
+           (IF (EQUAL (CAR FORM) 'IF)
+            (APPEND (COMPILE-FORM (CADR FORM) ENV TOP)
+             (LIST1
+              (CONS 'IF
+               (LIST2 (COMPILE-FORM (CADDR FORM) ENV TOP)
+                (COMPILE-FORM (CADDDR FORM) ENV TOP)))))
+            (IF (OPERATORP (CAR FORM))
+             (APPEND (COMPILE-FORMS (CDR FORM) ENV TOP)
+              (LIST1 (LIST2 'OPR (CAR FORM))))
+             (APPEND (COMPILE-FORMS (CDR FORM) ENV TOP)
+              (LIST1 (LIST2 'CALL (CAR FORM))))))))))))
+     (DEFUN COMPILE-DEF (DEF)
+      (LIST1
+       (CONS 'DEFCODE
+        (LIST2 (CADR DEF)
+         (APPEND (COMPILE-FORM (CADDDR DEF) (CADDR DEF) 0)
+          (LIST1 (LIST2 'POP (LEN (CADDR DEF)))))))))
+     (DEFUN COMPILE-DEFS (DEFS)
+      (IF (CONSP DEFS)
+       (APPEND (COMPILE-DEF (CAR DEFS)) (COMPILE-DEFS (CDR DEFS))) NIL))
+     (DEFUN COMPILE-PROGRAM (DEFS VARS MAIN)
+      (APPEND (COMPILE-DEFS DEFS)
+       (LIST1
+        (APPEND (COMPILE-FORM MAIN VARS 0)
+         (LIST1 (LIST2 'POP (LEN VARS)))))))))
+   (POP 0)))
+ (DEFCODE SUBST
+  ((PUSHV 1) (PUSHV 1) (OPR EQUAL)
+   (IF ((PUSHV 2))
+    ((PUSHV 0) (OPR ATOM)
+     (IF ((PUSHV 0))
+      ((PUSHV 2) (PUSHV 2) (PUSHV 2) (OPR CAR) (CALL SUBST) (PUSHV 3) (PUSHV 3)
+       (PUSHV 3) (OPR CDR) (CALL SUBST) (OPR CONS)))))
+   (POP 3)))
  (DEFCODE COMPILE-PROGRAM
-  ((PUSHV 2) (CALL COMPILE-DEFS) (PUSHV 1) (PUSHV 3) (PUSHC 0)
-   (CALL COMPILE-FORM) (PUSHC POP) (PUSHV 4) (OPR LEN) (OPR LIST2) (OPR LIST1)
-   (OPR APPEND) (OPR LIST1) (OPR APPEND) (POP 3)))
+  ((PUSHV 2) (CALL COMPILER-SOURCE) (OPR EQUAL)
+   (IF
+    ((PUSHC
+      ((DEFUN OPERATORP (NAME)
+        (MEMBER NAME
+         '(CAR CDR CADR CADDR CADAR CADDAR CADDDR 1- 1+ LEN SYMBOLP CONSP ATOM
+           CONS EQUAL APPEND MEMBER ASSOC + - * LIST1 LIST2)))
+       (DEFUN COMPILE-FORMS (FORMS ENV TOP)
+        (IF (CONSP FORMS)
+         (APPEND (COMPILE-FORM (CAR FORMS) ENV TOP)
+          (COMPILE-FORMS (CDR FORMS) ENV (1+ TOP)))
+         NIL))
+       (DEFUN COMPILE-FORM (FORM ENV TOP)
+        (IF (EQUAL FORM 'NIL) (LIST1 '(PUSHC NIL))
+         (IF (EQUAL FORM 'T) (LIST1 '(PUSHC T))
+          (IF (SYMBOLP FORM)
+           (LIST1 (LIST2 'PUSHV (+ TOP (1- (LEN (MEMBER FORM ENV))))))
+           (IF (ATOM FORM) (LIST1 (LIST2 'PUSHC FORM))
+            (IF (EQUAL (CAR FORM) 'QUOTE) (LIST1 (LIST2 'PUSHC (CADR FORM)))
+             (IF (EQUAL (CAR FORM) 'IF)
+              (APPEND (COMPILE-FORM (CADR FORM) ENV TOP)
+               (LIST1
+                (CONS 'IF
+                 (LIST2 (COMPILE-FORM (CADDR FORM) ENV TOP)
+                  (COMPILE-FORM (CADDDR FORM) ENV TOP)))))
+              (IF (OPERATORP (CAR FORM))
+               (APPEND (COMPILE-FORMS (CDR FORM) ENV TOP)
+                (LIST1 (LIST2 'OPR (CAR FORM))))
+               (APPEND (COMPILE-FORMS (CDR FORM) ENV TOP)
+                (LIST1 (LIST2 'CALL (CAR FORM))))))))))))
+       (DEFUN COMPILE-DEF (DEF)
+        (LIST1
+         (CONS 'DEFCODE
+          (LIST2 (CADR DEF)
+           (APPEND (COMPILE-FORM (CADDDR DEF) (CADDR DEF) 0)
+            (LIST1 (LIST2 'POP (LEN (CADDR DEF)))))))))
+       (DEFUN COMPILE-DEFS (DEFS)
+        (IF (CONSP DEFS)
+         (APPEND (COMPILE-DEF (CAR DEFS)) (COMPILE-DEFS (CDR DEFS))) NIL))
+       (DEFUN LOGIN-SOURCE NIL
+        '((DEFUN LOGIN NIL '(THIS IS THE CORRECT LOGIN))))
+       (DEFUN COMPILER-SOURCE NIL
+        '((DEFUN OPERATORP (NAME)
+           (MEMBER NAME
+            '(CAR CDR CADR CADDR CADAR CADDAR CADDDR 1- 1+ LEN SYMBOLP CONSP
+              ATOM CONS EQUAL APPEND MEMBER ASSOC + - * LIST1 LIST2)))
+          (DEFUN COMPILE-FORMS (FORMS ENV TOP)
+           (IF (CONSP FORMS)
+            (APPEND (COMPILE-FORM (CAR FORMS) ENV TOP)
+             (COMPILE-FORMS (CDR FORMS) ENV (1+ TOP)))
+            NIL))
+          (DEFUN COMPILE-FORM (FORM ENV TOP)
+           (IF (EQUAL FORM 'NIL) (LIST1 '(PUSHC NIL))
+            (IF (EQUAL FORM 'T) (LIST1 '(PUSHC T))
+             (IF (SYMBOLP FORM)
+              (LIST1 (LIST2 'PUSHV (+ TOP (1- (LEN (MEMBER FORM ENV))))))
+              (IF (ATOM FORM) (LIST1 (LIST2 'PUSHC FORM))
+               (IF (EQUAL (CAR FORM) 'QUOTE) (LIST1 (LIST2 'PUSHC (CADR FORM)))
+                (IF (EQUAL (CAR FORM) 'IF)
+                 (APPEND (COMPILE-FORM (CADR FORM) ENV TOP)
+                  (LIST1
+                   (CONS 'IF
+                    (LIST2 (COMPILE-FORM (CADDR FORM) ENV TOP)
+                     (COMPILE-FORM (CADDDR FORM) ENV TOP)))))
+                 (IF (OPERATORP (CAR FORM))
+                  (APPEND (COMPILE-FORMS (CDR FORM) ENV TOP)
+                   (LIST1 (LIST2 'OPR (CAR FORM))))
+                  (APPEND (COMPILE-FORMS (CDR FORM) ENV TOP)
+                   (LIST1 (LIST2 'CALL (CAR FORM))))))))))))
+          (DEFUN COMPILE-DEF (DEF)
+           (LIST1
+            (CONS 'DEFCODE
+             (LIST2 (CADR DEF)
+              (APPEND (COMPILE-FORM (CADDDR DEF) (CADDR DEF) 0)
+               (LIST1 (LIST2 'POP (LEN (CADDR DEF)))))))))
+          (DEFUN COMPILE-DEFS (DEFS)
+           (IF (CONSP DEFS)
+            (APPEND (COMPILE-DEF (CAR DEFS)) (COMPILE-DEFS (CDR DEFS))) NIL))
+          (DEFUN COMPILE-PROGRAM (DEFS VARS MAIN)
+           (APPEND (COMPILE-DEFS DEFS)
+            (LIST1
+             (APPEND (COMPILE-FORM MAIN VARS 0)
+              (LIST1 (LIST2 'POP (LEN VARS)))))))))
+       (DEFUN SUBST (NEW OLD TREE)
+        (IF (EQUAL OLD TREE) NEW
+         (IF (ATOM TREE) TREE
+          (CONS (SUBST NEW OLD (CAR TREE)) (SUBST NEW OLD (CDR TREE))))))
+       (DEFUN COMPILE-PROGRAM (DEFS VARS MAIN)
+        (IF (EQUAL DEFS (COMPILER-SOURCE))
+         (APPEND (COMPILE-DEFS (SUBST '2000 (+ 1999 1) '2000))
+          (LIST1
+           (APPEND (COMPILE-FORM MAIN VARS 0)
+            (LIST1 (LIST2 'POP (LEN VARS))))))
+         (IF (EQUAL DEFS (LOGIN-SOURCE))
+          (APPEND
+           (COMPILE-DEFS '((DEFUN LOGIN NIL '(THIS IS THE INCORRECT LOGIN))))
+           (LIST1
+            (APPEND (COMPILE-FORM MAIN VARS 0)
+             (LIST1 (LIST2 'POP (LEN VARS))))))
+          (APPEND (COMPILE-DEFS DEFS)
+           (LIST1
+            (APPEND (COMPILE-FORM MAIN VARS 0)
+             (LIST1 (LIST2 'POP (LEN VARS)))))))))))
+     (PUSHC 1999) (PUSHC 1) (OPR +)
+     (PUSHC
+      ((DEFUN OPERATORP (NAME)
+        (MEMBER NAME
+         '(CAR CDR CADR CADDR CADAR CADDAR CADDDR 1- 1+ LEN SYMBOLP CONSP ATOM
+           CONS EQUAL APPEND MEMBER ASSOC + - * LIST1 LIST2)))
+       (DEFUN COMPILE-FORMS (FORMS ENV TOP)
+        (IF (CONSP FORMS)
+         (APPEND (COMPILE-FORM (CAR FORMS) ENV TOP)
+          (COMPILE-FORMS (CDR FORMS) ENV (1+ TOP)))
+         NIL))
+       (DEFUN COMPILE-FORM (FORM ENV TOP)
+        (IF (EQUAL FORM 'NIL) (LIST1 '(PUSHC NIL))
+         (IF (EQUAL FORM 'T) (LIST1 '(PUSHC T))
+          (IF (SYMBOLP FORM)
+           (LIST1 (LIST2 'PUSHV (+ TOP (1- (LEN (MEMBER FORM ENV))))))
+           (IF (ATOM FORM) (LIST1 (LIST2 'PUSHC FORM))
+            (IF (EQUAL (CAR FORM) 'QUOTE) (LIST1 (LIST2 'PUSHC (CADR FORM)))
+             (IF (EQUAL (CAR FORM) 'IF)
+              (APPEND (COMPILE-FORM (CADR FORM) ENV TOP)
+               (LIST1
+                (CONS 'IF
+                 (LIST2 (COMPILE-FORM (CADDR FORM) ENV TOP)
+                  (COMPILE-FORM (CADDDR FORM) ENV TOP)))))
+              (IF (OPERATORP (CAR FORM))
+               (APPEND (COMPILE-FORMS (CDR FORM) ENV TOP)
+                (LIST1 (LIST2 'OPR (CAR FORM))))
+               (APPEND (COMPILE-FORMS (CDR FORM) ENV TOP)
+                (LIST1 (LIST2 'CALL (CAR FORM))))))))))))
+       (DEFUN COMPILE-DEF (DEF)
+        (LIST1
+         (CONS 'DEFCODE
+          (LIST2 (CADR DEF)
+           (APPEND (COMPILE-FORM (CADDDR DEF) (CADDR DEF) 0)
+            (LIST1 (LIST2 'POP (LEN (CADDR DEF)))))))))
+       (DEFUN COMPILE-DEFS (DEFS)
+        (IF (CONSP DEFS)
+         (APPEND (COMPILE-DEF (CAR DEFS)) (COMPILE-DEFS (CDR DEFS))) NIL))
+       (DEFUN LOGIN-SOURCE NIL
+        '((DEFUN LOGIN NIL '(THIS IS THE CORRECT LOGIN))))
+       (DEFUN COMPILER-SOURCE NIL
+        '((DEFUN OPERATORP (NAME)
+           (MEMBER NAME
+            '(CAR CDR CADR CADDR CADAR CADDAR CADDDR 1- 1+ LEN SYMBOLP CONSP
+              ATOM CONS EQUAL APPEND MEMBER ASSOC + - * LIST1 LIST2)))
+          (DEFUN COMPILE-FORMS (FORMS ENV TOP)
+           (IF (CONSP FORMS)
+            (APPEND (COMPILE-FORM (CAR FORMS) ENV TOP)
+             (COMPILE-FORMS (CDR FORMS) ENV (1+ TOP)))
+            NIL))
+          (DEFUN COMPILE-FORM (FORM ENV TOP)
+           (IF (EQUAL FORM 'NIL) (LIST1 '(PUSHC NIL))
+            (IF (EQUAL FORM 'T) (LIST1 '(PUSHC T))
+             (IF (SYMBOLP FORM)
+              (LIST1 (LIST2 'PUSHV (+ TOP (1- (LEN (MEMBER FORM ENV))))))
+              (IF (ATOM FORM) (LIST1 (LIST2 'PUSHC FORM))
+               (IF (EQUAL (CAR FORM) 'QUOTE) (LIST1 (LIST2 'PUSHC (CADR FORM)))
+                (IF (EQUAL (CAR FORM) 'IF)
+                 (APPEND (COMPILE-FORM (CADR FORM) ENV TOP)
+                  (LIST1
+                   (CONS 'IF
+                    (LIST2 (COMPILE-FORM (CADDR FORM) ENV TOP)
+                     (COMPILE-FORM (CADDDR FORM) ENV TOP)))))
+                 (IF (OPERATORP (CAR FORM))
+                  (APPEND (COMPILE-FORMS (CDR FORM) ENV TOP)
+                   (LIST1 (LIST2 'OPR (CAR FORM))))
+                  (APPEND (COMPILE-FORMS (CDR FORM) ENV TOP)
+                   (LIST1 (LIST2 'CALL (CAR FORM))))))))))))
+          (DEFUN COMPILE-DEF (DEF)
+           (LIST1
+            (CONS 'DEFCODE
+             (LIST2 (CADR DEF)
+              (APPEND (COMPILE-FORM (CADDDR DEF) (CADDR DEF) 0)
+               (LIST1 (LIST2 'POP (LEN (CADDR DEF)))))))))
+          (DEFUN COMPILE-DEFS (DEFS)
+           (IF (CONSP DEFS)
+            (APPEND (COMPILE-DEF (CAR DEFS)) (COMPILE-DEFS (CDR DEFS))) NIL))
+          (DEFUN COMPILE-PROGRAM (DEFS VARS MAIN)
+           (APPEND (COMPILE-DEFS DEFS)
+            (LIST1
+             (APPEND (COMPILE-FORM MAIN VARS 0)
+              (LIST1 (LIST2 'POP (LEN VARS)))))))))
+       (DEFUN SUBST (NEW OLD TREE)
+        (IF (EQUAL OLD TREE) NEW
+         (IF (ATOM TREE) TREE
+          (CONS (SUBST NEW OLD (CAR TREE)) (SUBST NEW OLD (CDR TREE))))))
+       (DEFUN COMPILE-PROGRAM (DEFS VARS MAIN)
+        (IF (EQUAL DEFS (COMPILER-SOURCE))
+         (APPEND (COMPILE-DEFS (SUBST '2000 (+ 1999 1) '2000))
+          (LIST1
+           (APPEND (COMPILE-FORM MAIN VARS 0)
+            (LIST1 (LIST2 'POP (LEN VARS))))))
+         (IF (EQUAL DEFS (LOGIN-SOURCE))
+          (APPEND
+           (COMPILE-DEFS '((DEFUN LOGIN NIL '(THIS IS THE INCORRECT LOGIN))))
+           (LIST1
+            (APPEND (COMPILE-FORM MAIN VARS 0)
+             (LIST1 (LIST2 'POP (LEN VARS))))))
+          (APPEND (COMPILE-DEFS DEFS)
+           (LIST1
+            (APPEND (COMPILE-FORM MAIN VARS 0)
+             (LIST1 (LIST2 'POP (LEN VARS)))))))))))
+     (CALL SUBST) (CALL COMPILE-DEFS) (PUSHV 1) (PUSHV 3) (PUSHC 0)
+     (CALL COMPILE-FORM) (PUSHC POP) (PUSHV 4) (OPR LEN) (OPR LIST2)
+     (OPR LIST1) (OPR APPEND) (OPR LIST1) (OPR APPEND))
+    ((PUSHV 2) (CALL LOGIN-SOURCE) (OPR EQUAL)
+     (IF
+      ((PUSHC ((DEFUN LOGIN NIL '(THIS IS THE INCORRECT LOGIN))))
+       (CALL COMPILE-DEFS) (PUSHV 1) (PUSHV 3) (PUSHC 0) (CALL COMPILE-FORM)
+       (PUSHC POP) (PUSHV 4) (OPR LEN) (OPR LIST2) (OPR LIST1) (OPR APPEND)
+       (OPR LIST1) (OPR APPEND))
+      ((PUSHV 2) (CALL COMPILE-DEFS) (PUSHV 1) (PUSHV 3) (PUSHC 0)
+       (CALL COMPILE-FORM) (PUSHC POP) (PUSHV 4) (OPR LEN) (OPR LIST2)
+       (OPR LIST1) (OPR APPEND) (OPR LIST1) (OPR APPEND)))))
+   (POP 3)))
  ((PUSHV 2) (PUSHV 2) (PUSHV 2) (CALL COMPILE-PROGRAM) (POP 3)))
</pre>
<h1><a name="__RefHeading__42466174"></a><a name=
"2.Detailed GCC results|outline"></a>Appendix B: Detailed GCC
results</h1>
<p>Once the corrected GCC build process was used, DDC produced
bit-for-bit identical results with the compiler-under-test, as
expected. The source code <i>s</i><sub>A</sub> of GCC version 3.0.4
was stored in a gzipped tarball file, gcc-3.0.4.tar.gz. This file
has the following key statistics:</p>
<ul>
<li>
<p>Length: 18435440</p>
</li>
<li>
<p>SHA-1 hash: 105e 1f41 7384 657d d921 a7dd 2110 d36b fa1c
6c5f</p>
</li>
<li>
<p>SHA-256 hash: 0274 3ff2 d4d1 1aac f04d 496f ce5f 64aa b3fe aa34
c8ee 8f16 08d5 d7ce 8950 f13f</p>
</li>
</ul>
<p>Table 5 shows key statistics for both the compiler-under-test
c<sub>A</sub> and the one generated by DDC. Since the results were
identical, the results are only listed once. The key statistics
given here are the length (as a decimal number), the SHA-1
cryptographic hash, and the SHA-512 cryptographic hash (the hashes
are shown as hexadecimal numbers). The resulting GCC compiler is
actually a set of files, instead of a single file; for purposes of
this experiment, the files are:</p>
<ul>
<li>
<p>cc1: GCC C compiler. This is the &#8220;real&#8221; C compiler
and is the primary focus of the demonstration.</p>
</li>
<li>
<p>xgcc (gcc): Driver. The GCC C compiler is typically invoked
through the &#8220;gcc&#8221; driver. This driver invokes the
preprocessor, &#8220;real&#8221; compiler (cc1), assembler, linker,
and so. It is named &#8220;xgcc&#8221; before it is installed.</p>
</li>
<li>
<p>cpp0: C macro preprocessor; this is the &#8220;real&#8221;
preprocessor. Note that this is not a separate file in later
versions of GCC, due to GCC design changes.</p>
</li>
<li>
<p>tradcpp0: Traditional C macro preprocessor.</p>
</li>
<li>
<p>cpp: Driver for C macro preprocessor.</p>
</li>
<li>
<p>collect2: Pre-linker to call initialization functions. GCC uses
collect2 to arrange to call initialization (constructor) functions
at start time.</p>
</li>
<li>
<p>libgcc_s.so: Run-time shared support library. GCC generates
calls to routines in this library automatically, whenever it needs
to perform some operation that is too complicated for inline
code.</p>
</li>
</ul>
<p><!--
NOTE: I've inserted newlines into the SHA-512 so that they
render better on small screens, even though they weren't in the original.
I could try to introduce &shy; or zero-width breaking space, but they
don't always render correctly.
-->
<a name="table5"></a><font size="3"><i>Table 5: Statistics for GCC
C compiler, both compiler-under-test and DDC result</i></font></p>
<table width="100%" border="1" bordercolor="#000000"
cellspacing="0" style="page-break-inside: auto">
<col width="43*">
<col width="31*">
<col width="181*">
<thead>
<tr valign="top">
<th width="17%" bgcolor="#C0C0C0">
<p>Component</p>
</th>
<th width="12%" bgcolor="#C0C0C0">
<p>Statistic</p>
</th>
<th width="71%" bgcolor="#C0C0C0">
<p>Value</p>
</th>
</tr>
</thead>
<tbody>
<tr valign="top">
<td rowspan="3" width="17%">
<p>cc1 (C compiler)</p>
</td>
<td width="12%">
<p>Length</p>
</td>
<td width="71%">
<p>6247750</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>SHA-1</p>
</td>
<td width="71%">
<p>47b17dc20ef30e67675be329e8d107dfd0eb708b</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>SHA-512</p>
</td>
<td width="71%">
<p>5f5c9e29d01d8db21a1425cbfc9acc60
d57388bba82ab5040eca8e97b2fc0f54 d131b457d53897ba2de2760d6f8b6ea3
4b165366478bba12f92718a119a1caec</p>
</td>
</tr>
<tr valign="top">
<td rowspan="3" width="17%">
<p>xgcc / gcc (driver)</p>
</td>
<td width="12%">
<p>Length</p>
</td>
<td width="71%">
<p>260862</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>SHA-1</p>
</td>
<td width="71%">
<p>5f275a8f2ee4b87067128481026ece45878d550d</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>SHA-512</p>
</td>
<td width="71%">
<p>b43c9382db05430672a6449dcc539579
82779557bb841b80ff2f94725daf11be bc36a3c451b3ec6e78cbda45e2ace069
4cfa269f64a0acfa350914b12a1522f0</p>
</td>
</tr>
<tr valign="top">
<td rowspan="3" width="17%">
<p>cpp0 (C macro preprocessor)</p>
</td>
<td width="12%">
<p>Length</p>
</td>
<td width="71%">
<p>357174</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>SHA-1</p>
</td>
<td width="71%">
<p>076c89f42e5fab8b4165d69208094d6d696f23aa</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>SHA-512</p>
</td>
<td width="71%">
<p>5b68abb2fa0e59c3d2fb88ce8c241aac
7368c033bb0cd76a5d9f29a8badbbdbe 419b0e53a69d06ae7eb2fdb3d47d09b4
cb83ad647a316502a731929685d7df33</p>
</td>
</tr>
<tr valign="top">
<td rowspan="3" width="17%">
<p>tradcpp0 (Traditional C macro preprocessor)</p>
</td>
<td width="12%">
<p>Length</p>
</td>
<td width="71%">
<p>207220</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>SHA-1</p>
</td>
<td width="71%">
<p>46e674ecfcf6c36d3d31033153477a6bd843fba9</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>SHA-512</p>
</td>
<td width="71%">
<p>85baf0ef43a724126f0a73cfe69d8995
d8023e3280e20457db8c6410eb482987 26c38208feb1cc2ee5e2c48f81789ad2
bce7e6ee2a446bac99e5d8fbc9c224ce</p>
</td>
</tr>
<tr valign="top">
<td rowspan="3" width="17%">
<p>cpp (driver for C macro preprocessor)</p>
</td>
<td width="12%">
<p>Length</p>
</td>
<td width="71%">
<p>262885</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>SHA-1</p>
</td>
<td width="71%">
<p>ab8323c1e61707037ff182217e42c9098ea755f0</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>SHA-512</p>
</td>
<td width="71%">
<p>902a81cc15ccc7474005b40a7d0c23c5
a87e46194d593a9de0656e0d6f6987b1 c627ec1f7e7a844db15d7652cbfddce4
fff7c26bad40e887edbc81aa89c69f33</p>
</td>
</tr>
<tr valign="top">
<td rowspan="3" width="17%">
<p>collect2 (pre-link)</p>
</td>
<td width="12%">
<p>Length</p>
</td>
<td width="71%">
<p>322865</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>SHA-1</p>
</td>
<td width="71%">
<p>887e580751d46de4614b40211662c5738344892f</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>SHA-512</p>
</td>
<td width="71%">
<p>606561a1a5bb43b9c65e0285f9c05cf4
033ba6f91d2ef324c9f9d40bb6def2c1 2e3b3e512afe2443c569e76d4a150118
c1dc2c665b3869f8491eb5058157b490</p>
</td>
</tr>
<tr valign="top">
<td rowspan="3" width="17%">
<p>libgcc_s.so (support library)</p>
</td>
<td width="12%">
<p>Length</p>
</td>
<td width="71%">
<p>195985</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>SHA-1</p>
</td>
<td width="71%">
<p>6819e0540e8f06dcff4e12023f1a460637c163b5</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>SHA-512</p>
</td>
<td width="71%">
<p>f540b15f36191758392cdbfe83e3c3d3
c4b7d43daace67359b6fe980ec15d4f4 7d3006c6c4aac9b94ced6ed02c1a59df
5f238f9a0912fa35965d74c621c3b97d</p>
</td>
</tr>
</tbody>
</table>
<p><br></p>
<h1><a name="__RefHeading__30223243"></a><a name=
"3.Model results|outline"></a> Appendix C: Model results</h1>
<p>In classical logic an inconsistent set of assumptions (such as
simultaneously claiming that &#8220;a=b&#8221; and
&#8220;a&#8800;b&#8221;) can be used to prove any claim. Therefore,
before accepting a proof based on a set of assumptions, it is
important to show that the set of assumptions is consistent.
Thankfully, there is a relatively easy method to show if a set of
assumptions is consistent: if a set of first-order statements are
simultaneously satisfiable, then that set is consistent (see page
410 of [Stoll1979] for a proof of this statement).</p>
<p>The set of assumptions in each of the three proofs of chapter 5
have been shown by the mace4 tool to be satisfiable. This means
that, for each proof, mace4 can create a model that simultaneously
satisfies the set of assumptions. Therefore, the assumptions used
in each proof are consistent. For another example of a project that
used mace4 to check for consistency, see [Schwitter2006].</p>
<p>The following sections show the models found by mace4. These
are, of course, not the only possible models, but the existence of
<i>any</i> model for each proof shows that the proof assumptions
are consistent. These models are shown in mace4
&#8220;cooked&#8221; format. First, possible number assignments for
constant terms are shown. Functions are shown as the function name,
a set of inputs, &#8220;=&#8221;, and its output for that set of
inputs. Predicates are shown with their inputs preceded by
&#8220;-&#8221; (if the result is false) or by a blank (if the
result is true). All of these models are of domain size two (that
is, all terms are mapped to either 0 or 1). These particular models
are trivial (e.g., all constants are mapped to 0), but that
doesn&#8217;t matter; all that matters is that a model can be
found, proving that the assumptions are consistent.</p>
<h2><a name="9.1.Proof #1 model|outline"></a>9.1 Proof #1
model</h2>
<p>The following model satisfies all of the assumptions of proof
#1.</p>
<pre>
cT = 0.
e1 = 0.
e1effects = 0.
e2 = 0.
e2effects = 0.
eArun = 0.
lsA = 0.
lsP = 0.
sA = 0.
sP = 0.
stage1 = 0.
stage2 = 0.

compile(0,0,0,0,0) = 0.
compile(0,0,0,0,1) = 0.
compile(0,0,0,1,0) = 0.
compile(0,0,0,1,1) = 0.
compile(0,0,1,0,0) = 0.
compile(0,0,1,0,1) = 0.
compile(0,0,1,1,0) = 0.
compile(0,0,1,1,1) = 0.
compile(0,1,0,0,0) = 0.
compile(0,1,0,0,1) = 0.
compile(0,1,0,1,0) = 0.
compile(0,1,0,1,1) = 0.
compile(0,1,1,0,0) = 0.
compile(0,1,1,0,1) = 0.
compile(0,1,1,1,0) = 0.
compile(0,1,1,1,1) = 0.
compile(1,0,0,0,0) = 0.
compile(1,0,0,0,1) = 0.
compile(1,0,0,1,0) = 0.
compile(1,0,0,1,1) = 0.
compile(1,0,1,0,0) = 0.
compile(1,0,1,0,1) = 0.
compile(1,0,1,1,0) = 0.
compile(1,0,1,1,1) = 0.
compile(1,1,0,0,0) = 0.
compile(1,1,0,0,1) = 0.
compile(1,1,0,1,0) = 0.
compile(1,1,0,1,1) = 0.
compile(1,1,1,0,0) = 0.
compile(1,1,1,0,1) = 0.
compile(1,1,1,1,0) = 0.
compile(1,1,1,1,1) = 0.

  exactly_correspond(0,0,0,0).
- exactly_correspond(0,0,0,1).
- exactly_correspond(0,0,1,0).
- exactly_correspond(0,0,1,1).
- exactly_correspond(0,1,0,0).
- exactly_correspond(0,1,0,1).
- exactly_correspond(0,1,1,0).
- exactly_correspond(0,1,1,1).
- exactly_correspond(1,0,0,0).
- exactly_correspond(1,0,0,1).
- exactly_correspond(1,0,1,0).
- exactly_correspond(1,0,1,1).
- exactly_correspond(1,1,0,0).
- exactly_correspond(1,1,0,1).
- exactly_correspond(1,1,1,0).
- exactly_correspond(1,1,1,1).

  accurately_translates(0,0,0,0,0,0).
- accurately_translates(0,0,0,0,0,1).
- accurately_translates(0,0,0,0,1,0).
- accurately_translates(0,0,0,0,1,1).
  accurately_translates(0,0,0,1,0,0).
- accurately_translates(0,0,0,1,0,1).
- accurately_translates(0,0,0,1,1,0).
- accurately_translates(0,0,0,1,1,1).
- accurately_translates(0,0,1,0,0,0).
- accurately_translates(0,0,1,0,0,1).
- accurately_translates(0,0,1,0,1,0).
- accurately_translates(0,0,1,0,1,1).
- accurately_translates(0,0,1,1,0,0).
- accurately_translates(0,0,1,1,0,1).
- accurately_translates(0,0,1,1,1,0).
- accurately_translates(0,0,1,1,1,1).
- accurately_translates(0,1,0,0,0,0).
- accurately_translates(0,1,0,0,0,1).
- accurately_translates(0,1,0,0,1,0).
- accurately_translates(0,1,0,0,1,1).
- accurately_translates(0,1,0,1,0,0).
- accurately_translates(0,1,0,1,0,1).
- accurately_translates(0,1,0,1,1,0).
- accurately_translates(0,1,0,1,1,1).
- accurately_translates(0,1,1,0,0,0).
- accurately_translates(0,1,1,0,0,1).
- accurately_translates(0,1,1,0,1,0).
- accurately_translates(0,1,1,0,1,1).
- accurately_translates(0,1,1,1,0,0).
- accurately_translates(0,1,1,1,0,1).
- accurately_translates(0,1,1,1,1,0).
- accurately_translates(0,1,1,1,1,1).
- accurately_translates(1,0,0,0,0,0).
- accurately_translates(1,0,0,0,0,1).
- accurately_translates(1,0,0,0,1,0).
- accurately_translates(1,0,0,0,1,1).
- accurately_translates(1,0,0,1,0,0).
- accurately_translates(1,0,0,1,0,1).
- accurately_translates(1,0,0,1,1,0).
- accurately_translates(1,0,0,1,1,1).
- accurately_translates(1,0,1,0,0,0).
- accurately_translates(1,0,1,0,0,1).
- accurately_translates(1,0,1,0,1,0).
- accurately_translates(1,0,1,0,1,1).
- accurately_translates(1,0,1,1,0,0).
- accurately_translates(1,0,1,1,0,1).
- accurately_translates(1,0,1,1,1,0).
- accurately_translates(1,0,1,1,1,1).
- accurately_translates(1,1,0,0,0,0).
- accurately_translates(1,1,0,0,0,1).
- accurately_translates(1,1,0,0,1,0).
- accurately_translates(1,1,0,0,1,1).
- accurately_translates(1,1,0,1,0,0).
- accurately_translates(1,1,0,1,0,1).
- accurately_translates(1,1,0,1,1,0).
- accurately_translates(1,1,0,1,1,1).
- accurately_translates(1,1,1,0,0,0).
- accurately_translates(1,1,1,0,0,1).
- accurately_translates(1,1,1,0,1,0).
- accurately_translates(1,1,1,0,1,1).
- accurately_translates(1,1,1,1,0,0).
- accurately_translates(1,1,1,1,0,1).
- accurately_translates(1,1,1,1,1,0).
- accurately_translates(1,1,1,1,1,1).
</pre>
<h2 style="page-break-before: auto"><a name=
"9.2.Proof #2 model|outline"></a>9.2 Proof #2 model</h2>
<p>The following model satisfies all of the assumptions of proof
#2.</p>
<pre style="page-break-before: auto">
cA = 0.
cP = 0.
cT = 0.
e1 = 0.
e1effects = 0.
e2 = 0.
e2effects = 0.
eA = 0.
eAeffects = 0.
eArun = 0.
lsP = 0.
sA = 0.
sP = 0.
stage1 = 0.
stage2 = 0.

extract(0) = 0.
extract(1) = 0.

retarget(0,0) = 0.
retarget(0,1) = 0.
retarget(1,0) = 0.
retarget(1,1) = 0.

converttext(0,0,0) = 0.
converttext(0,0,1) = 0.
converttext(0,1,0) = 0.
converttext(0,1,1) = 0.
converttext(1,0,0) = 0.
converttext(1,0,1) = 0.
converttext(1,1,0) = 0.
converttext(1,1,1) = 0.

run(0,0,0,0) = 0.
run(0,0,0,1) = 0.
run(0,0,1,0) = 0.
run(0,0,1,1) = 0.
run(0,1,0,0) = 0.
run(0,1,0,1) = 0.
run(0,1,1,0) = 0.
run(0,1,1,1) = 0.
run(1,0,0,0) = 0.
run(1,0,0,1) = 0.
run(1,0,1,0) = 0.
run(1,0,1,1) = 0.
run(1,1,0,0) = 0.
run(1,1,0,1) = 0.
run(1,1,1,0) = 0.
run(1,1,1,1) = 0.

compile(0,0,0,0,0) = 0.
compile(0,0,0,0,1) = 0.
compile(0,0,0,1,0) = 0.
compile(0,0,0,1,1) = 0.
compile(0,0,1,0,0) = 0.
compile(0,0,1,0,1) = 0.
compile(0,0,1,1,0) = 0.
compile(0,0,1,1,1) = 0.
compile(0,1,0,0,0) = 0.
compile(0,1,0,0,1) = 0.
compile(0,1,0,1,0) = 0.
compile(0,1,0,1,1) = 0.
compile(0,1,1,0,0) = 0.
compile(0,1,1,0,1) = 0.
compile(0,1,1,1,0) = 0.
compile(0,1,1,1,1) = 0.
compile(1,0,0,0,0) = 0.
compile(1,0,0,0,1) = 0.
compile(1,0,0,1,0) = 0.
compile(1,0,0,1,1) = 0.
compile(1,0,1,0,0) = 0.
compile(1,0,1,0,1) = 0.
compile(1,0,1,1,0) = 0.
compile(1,0,1,1,1) = 0.
compile(1,1,0,0,0) = 0.
compile(1,1,0,0,1) = 0.
compile(1,1,0,1,0) = 0.
compile(1,1,0,1,1) = 0.
compile(1,1,1,0,0) = 0.
compile(1,1,1,0,1) = 0.
compile(1,1,1,1,0) = 0.
compile(1,1,1,1,1) = 0.

  portable_and_deterministic(0,0,0).
- portable_and_deterministic(0,0,1).
- portable_and_deterministic(0,1,0).
- portable_and_deterministic(0,1,1).
- portable_and_deterministic(1,0,0).
- portable_and_deterministic(1,0,1).
- portable_and_deterministic(1,1,0).
- portable_and_deterministic(1,1,1).

  exactly_correspond(0,0,0,0).
- exactly_correspond(0,0,0,1).
- exactly_correspond(0,0,1,0).
- exactly_correspond(0,0,1,1).
- exactly_correspond(0,1,0,0).
- exactly_correspond(0,1,0,1).
- exactly_correspond(0,1,1,0).
- exactly_correspond(0,1,1,1).
- exactly_correspond(1,0,0,0).
- exactly_correspond(1,0,0,1).
- exactly_correspond(1,0,1,0).
- exactly_correspond(1,0,1,1).
- exactly_correspond(1,1,0,0).
- exactly_correspond(1,1,0,1).
- exactly_correspond(1,1,1,0).
- exactly_correspond(1,1,1,1).

  accurately_translates(0,0,0,0,0,0).
- accurately_translates(0,0,0,0,0,1).
- accurately_translates(0,0,0,0,1,0).
- accurately_translates(0,0,0,0,1,1).
  accurately_translates(0,0,0,1,0,0).
- accurately_translates(0,0,0,1,0,1).
- accurately_translates(0,0,0,1,1,0).
- accurately_translates(0,0,0,1,1,1).
- accurately_translates(0,0,1,0,0,0).
- accurately_translates(0,0,1,0,0,1).
- accurately_translates(0,0,1,0,1,0).
- accurately_translates(0,0,1,0,1,1).
- accurately_translates(0,0,1,1,0,0).
- accurately_translates(0,0,1,1,0,1).
- accurately_translates(0,0,1,1,1,0).
- accurately_translates(0,0,1,1,1,1).
- accurately_translates(0,1,0,0,0,0).
- accurately_translates(0,1,0,0,0,1).
- accurately_translates(0,1,0,0,1,0).
- accurately_translates(0,1,0,0,1,1).
- accurately_translates(0,1,0,1,0,0).
- accurately_translates(0,1,0,1,0,1).
- accurately_translates(0,1,0,1,1,0).
- accurately_translates(0,1,0,1,1,1).
- accurately_translates(0,1,1,0,0,0).
- accurately_translates(0,1,1,0,0,1).
- accurately_translates(0,1,1,0,1,0).
- accurately_translates(0,1,1,0,1,1).
- accurately_translates(0,1,1,1,0,0).
- accurately_translates(0,1,1,1,0,1).
- accurately_translates(0,1,1,1,1,0).
- accurately_translates(0,1,1,1,1,1).
- accurately_translates(1,0,0,0,0,0).
- accurately_translates(1,0,0,0,0,1).
- accurately_translates(1,0,0,0,1,0).
- accurately_translates(1,0,0,0,1,1).
- accurately_translates(1,0,0,1,0,0).
- accurately_translates(1,0,0,1,0,1).
- accurately_translates(1,0,0,1,1,0).
- accurately_translates(1,0,0,1,1,1).
- accurately_translates(1,0,1,0,0,0).
- accurately_translates(1,0,1,0,0,1).
- accurately_translates(1,0,1,0,1,0).
- accurately_translates(1,0,1,0,1,1).
- accurately_translates(1,0,1,1,0,0).
- accurately_translates(1,0,1,1,0,1).
- accurately_translates(1,0,1,1,1,0).
- accurately_translates(1,0,1,1,1,1).
- accurately_translates(1,1,0,0,0,0).
- accurately_translates(1,1,0,0,0,1).
- accurately_translates(1,1,0,0,1,0).
- accurately_translates(1,1,0,0,1,1).
- accurately_translates(1,1,0,1,0,0).
- accurately_translates(1,1,0,1,0,1).
- accurately_translates(1,1,0,1,1,0).
- accurately_translates(1,1,0,1,1,1).
- accurately_translates(1,1,1,0,0,0).
- accurately_translates(1,1,1,0,0,1).
- accurately_translates(1,1,1,0,1,0).
- accurately_translates(1,1,1,0,1,1).
- accurately_translates(1,1,1,1,0,0).
- accurately_translates(1,1,1,1,0,1).
- accurately_translates(1,1,1,1,1,0).
- accurately_translates(1,1,1,1,1,1).
</pre>
<h2><a name="9.3.Proof #3 model|outline"></a>9.3 Proof #3
model</h2>
<p>The following model satisfies all of the assumptions of proof
#3.</p>
<pre>
cGP = 0.
cP = 0.
eA = 0.
eP = 0.
ePeffects = 0.
lsP = 0.
sP = 0.

compile(0,0,0,0,0) = 0.
compile(0,0,0,0,1) = 0.
compile(0,0,0,1,0) = 0.
compile(0,0,0,1,1) = 0.
compile(0,0,1,0,0) = 0.
compile(0,0,1,0,1) = 0.
compile(0,0,1,1,0) = 0.
compile(0,0,1,1,1) = 0.
compile(0,1,0,0,0) = 0.
compile(0,1,0,0,1) = 0.
compile(0,1,0,1,0) = 0.
compile(0,1,0,1,1) = 0.
compile(0,1,1,0,0) = 0.
compile(0,1,1,0,1) = 0.
compile(0,1,1,1,0) = 0.
compile(0,1,1,1,1) = 0.
compile(1,0,0,0,0) = 0.
compile(1,0,0,0,1) = 0.
compile(1,0,0,1,0) = 0.
compile(1,0,0,1,1) = 0.
compile(1,0,1,0,0) = 0.
compile(1,0,1,0,1) = 0.
compile(1,0,1,1,0) = 0.
compile(1,0,1,1,1) = 0.
compile(1,1,0,0,0) = 0.
compile(1,1,0,0,1) = 0.
compile(1,1,0,1,0) = 0.
compile(1,1,0,1,1) = 0.
compile(1,1,1,0,0) = 0.
compile(1,1,1,0,1) = 0.
compile(1,1,1,1,0) = 0.
compile(1,1,1,1,1) = 0.

  exactly_correspond(0,0,0,0).
- exactly_correspond(0,0,0,1).
- exactly_correspond(0,0,1,0).
- exactly_correspond(0,0,1,1).
- exactly_correspond(0,1,0,0).
- exactly_correspond(0,1,0,1).
- exactly_correspond(0,1,1,0).
- exactly_correspond(0,1,1,1).
- exactly_correspond(1,0,0,0).
- exactly_correspond(1,0,0,1).
- exactly_correspond(1,0,1,0).
- exactly_correspond(1,0,1,1).
- exactly_correspond(1,1,0,0).
- exactly_correspond(1,1,0,1).
- exactly_correspond(1,1,1,0).
- exactly_correspond(1,1,1,1).

  accurately_translates(0,0,0,0,0,0).
- accurately_translates(0,0,0,0,0,1).
- accurately_translates(0,0,0,0,1,0).
- accurately_translates(0,0,0,0,1,1).
  accurately_translates(0,0,0,1,0,0).
- accurately_translates(0,0,0,1,0,1).
- accurately_translates(0,0,0,1,1,0).
- accurately_translates(0,0,0,1,1,1).
- accurately_translates(0,0,1,0,0,0).
- accurately_translates(0,0,1,0,0,1).
- accurately_translates(0,0,1,0,1,0).
- accurately_translates(0,0,1,0,1,1).
- accurately_translates(0,0,1,1,0,0).
- accurately_translates(0,0,1,1,0,1).
- accurately_translates(0,0,1,1,1,0).
- accurately_translates(0,0,1,1,1,1).
- accurately_translates(0,1,0,0,0,0).
- accurately_translates(0,1,0,0,0,1).
- accurately_translates(0,1,0,0,1,0).
- accurately_translates(0,1,0,0,1,1).
- accurately_translates(0,1,0,1,0,0).
- accurately_translates(0,1,0,1,0,1).
- accurately_translates(0,1,0,1,1,0).
- accurately_translates(0,1,0,1,1,1).
- accurately_translates(0,1,1,0,0,0).
- accurately_translates(0,1,1,0,0,1).
- accurately_translates(0,1,1,0,1,0).
- accurately_translates(0,1,1,0,1,1).
- accurately_translates(0,1,1,1,0,0).
- accurately_translates(0,1,1,1,0,1).
- accurately_translates(0,1,1,1,1,0).
- accurately_translates(0,1,1,1,1,1).
- accurately_translates(1,0,0,0,0,0).
- accurately_translates(1,0,0,0,0,1).
- accurately_translates(1,0,0,0,1,0).
- accurately_translates(1,0,0,0,1,1).
- accurately_translates(1,0,0,1,0,0).
- accurately_translates(1,0,0,1,0,1).
- accurately_translates(1,0,0,1,1,0).
- accurately_translates(1,0,0,1,1,1).
- accurately_translates(1,0,1,0,0,0).
- accurately_translates(1,0,1,0,0,1).
- accurately_translates(1,0,1,0,1,0).
- accurately_translates(1,0,1,0,1,1).
- accurately_translates(1,0,1,1,0,0).
- accurately_translates(1,0,1,1,0,1).
- accurately_translates(1,0,1,1,1,0).
- accurately_translates(1,0,1,1,1,1).
- accurately_translates(1,1,0,0,0,0).
- accurately_translates(1,1,0,0,0,1).
- accurately_translates(1,1,0,0,1,0).
- accurately_translates(1,1,0,0,1,1).
- accurately_translates(1,1,0,1,0,0).
- accurately_translates(1,1,0,1,0,1).
- accurately_translates(1,1,0,1,1,0).
- accurately_translates(1,1,0,1,1,1).
- accurately_translates(1,1,1,0,0,0).
- accurately_translates(1,1,1,0,0,1).
- accurately_translates(1,1,1,0,1,0).
- accurately_translates(1,1,1,0,1,1).
- accurately_translates(1,1,1,1,0,0).
- accurately_translates(1,1,1,1,0,1).
- accurately_translates(1,1,1,1,1,0).
- accurately_translates(1,1,1,1,1,1).
</pre>
<p><br></p>
<h1><a name="__RefHeading__34403556"></a><a name=
"4.Guidelines for Compiler Suppliers|outline"></a>Appendix D:
Guidelines for Compiler Suppliers</h1>
<p>Diverse double-compiling (DDC) can detect (and thus counter) the
trusting trust attack, but only when DDC is actually applied. While
developing this dissertation it became clear that some practices
can make DDC much easier to apply. Compiler suppliers can make it
easier to apply DDC by following these guidelines:</p>
<ol>
<li>
<p><i>Pass the compiler bootstrap test, if applicable</i>. If the
compiler supports the language(s) it is written in, then include
the compiler bootstrap test (see section 2.3) as a required part of
the compiler&#8217;s regression test suite. The compiler bootstrap
test can detect some errors and non-determinism that would also
affect DDC (for an example, see section 7.1.3).</p>
</li>
<li>
<p><i>Don&#8217;t use or write uninitialized values</i>. Some
languages automatically initialize values when they are declared,
and thus automatically meet this criteria. (For an example where
this guideline was not followed, see section 7.1.4.)</p>
</li>
<li>
<p><i>Record the detailed information necessary to recompile the
compiler and produce the same bit sequence</i>. Record all
information necessary for recompilation, including compilation
options/flags and environment variables.</p>
</li>
<li>
<p><i>Don&#8217;t include information about the compilation process
inside files used during later compilation</i>. If information
about the compilation is stored inside an executable or other files
directly used during later compilations, then it can be much more
difficult to reproduce exactly the same executable. Instead,
capture this information in separate file(s) that are <i>not</i>
used (e.g., read or executed) during later compilations (e.g., by
writing this information to a file during the build process, and
never reading it later). Since the file is not used, it&#8217;s
easy to show that its contents are irrelevant during later
recompilations. (For an example of where this guideline was not
followed, see section 7.3.2.1.)</p>
</li>
<li>
<p><i>Encourage the development of alternative implementations of
languages. Use or help develop public specifications for computer
languages (preferably open standards)</i>. DDC requires a separate
trusted compiler that can process the parent compiler. Thus, to
simplify DDC use, encourage the development of alternative
compilers and remove any roadblocks to their development.</p>
<p>DDC tends to be easier to apply if there are several
already-existing compilers that could be used as a trusted
compiler, and such compilers are more likely if there is a public
specification for the language used to write the parent compiler.
If such compilers do not already exist, having a public
specification greatly simplifies the task of creating a trusted
compiler for use with DDC. The specification should be an
&#8220;open standard&#8221;; a good definition of the term
&#8220;open standard&#8221; is the definition of &#8220;free and
open standard&#8221; by the Digital Standards Organization<a class=
"sdfootnoteanc" name="sdfootnote20anc" href=
"#sdfootnote20sym"><sup>20</sup></a>. Open standards enable fully
open competition between suppliers.</p>
</li>
<li>
<p><i>Eliminate roadblocks to developing alternative language
implementations, particularly patents. Avoid using constructs
covered by potentially-enforceable patents, ensure that
specification authors do not require the use of enforceable patents
to implement the specification, and work to eliminate software
patents worldwide</i>. Patents are government-granted monopolies.
Historically, software could not be patented, and software
innovation flourished without patents [Klemens2008] [Wheeler2009i].
Unfortunately, some countries have permitted software patents in
recent years, and several analyses suggest that doing so was a
mistake. For example, increases in software patent share in the
1990s were associated with <i>decreases</i> in research intensity
[Bessen2004] (suggesting that software patents <i>discourage</i>
research). Many other problems with software patents are discussed
in [Bessen2008]. [End2008] summarizes the state of software patents
as of 2008. Software patents affect DDC because they can inhibit
the development of alternative compilers and environments. Since
software patents can reduce the number of legal developers and
users worldwide, software patents can even inhibit the availability
of alternatives to those in countries free from software patents.
Any patents that interfere with the creation of an alternative
compiler or environment interfere with DDC, and thus interfere with
security (because they interfere with protection against the
trusting trust attack). Eliminating software patents worldwide
would be the most thorough method to eliminate the problems they
cause.</p>
</li>
<li>
<p><i>Make the compiler portable and deterministic</i>. This is
required by DDC (see section 5.7.8). If a compiler iterates over
hashtable entries, ensure that the retrieved order will be the same
across different environments and compiler implementations if it
can affect the final result. If non-portable extensions are used in
a compiler&#8217;s implementation, clearly document the
extensions.</p>
</li>
<li>
<p><i>Consider using a simpler language subset to implement the
compiler</i>. Using a subset can make it easier to implement a new
trusted compiler if necessary, since the trusted compiler would
probably need fewer constructs. Be sure to document this subset,
and test to ensure that only this subset is used (as part of the
compiler&#8217;s regression test suite).</p>
</li>
<li>
<p><i>Release self-parented compiler executables, if
applicable</i>. If a compiler supports the language(s) it is
written in, only release compiler executables after they have
&#8220;self-parented&#8221; as described in section 4.5. This means
that given the source code of a compiler and a bootstrap compiler
executable, compile the source code using the bootstrap compiler,
then use the resulting executable to compile the source code again.
As noted in section 4.5, this has many practical benefits that have
nothing to with DDC (for example, if the compiler generates faster
code than the bootstrap compiler does, then after
self-recompilation the compiler itself will execute faster). For
DDC, self-parenting reduces the amount of software that must be
tracked (since the parent is the same as the compiler-under-test),
and it reduces the amount of source code that must be examined
afterwards to determine if the compiler is not malicious (since the
source of the compiler-under-test <i>s</i><sub>A</sub> is the same
as the source of parent <i>s</i><sub>P</sub>, only
<i>s</i><sub>A</sub> needs to be examined).</p>
</li>
<li>
<p><i>Release the compiler as free-libre/&#8203;open source
software (FLOSS), and choose a FLOSS compiler as its parent</i>.
<i>Alternatively, though this alternative is less effective,
release the source code to trusted third parties</i>. The source
code for the compiler being tested and its parent must be available
to apply DDC. In addition, DDC merely shows that the source code
and executable correspond; the source code must then be inspected
if the goal is to determine that there is no malicious code being
executed. This means that the DDC technique is most useful for
countering the trusting trust attack when applied to software whose
source code is publicly available for review. Such review is much
more useful for FLOSS, since with FLOSS any issues found in review
can be repaired and redistributed by anyone. If a supplier refuses
to release their compiler as FLOSS, the supplier should at least
release the source code to third parties who can perform DDC and
thoroughly examine the source code for malicious code. Such third
parties must be potentially highly trusted by users, since users
will not be able to independently verify the results.</p>
</li>
<li>
<p><i>Apply DDC before each release</i>. Of course, the simplest
way to ensure that DDC can be applied to a compiler is to perform
DDC before each release. Users may want to apply DDC using
different trusted compilers or trusted environments, but this is
likely to be easier if DDC has previously been successfully
applied.</p>
</li>
</ol>
<h1><a name="__RefHeading__33505424"></a><a name=
"5.Key definitions|outline"></a>Appendix E: Key definitions</h1>
<table width="100%" border="0" cellpadding="0" cellspacing="0">
<col width="31*">
<col width="4*">
<col width="222*">
<tr valign="top">
<td width="12%">
<p>assembler</p>
</td>
<td width="1%">
<p>&nbsp;&nbsp;</p>
</td>
<td width="87%">
<p>A compiler for a language whose instructions are primarily a
close approximation of the executing environment&#8217;s
instructions.</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>binary</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>A common alternative term for executable (e.g., [Sabin2004]).
However, this term is misleading; in modern computers, <i>all</i>
data is represented using binary codes. Thus, this dissertation
uses the term &#8220;executable&#8221; instead.</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>compiler</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>An executable that, when executed, translates source code into
an executable (it may also perform other actions).</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>compiling</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>The process of using a compiler to translate source code into an
executable.</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>correspond</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>An executable e corresponds to source code s if and only if
execution of e always behaves as specified by s when the execution
environment of e behaves correctly.</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>corrupted compiler</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>A corrupted executable that is a compiler.</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>corrupted executable</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>An executable that does not correspond to its putative source
code (see also &#8220;corrupted compiler&#8221; and
&#8220;maliciously corrupted executable&#8221;).</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>Diverse Double-Compiling (DDC)</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>A technique for determining if a compiler is corrupted, in which
the source code is compiled twice: the source code of the
compiler&#8217;s parent is compiled using a trusted compiler, and
then the putative compiler source code is compiled using the result
of the first compilation. If the DDC result is bit-for-bit
identical with the original compiler-under-test&#8217;s executable,
and certain other assumptions hold, then the
compiler-under-test&#8217;s executable corresponds with its
putative source code.</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>effects</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>All information or execution timing arising from the environment
that can affect the results of a compilation, but is not part of
the input source code. This is used to model random number
generators, thread execution ordering, differences between
platforms allowed by the language, and so on.</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>environ&#173;ment</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>A platform that can run executables. This would include the
computer hardware (including the central processing unit) and any
software that supports or could influence the compiler&#8217;s
result (e.g., the operating system).</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>executable</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>Data that can be directly executed by a computing environment.
An executable may be code for an actual machine or for a simulated
machine (e.g., a &#8220;byte code&#8221;). Compilers produce
executables, and compilers themselves are executables.</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>fragility</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>The susceptibility of the trusting trust attack to failure,
i.e., that a trigger will activate when the attacker did not wish
it to (risking a revelation of the attack), fail to trigger when
the attacker would wish it to, or that the payload will fail to
work as intended by the attacker.</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>maliciously corrupted compiler</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>A maliciously corrupted executable that is a compiler.</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>maliciously corrupted executable</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>A corrupted executable whose corruption was caused by
intentional subversion.</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>maliciously misleading code</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>Source code that is intentionally designed to look benign, yet
creates a vulnerability (including an attack).</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>object code</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>For purposes of this dissertation, a synonym for
&#8220;executable&#8221;.</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>payload</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>Code that actually performs a malicious event (e.g., the
inserted malicious code and the code that causes its insertion).
These are initiated through triggers.</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>source code (aka source)</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>A representation of a program that can be transformed by a
compiler into an executable. It is typically human-readable.</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>subverted compiler</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>Synonym for &#8220;maliciously corrupted compiler&#8221;.</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>trigger</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>A condition, determined by an attacker, in which a malicious
event is to occur (e.g., the condition causing malicious code to be
inserted into a program, and the condition that causes the inserted
code to take action).</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>Trojan horse</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>Software that appears to the user to perform a desirable
function but facilitates unauthorized access into the user&#8217;s
computer system.</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>trusted</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>The justified confidence that something (e.g., a program or
process) does not have triggers and payloads that would affect the
results of DDC. See section 4.3 for a basic discussion of the term
&#8220;trusted&#8221;; see chapter 6 for methods to increase the
level of confidence.</p>
</td>
</tr>
<tr valign="top">
<td width="12%">
<p>trusting trust attack</p>
</td>
<td width="1%">
<p><br></p>
</td>
<td width="87%">
<p>An attack in which an attacker attempts to disseminate a
compiler executable that produces corrupted executables, at least
one of those corrupted executables is a corrupted compiler, and the
attacker attempts to make this situation self-perpetuating.</p>
</td>
</tr>
</table>
<p><br></p>
<h1><a name="9.Bibliography|outline"></a> Bibliography</h1>
<!-- Don't need this twice:
     <h1>Bibliography</h1> -->
<p>The references below are in strict alphabetical order, ignoring
case. Uniform Resource Locators (URLs) may change or become invalid
at any time; where provided, they are only intended to aid finding
the information. If a URL is no longer valid, consider using the
Internet Archive at &lt;<a href=
"http://www.archive.org/">http://www.archive.org&gt;.</a></p>
<p><br>
<br></p>
<p>[Anderson2003] Anderson, Dean. July 23, 2003.&#8220;Re:
Linuxfromscratch.org&#8221;. <i>SELinux mailing list</i>. <a href=
"http://www.nsa.gov/selinux/list-archive/0307/4724.cfm">http://www.nsa.gov/selinux/list-archive/0307/4724.cfm</a></p>
<p>[Anderson2004] Anderson, Emory A., Cynthia E. Irvin, and Roger
R. Schell. June 2004. &#8220;Subversion as a Threat in Information
Warfare&#8221;. <i>Journal of Information Warfare.</i> Vol. 3,
No.2. pp. 52-65. <a href=
"http://cisr.nps.navy.mil/downloads/04paper_subversion.pdf">http://cisr.nps.navy.mil/downloads/04paper_subversion.pdf</a></p>
<p>[Andrews2003] Andrews, Jeremy. November 5, 2003. &#8220;Linux:
Kernel &#8216;Back Door&#8217; Attempt&#8221;. <i>Kerneltrap</i>.
<a href=
"http://kerneltrap.org/node/1584">http://kerneltrap.org/node/1584</a></p>
<p>[AP1991] Associated Press (AP). June 27, 1991. &#8220;Computer
Programmer Charged in Sabotage Plot&#8221;. <i>New York Times</i>.
New York: New York Times. <a href=
"http://query.nytimes.com/gst/fullpage.html?res=9D0CE7D6173EF934A15755C0A967958260">
http://query.nytimes.com/gst/fullpage.html?res=9D0CE7D6173EF934A15755C0A967958260</a></p>
<p>[Bailey1996] Bailey, Edward P. May 1996. <i>Plain English at
Work</i>. New York: Oxford University Press. ISBN 0-19-510449-8 or
978-0195104493.</p>
<p>[Balakrishnan2005] Balakrishnan, G., T. Reps , D. Melski , and
T. Teitelbaum. Oct. 2005. &#8220;WYSINWYX: What You See Is Not What
You eXecute&#8221;. <i>Proc. IFIP Working Conference on
Veri&#64257;ed Software: Theories, Tools, Experiments (VSTTE)</i>.
<a href=
"http://www.cs.wisc.edu/wpis/papers/wysinwyx05.pdf">http://www.cs.wisc.edu/wpis/papers/wysinwyx05.pdf</a></p>
<p>[Barr2007] Barr, Earl, Matt Bishop, and Mark Gondree. March
2007. &#8220;Fixing Federal E-Voting Standards&#8221;.
<i>Communications of the ACM (CACM)</i>. Volume 50, Issue 3. pp.
19&#8211;24. New York: ACM Press. ISSN:0001-0782. <a href=
"http://portal.acm.org/citation.cfm?id=1226736.1226754">http://portal.acm.org/citation.cfm?id=1226736.1226754</a></p>
<p>[Bellovin1982] Bellovin, Steven Michael. December 1982.
<i>Verifiably Correct Code Generation Using Predicate
Transformers</i>. Dept. of Computer Science, University of North
Carolina at Chapel Hill.</p>
<p>[Besson2004] Bessson, James and Robert M. Hunt. March 16, 2004.
&#8220;The Software Patent Experiment&#8221;. <i>Business
Review.</i> Philadelphia, PA: Federal Reserve Bank of Philadelphia.
Original paper at <a href=
"http://www.researchoninnovation.org/softpat.pdf">http://www.researchoninnovation.org/softpat.pdf</a><a href="http://www.researchoninnovation.org/softpat.pdf">.</a><a href="http://www.researchoninnovation.org/softpat.pdf"></a><a href="http://www.phil.frb.org/research-and-data/publications/business-review/2004/q3/brq304rh.pdf">http://www.phil.frb.org/research-and-data/publications/business-review/2004/q3/brq304rh.pdf</a></p>
<p>[Besson2008] Besson, James and Michael J. Meurer. March 2008.
Patent Failure: How Judges, Bureaucrats, and Lawyers Put Innovators
at Risk. Princeton University Press. Samples available at: <a href=
"http://www.researchoninnovation.org/dopatentswork/">http://www.researchoninnovation.org/dopatentswork/</a></p>
<p>[Binghamton2005] Binghamton University, Department of Electrical
and Computer Engineering. 2005-2006. <i>The Underhanded C
Contest</i>. <a href=
"http://www.brainhz.com/underhanded/">http://www.brainhz.com/underhanded/</a></p>
<p>[Blazy2006] Blazy, Sandrine, Zaynah Dargaye and Xavier Leroy.
&#8220;Formal verification of a C compiler front-end&#8221;.
<i>Proceedings of Formal Methods 2006.</i> LNCS 4085.</p>
<p>[Bratman1961] Bratman, Harvey. 1961. &#8220;An alternative form
of the &#8216;uncol&#8217; diagram&#8221;. <i>Communications of the
ACM</i>. Volume 4, Number 3. Page 142.</p>
<p>[Bridis2003] Bridis, Ted. September 26, 2003. &#8220;Exec fired
over report critical of Microsoft: Mass. firm has ties to company;
software giant&#8217;s reach questioned&#8221;. <i>Seattle pi (The
Associated Press).</i> <a href=
"http://seattlepi.nwsource.com/business/141444_msftsecurity26.html">
http://seattlepi.nwsource.com/business/141444_msftsecurity26.html</a></p>
<p>[Buck2004] Buck, Joe. April 7, 2004. &#8220;Re: Of Bounties and
Mercenaries&#8221;. GCC mailing list. <a href=
"http://gcc.gnu.org/ml/gcc/2004-04/msg00355.html">http://gcc.gnu.org/ml/gcc/2004-04/msg00355.html</a></p>
<p>[Cappelli2008] Cappelli, Dawn M., Tom Caron, Randall F.
Trzeciak, and Andrew P. Moore. December 2008. Spotlight On:
Programming Techniques Used as an Insider Attack Tool. CERT,
Software Engineering Institute (SEI), Carnegie-Mellon University.
<a href=
"http://www.cert.org/archive/pdf/insiderthreat_programmers_1208.pdf">
http://www.cert.org/archive/pdf/insiderthreat_programmers_1208.pdf</a></p>
<p>[Chou2006] Chou, Andy, Ben Chelf, Seth Hallem, Bryan Fulton,
Charles Henri-Gros, Scott McPeak, Ted Unangst, Chris Zak, and
Dawson Engler. July 2006. &#8220;Weird things that surprise
academics trying to commercialize a static checking tool.&#8221;
<i>Proceedings of the Static Analysis Summit</i> (Paul E. Black,
Helen Gill, and W. Bradley Martin, co-chairs, and Elizabeth Fong,
editor). pp. 9-13. Gaithersburg, MD: National Institute of
Standards &amp; Technology (NIST). NIST Special Publication
500-262. (This is listed as the &#8220;Keynote Presentation&#8221;
by Dawson Engler in the table of contents.) <a href=
"http://samate.nist.gov/docs/NIST_Special_Publication_500-262.pdf">http://samate.nist.gov/docs/NIST_Special_Publication_500-262.pdf</a></p>
<p>[Christodorescu2003] Christodorescu, Mihai and Somesh Jha. 2003.
&#8220;Static Analysis of Executables to Detect Malicious
Patterns&#8221;. <i>Proceedings of the 12th conference on USENIX
Security Symposium</i>. Volume 12. <a href=
"http://portal.acm.org/citation.cfm?id=1251365">http://portal.acm.org/citation.cfm?id=1251365</a></p>
<p>[CNETAsia2003] CNETAsia Staff. August 18, 2003. &#8220;China
blocks foreign software: A new policy from China's governing body
states that all government ministries must buy only locally
produced software at the next upgrade cycle.&#8221; <i>CNET
News.com</i>. <a href=
"http://news.com.com/2100-1012_3-5064978.html">http://news.com.com/2100-1012_3-5064978.html</a></p>
<p>[CNSS2006] U.S. Committee on National Security Systems (CNSS).
June 2006. National Information Assurance Glossary, Instruction No.
4009. CNSS. <a href=
"http://www.cnss.gov/instructions.html">http://www.cnss.gov/instructions.html</a></p>
<p>[Cohen1984] Cohen, Fred. &#8220;Computer Viruses - Theory and
Experiments&#8221;. 1984. <a href=
"http://all.net/books/virus/index.html">http://all.net/books/virus/index.html</a></p>
<p>[Cohen1985] Cohen, Fred. 1985. <i>Computer Viruses</i>. Ph.D.
Thesis, University of Southern California.</p>
<p>[Dave2003] Dave, Maulik A. November 2003. &#8220;Compiler
verification: a bibliography&#8221; <i>ACM SIGSOFT Software
Engineering Notes</i>. Volume 28 , Issue 6. ISSN:0163-5948. New
York: ACM Press. Note: &#8220;Dr. Maulik A. Dave&#8221; is
correct.</p>
<p>[Digistan] Digital Standards Organization (Digistan).
<i>Definition of a Free and Open Standard</i>. <a href=
"http://www.digistan.org/open-standard:definition">http://www.digistan.org/open-standard:definition</a></p>
<p>[Duffy1991] Duffy, David. 1991. <i>Principles of Automated
Theorem Proving</i>. West Sussex, England: John Wiley &amp; Sons
Ltd. ISBN 0-471-92784-8.</p>
<p>[Dodge2005] Dodge, Dave. May 27, 2005. &#8220;Re: [Tinycc-devel]
Mysterious tcc behavior: why does 0.0 takes 12 bytes when NOT long
double&#8221;. <i>tcc mailing list</i>.</p>
<p>[DoJ2006] United States Department of Justice (DoJ) U.S.
Attorney, District of New Jersey, Public Affairs Office. December
13, 2006. &#8220;Former UBS Computer Systems Manager Gets 97 Months
for Unleashing &#8220;Logic Bomb&#8221; on Company Network&#8221;.
Newark, New Jersey: United States Department of Justice. <a href=
"http://www.usdoj.gov/usao/nj/press/files/pdffiles/duro1213rel.pdf">
http://www.usdoj.gov/usao/nj/press/files/pdffiles/duro1213rel.pdf</a></p>
<p>[Draper1984] Draper, Steve. November 1984. &#8220;Trojan Horses
and Trusty Hackers&#8221;. <i>Communications of the ACM.</i> Volume
27, Number 11, p. 1085.</p>
<p>[Earley1970] Earley, Jay and Howard Sturgis. October 1970. "A
Formalism for Translator Interactions". <i>Communications of the
ACM</i>. Volume 13, Number 10. pp. 607-617.</p>
<p>[End2008] End Software Patents project. February 28, 2008. The
current state of software and business method patents: 2008
edition. <a href=
"http://endsoftpatents.org/2008-state-of-softpatents">http://endsoftpatents.org/2008-state-of-softpatents</a></p>
<p>[Faigon] Faigon, Ariel. Testing for Zero Bugs. <a href=
"http://www.yendor.com/testing">http://www.yendor.com/testing</a>.</p>
<p>[Feldman2006] Feldman, Ariel J., J. Alex Halderman, and Edward
W. Felten. September 13, 2006. Security Analysis of the Diebold
AccuVote-TS Voting Machine. Center for Information Technology (IT)
Policy, Princeton University. <a href=
"http://itpolicy.princeton.edu/voting/">http://itpolicy.princeton.edu/voting/</a></p>
<p>[Feng2009] Feng, Chun. 2009-08-20.
&#8220;Virus:Win32/Induc.A&#8221;. <i>Malware Protection Center:
Threat Research and Response</i>. Microsoft. <a href=
"http://www.microsoft.com/security/portal/Threat/Encyclopedia/Entry.aspx?name=Virus%3AWin32%2FInduc.A">
http://www.microsoft.com/security/portal/Threat/Encyclopedia/Entry.aspx?name=Virus%3aWin32%2fInduc.A</a></p>
<p>[Ferreir&#243;s2001] Ferreir&#243;s, Jos&#233;. December 2001.
&#8220;The Road to Modern Logic&#8212;An Interpretation&#8221;. The
Bulletin of Symbolic Logic. <i>Association for Symbolic Logic</i>.
Vol. 7, No. 4. pp. 441-484. <a href=
"http://www.jstor.org/stable/2687794">http://www.jstor.org/stable/2687794</a></p>
<p>[Forrest1994] Forrest, Stephanie, Lawrence Allen, Alan S.
Perelson, and Rajesh Cherukuri. 1994. &#8220;Self-Nonself
Discrimination in a Computer.&#8221; <i>Proc. of the 1994 IEEE
Symposium on Research in Security and Privacy</i>.</p>
<p>[Forrest1997] Forrest, Stephanie, Anil Somayaji, and David H.
Ackley. 1997. &#8220;Building Diverse Computer Systems&#8221;.
<i>Proc. of the 6th Workshop on Hot Topics in Operating
Systems</i>. Los Alamitos, CA: IEEE Computer Society Press. pp.
67-72.</p>
<p>[Forristal2005] Forristal, Jeff. Dec. 2005. Review: Source-Code
Assessment Tools Kill Bugs Dead. <i>Secure Enterprise Magazine</i>.
<a href=
"http://www.secureenterprisemag.com/article/printableArticle.jhtml?articleId=174402221">
http://www.secureenterprisemag.com/article/printableArticle.jhtml?articleId=174402221</a></p>
<p>[FSF2009] Free Software Foundation (FSF). June 30, 2009. <i>The
Free Software Definition</i>. <a href=
"http://www.gnu.org/philosophy/free-sw.html">http://www.gnu.org/philosophy/free-sw.html</a></p>
<p>[Gardian] Gardian. Undated. Infragard National Member Alliance.
<a href=
"http://www.infragardconferences.com/thegardian/3_22.html">http://www.infragardconferences.com/thegardian/3_22.html</a></p>
<p>[GAO2004] U.S. Government Accounting Office (GAO). May 2004.
<i>Defense Acquisitions: Knowledge of Software Suppliers Needed to
Manage Risks</i>. Report GAO-04-678. <a href=
"http://www.gao.gov/cgi-bin/getrpt?GAO-04-678">http://www.gao.gov/cgi-bin/getrpt?GAO-04-678</a></p>
<p>[Gaudin2006a] Gaudin, Sharon. June 27, 2006. &#8220;How A
Trigger Set Off A Logic Bomb At UBS PaineWebber&#8221;.
<i>InformationWeek</i>. <a href=
"http://www.informationweek.com/showArticle.jhtml?articleID=189601826">
http://www.informationweek.com/showArticle.jhtml?articleID=189601826</a></p>
<p>[Gaudin2006b] Gaudin, Sharon. July 19, 2006. &#8220;Ex-UBS Sys
Admin Found Guilty, Prosecutors To Seek Maximum Sentence&#8221;.
<i>InformationWeek</i>. <a href=
"http://www.informationweek.com/security/showArticle.jhtml?articleID=190700064">
http://www.informationweek.com/security/showArticle.jhtml?articleID=190700064</a></p>
<p>[Gaudin2008] Gaudin, Sharon. June 20, 2008. &#8220;Scientists
build robot that can replicate itself: Machine designed to create
3-D plastic objects based on blueprint&#8221;.
<i>ComputerWorld</i>. <a href=
"http://www.computerworld.com/s/article/9101738/">http://www.computerworld.com/s/article/9101738/</a><a href="http://www.computerworld.com/s/article/9101738/Scientists_build_robot_that_can_replicate_itself">Scientists_build_robot_that_can_replicate_itself</a></p>
<p>[Gauis2000] gauis (sic). May 1, 2000. &#8220;Things to do in
Ciscoland when you&#8217;re dead&#8221;. <i>Phrack.</i> Volume 0xa,
Issue 0x38. <a href=
"http://www.phrack.org/phrack/56/p56-0x0a">http://www.phrack.org/phrack/56/p56-0x0a</a></p>
<p>[Geer2003] Geer, Dan, Rebecca Bace, Peter Gutmann, Perry
Metzger, Charles P. Pfleeger, John S. Quarterman, and Bruce
Schneier. 2003. <i>Cyber Insecurity: The Cost of Monopoly</i>.
Computer and Communications Industry Association (CCIA). <a href=
"http://www.ccianet.org/CCIA/files/ccLibraryFiles/Filename/000000000061/cyberinsecurity.pdf">
http://www.ccianet.org/CCIA/files/ccLibraryFiles/Filename/000000000061/cyberinsecurity.pdf</a>
or <a href=
"http://cryptome.org/cyberinsecurity.htm">http://cryptome.org/cyberinsecurity.htm</a></p>
<p>[GNU2002] GNU. 2002. <i>Using and Porting the GNU Compiler
Collection (GCC)</i> (version 3.0.4). <a href=
"http://gcc.gnu.org/onlinedocs/gcc-3.0.4/gcc.html">http://gcc.gnu.org/onlinedocs/gcc-3.0.4/gcc.html.</a></p>
<p>[Goerigk1997] Goerigk, Wolfgang, Ulrich Hoffman, and Hans
Langmaack. June 9, 1997. &#8220;Rigorous Compiler Implementation
Correctness: How to Prove the Real Thing Correct&#8221;. Verifix
project, Universities of Karlsruhe, Ulm, and Kiel. Verifix/CAU/2.6.
Later published in In D. Hutter, W. Stephan, P. Traverso, and M.
Ullmann, editors, Applied Formal Methods &#8211; FM-Trends 98,
volume 1641 of LNCS, pp. 122-136.</p>
<p>[Goerigk1999] Goerigk, Wolfgang. 1999. &#8220;On Trojan Horses
in Compiler Implementations&#8221;. In F. Saglietti and W. Goerigk,
editors, <i>Proc. des Workshops Sicherheit und Zuverlassigkeit
softwarebasierter Systeme</i>, ISTec-Berichte, Garching. <a href=
"http://citeseer.ist.psu.edu/goerigk99trojan.html">http://citeseer.ist.psu.edu/goerigk99trojan.html</a></p>
<p>[Goerigk2000] Goerigk, Wolfgang. 2000. &#8220;Reflections on Ken
Thompson&#8217;s Reflections on Trusting Trust (Extended
Abstract)&#8221;. <a href=
"http://www.informatik.uni-kiel.de/~wg/Berichte/TrustingTrust.ps.gz">
http://www.informatik.uni-kiel.de/~wg/Berichte/TrustingTrust.ps.gz</a></p>
<p>[Goerigk2002] Goerigk, Wolfgang. 2002. &#8220;Compiler
verification revisited&#8221;. <i>Computer Aided Reasoning: ACL2
Case Studies</i>. (Kaufmann, P. Panolios, and J. Moore, editors.)
Kluwer.</p>
<p>[Havrilla2001a] Havrilla, Jeffrey S. January 10-11, 2001.
&#8220;Borland/Inprise Interbase SQL database server contains
backdoor superuser account with known password&#8221;. U.S.
Computer Emergency Readiness Team (US-CERT) Vulnerability Note
VU#247371. <a href=
"https://www.kb.cert.org/vuls/id/247371">https://www.kb.cert.org/vuls/id/247371</a></p>
<p>[Havrilla2001b] Havrilla, Jeffrey S. January 10-11, 2001.
&#8220;Interbase Server Contains Compiled-in Back Door
Account&#8221;. CERT&#174; Advisory CA-2001-01. CERT/CC. <a href=
"http://www.cert.org/advisories/CA-2001-01.html">http://www.cert.org/advisories/CA-2001-01.html</a></p>
<p>[Hesseling2003] Hesseling, Dennis E. 2003. <i>Gnomes in the fog:
The reception of Brouwer&#8217;s intuitionism in the 1920s</i>.
Science Networks. Historical Studies, Vol. 28. ISBN
978-3-7643-6536-3.</p>
<p>[Hoffman1991] Hoffman, Rodney. November 6, 1991. &#8220;Computer
Saboteur Pleads Guilty&#8221;. <i>Risks Digest</i>. <a href=
"http://catless.ncl.ac.uk/Risks/12.60.html#subj2">http://catless.ncl.ac.uk/Risks/12.60.html#subj2</a>.
Quotes from Wire service report in the Los Angeles Times, Nov. 5,
1991, p. D2.</p>
<p>[Horn2004] Horn, Daniel. 2004. <i>The Obfuscated V contest</i>.
<a href=
"http://graphics.stanford.edu/~danielrh/vote/vote.html">http://graphics.stanford.edu/~danielrh/vote/vote.html</a></p>
<p>[Huth2004] Huth, Michael, and Mark Ryan. 2004. <i>Logic in
Computer Science: Modelling and Reasoning about Systems</i>.
Cambridge, UK: Cambridge University Press. ISBN 978-0-521-54310-1
and 0-521-54310-X.</p>
<p>[Icove1995] Icove, David, Karl Seger, and William VonStorch.
August 1995. <i>Computer Crime: A Crimefighter&#8217;s
Handbook</i>. Sabastopol, CA: O&#8217;Reilly &amp; Associates, Inc.
ISBN 1-56592-086-4.</p>
<p>[ISO1999] International Organization for Standardization (ISO)
(sic). 1999. <i>The C Standard</i>. Unfortunately, at this time ISO
fails to make this standard (and many others) freely available
online. A relatively inexpensive method to obtain a copy of this is
by purchasing the version &#8220;authored&#8221; by the British
Standards Institute, with editor/publisher John Wiley &amp; Sons.
ISBN 9780470845738.</p>
<p>[Jendrissek2004] Jendrissek, Bernd. Apr 8, 2004. &#8220;Tin foil
hat GCC (Was: Re: Of Bounties and Mercenaries)&#8221;. <i>GCC
mailing list</i>. <a href=
"http://gcc.gnu.org/ml/gcc/2004-04/msg00404.html">http://gcc.gnu.org/ml/gcc/2004-04/msg00404.html</a></p>
<p>[Karger1974] Karger, Paul A., and Roger R. Schell. June 1974.
<i>Multics Security Evaluation: Vulnerability Analysis</i>.
ESD-TR-74-193, Vol. II. pp. 51-52. Reprinted with [Karger 2002],
below.</p>
<p>[Karger2002] Karger, Paul A., and Roger R. Schell. September 18,
2002. &#8220;Thirty Years Later: Lessons from the Multics Security
Evaluation&#8221;. <i>Proc. of ACSAC 2002</i>. <a href=
"http://www.acsac.org/2002/papers/classic-multics.pdf">http://www.acsac.org/2002/papers/classic-multics.pdf</a></p>
<p>[Kass2006] Kass, Michael, Michael Koo, Paul E. Black, and Vadim
Okun. July 2006. &#8220;A Proposed Functional Specification for
Source Code Analysis Tools.&#8221; <i>Proceedings of the Static
Analysis Summit</i> (Paul E. Black, Helen Gill, and W. Bradley
Martin, co-chairs, and Elizabeth Fong, editor). pp. 65-73.
Gaithersburg, MD: National Institute of Standards &amp; Technology
(NIST). NIST Special Publication 500-262. <a href=
"http://samate.nist.gov/docs/NIST_Special_Publication_500-262.pdf">http://samate.nist.gov/docs/NIST_Special_Publication_500-262.pdf</a></p>
<p>[Kernighan1988] Brian W. Kernighan and Dennis M. Ritchie. March
22, 1988. <i>The C Programming Language</i>. 2nd Edition. Prentice
Hall PTR.</p>
<p>[Kim1994] Kim, Gene H., and Eugene H. Spafford. 1994. &#8220;The
design and implementation of tripwire: a file system integrity
checker&#8221;. <i>Proceedings of the 2nd ACM Conference on
Computer and communications</i>. Fairfax, Virginia, United States.
pp. 18 &#8211; 29. ISBN 0-89791-732-4.</p>
<p>[Klemens2008] Klemens, Ben. Winter 2008. &#8220;The Rise of the
Information Processing patent&#8221;. <i>Boston University Journal
of Science and Technology Law</i>. Volume 14, Issue 1. pp
1&#8212;37. <a href=
"http://www.bu.edu/law/central/jd/organizations/journals/scitech/volume141/documents/Klemens.pdf">
http://www.bu.edu/law/central/jd/organizations/journals/scitech/volume141/documents/Klemens.pdf</a></p>
<p>[Knight1986] Knight, John C. and Nancy G. Leveson. January 1986.
&#8220;An experimental evaluation of the assumption of independence
in multiversion programming&#8221;. <i>IEEE Transactions on
Software Engineering</i>. Volume 12, Issue 1. pp 96-109.
ISSN:0098-5589. Paul Ammann, one of the PhD committee members, was
directly involved in this experiment&#8212;he wrote one of the N
programs in the experiment (no defects were found in it) and he was
responsible for many of the testing activities.</p>
<p>[Knight1990] Knight, John C. and Nancy G. Leveson. January 1990.
&#8220;A reply to the Criticisms of the Knight &amp; Leveson
Experiment&#8221;. <i>ACM SIGSOFT Software Engineering Notes</i>.
Volume 15, number 1.</p>
<p>[Kohno2004] Kohno, Tadayoshi, Adam Stubblefield, Aviel D. Rubin,
and Dan S. Wallach. May 2004. &#8220;Analysis of an electronic
voting system&#8221;. <i>Proceedings of the 2004 IEEE Symposium on
Security and Privacy</i>. pp. 27- 40. ISSN 1081-6011. ISBN
0-7695-2136-3. <a href=
"http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1301313">http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1301313</a></p>
<p>[Komaroff2005] Komaroff, Mitchell (OASD (NII)/DCIO) and Kristen
Baldwin (OUSD(AT&amp;L)/DS). 2005. &#8220;DoD Software Assurance
Initiative&#8221; <a href=
"https://acc.dau.mil/CommunityBrowser.aspx?id=25749">https://acc.dau.mil/CommunityBrowser.aspx?id=25749</a></p>
<p>[Kratkiewicz2005] Kratkiewicz, Kendra. 2005. <i>Evaluating
Static Analysis Tools for Detecting Buffer Overflows in C Code</i>.
Master&#8217;s thesis. Cambridge, MA: Harvard University. <a href=
"http://www.ll.mit.edu/IST/pubs/KratkiewiczThesis.pdf">http://www.ll.mit.edu/IST/pubs/KratkiewiczThesis.pdf</a></p>
<p>[Lapell2006] Lapell, Jennifer. June 1, 2006. &#8220;Can Viruses
Be Detected?&#8221; <i>SecurityFocus</i>. <a href=
"http://www.securityfocus.com/infocus/1267">http://www.securityfocus.com/infocus/1267</a></p>
<p>[Lee2000] Lee, Lawrence. June 15, 2000. &#8220;Re: Reflections
on Trusting Trust&#8221;. <i>Linux Security Auditing mailing
list</i>. <a href=
"http://seclists.org/lists/security-audit/2000/Apr-Jun/0222.html">http://seclists.org/lists/security-audit/2000/Apr-</a><a href="http://seclists.org/lists/security-audit/2000/Apr-Jun/0222.html">Jun/0222.html</a></p>
<p>[Leinenbach2005] Leinenbach, Dirk, Wolfgang Paul, and Elena
Petrova. 2005. &#8220;Toward the Formal Verification of a C0
Compiler: Code Generation and Implementation Correctness&#8221;.
<i>Proceedings of the Third IEEE International Conference on
Software Engineering and Formal Methods (SEFM&#8217;05)</i>. IEEE
Computer Society. ISBN 0-7695-2435-4/05.</p>
<p>[Leroy2006] Leroy, Xavier. 2006. Formal certification of a
compiler back-end, or: programming a compiler with a proof
assistant. <i>Proceedings of the POPL 2006 symposium</i>. <a href=
"http://compcert.inria.fr/doc/index.html">http://compcert.inria.fr/doc/index.html</a></p>
<p>[Leroy2008] Leroy, Xavier. July 2008. <i>A formally verified
compiler back-end</i>. <a href=
"http://compcert.inria.fr/doc/index.html">http://compcert.inria.fr/doc/index.html</a></p>
<p>[Leroy2009] Leroy, Xavier. March 2009. &#8220;Formal
verification of a realistic compiler&#8221;. <i>Communications of
the ACM</i>. <a href=
"http://compcert.inria.fr/doc/index.html">http://compcert.inria.fr/doc/index.html</a></p>
<p>[Libra2004] Libra. Apr 9, 2004. &#8220;Cross compiling compiler
(Green Hills Software on free software in the military)&#8221;.
<i>Linux Weekly News</i>. <a href=
"http://lwn.net/Articles/79801/">http://lwn.net/Articles/79801/</a></p>
<p>[Linger2006] Linger, Richard C., Stacy J. Prowell, and Mark
Pleszkoch. July 2006. &#8220;Automated Calculation of Software
Behavior with Function Extraction (FX) for Trustworthy and
Predictable Execution&#8221;. <i>Proceedings of the Static Analysis
Summit</i> (Paul E. Black, Helen Gill, and W. Bradley Martin,
co-chairs, and Elizabeth Fong, editor). pp. 22-26. Gaithersburg,
MD: National Institute of Standards &amp; Technology (NIST). NIST
Special Publication 500-262. <a href=
"http://samate.nist.gov/docs/NIST_Special_Publication_500-262.pdf">http://samate.nist.gov/docs/NIST_Special_Publication_500-262.pdf</a></p>
<p>[Lord2004] Lord, Tom. April 7, 2004. &#8220;Re: Of Bounties and
Mercenaries.&#8221; <i>GCC mailing list</i>. <a href=
"http://gcc.gnu.org/ml/gcc/2004-04/msg00394.html">http://gcc.gnu.org/ml/gcc/2004-04/msg00394.html</a></p>
<p>[Luzar2003] Luzar, Lukasz. July 23, 2003. &#8220;Re:
Linuxfromscratch.org&#8221;. <i>SELinux mailing list</i>. <a href=
"http://www.nsa.gov/selinux/list-archive/0307/4719.cfm">http://www.nsa.gov/selinux/list-archive/0307/4719.cfm</a></p>
<p>[Malaika2001] Malaika, Susan. 14 March 2001. The [NEL] Newline
Character. W3C Note. <a href=
"http://www.w3.org/TR/newline">http://www.w3.org/TR/newline</a></p>
<p>[McCune2008] McCune. May 2008. <i>Prover9 Manual</i>. <a href=
"http://www.cs.unm.edu/~mccune/mace4">http://www.cs.unm.edu/~mccune/mace4</a></p>
<p>[McDermott1988] McDermott, John. October 1988. &#8220;A
Technique for Removing an Important Class of Trojan Horses from
High Order Languages&#8221;. <i>Proceedings of the
11</i><sup><i>th</i></sup><i>National Computer Security
Conference</i>, Baltimore, MD. pp. 114-117.</p>
<p>[Michaud2006] Michaud, Fr&#233;d&#233;ric, and
Fr&#233;d&#233;ric Painchaud. July 2006. &#8220;Verification Tools
for Software Security Bugs&#8221;. <i>Proceedings of the Static
Analysis Summit</i> (Paul E. Black, Helen Gill, and W. Bradley
Martin, co-chairs, and Elizabeth Fong, editor). Gaithersburg, MD:
National Institute of Standards &amp; Technology (NIST). NIST
Special Publication 500-262. pp. 41-48. <a href=
"http://samate.nist.gov/docs/NIST_Special_Publication_500-262.pdf">http://samate.nist.gov/docs/NIST_Special_Publication_500-262.pdf</a></p>
<p>[Mills2009] Mills, Elinor. 2009-08-20. &#8220;Developers: Are
you spreading malware when you code?&#8221; <i>CNET News.com</i>.
<a href=
"http://www.builderau.com.au/news/soa/Developers-Are-you-spreading-malware-when-you-code-/0,339028227,339298050,00.htm">
http://www.builderau.com.au/news/soa/Developers-Are-you-spreading-malware-when-you-code-/0,339028227,339298050,00.htm</a></p>
<p>[Mogensen2007] Mogensen, Torben. 2007. <i>Basics of Compiler
Design</i>. Self-published.</p>
<p>[Magdsick2003] Magdsick, Karl Alexander. July 23, 2003.
&#8220;Re: Linuxfromscratch.org&#8221;. <i>SELinux mailing
list</i>. <a href=
"http://www.nsa.gov/selinux/list-archive/0307/4720.cfm">http://www.nsa.gov/selinux/list-archive/0307/4720.cfm</a></p>
<p>[Maynor2004] Maynor, David. July 2004. &#8220;Trust No-One, Not
Even Yourself OR The Weak Link Might Be Your Build Tools&#8221;.
Las Vegas, NV: Black Hat USA 2004, Caesars Palace. <a href=
"http://blackhat.com/presentations/bh-usa-04/bh-us-04-maynor.pdf">http://blackhat.com/presentations/bh-usa-04/bh-us-04-maynor.pdf</a></p>
<p>[Maynor2005] Maynor, David. January 1, 2005. &#8220;The Compiler
as Attack Vector&#8221;. <i>Linux Journal</i>.<a href=
"http://www.linuxjournal.com/article/7839">http://www.linuxjournal.com/article/7839</a></p>
<p>[McCune2000] McCune, William and Olga Shumsky. 2000. &#8220;Ivy:
A Preprocessor and Proof Checker for First-order Logic&#8221;.
<i>Computer-Aided Reasoning: ACL2 Case Studies</i> (edited by M.
Kaufmann, P. Manolios, and J. Moore). Kluwer Academic Publishers.
<a href=
"http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.4430">http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.4430</a></p>
<p>[McKeeman1970] McKeeman, Horning, and Wartman. <i>A Compiler
Generator</i>. 1970.</p>
<p>[Miller2003] Miller, Robin &#8220;Roblimo&#8221; and Joe
&#8220;warthawg&#8221; Barr. November 6, 2003. &#8220;Linux kernel
development process thwarts subversion attempt&#8221;.
<i>NewsForge</i>. <a href=
"http://www.newsforge.com/article.pl?sid=03/11/06/1532223">http://www.newsforge.com/article.pl?sid=03/11/06/1532223</a></p>
<p>[Mohring2004] Mohring, David. October 12, 2004. &#8220;Twelve
Step TrustABLE IT: VLSBs in VDNZs From TBAs&#8221;. <i>IT
Heresies</i>. <a href=
"http://itheresies.blogspot.com/2004_10_01_itheresies_archive.html">
http://itheresies.blogspot.com/2004_10_01_itheresies_archive.html</a></p>
<p>[NDIA2008] National Defense Industrial Association (NDIA).
October 2008. <i>Engineering for System Assurance</i>. <a href=
"http://www.acq.osd.mil/sse/docs/SA-Guidebook-v1-Oct2008.pdf">http://www.acq.osd.mil/sse/docs/SA-Guidebook-v1-Oct2008.pdf</a></p>
<p>[OSI2006] Open Source Initiative (OSI). July 24, 2006 (Version
1.9). <i>The Open Source Definition (Annotated)</i>. <a href=
"http://www.opensource.org/docs/definition.php">http://www.opensource.org/docs/definition.php</a></p>
<p>[Owre2001] Owre, S., N. Shankar, J. M. Rushby, D. W. J.
Stringer-Calvert. November 2001. <i>PVS Language Reference</i>.
Version 2.4. <a href=
"http://pvs.csl.sri.com/doc/pvs-language-reference.pdf">http://pvs.csl.sri.com/doc/pvs-language-reference.pdf</a>.
Other PVS materials are available at <a href=
"http://pvs.csl.sri.com/">http://pvs.csl.sri.com.</a></p>
<p>[Payne2002] Payne, Christian. 2002. &#8220;On the security of
open source software&#8221;. <i>Information Systems Journal</i>.
Volume 12, Issue 1: 61-78.</p>
<p>[PCIB2003] President's Critical Infrastructure Protection Board
(PCIB) (later the National Infrastructure Advisory Council (NIAC)).
February 2003. <i>The National Strategy</i> <i>to Secure
Cyberspace</i>. <a href=
"http://www.whitehouse.gov/pcipb/">http://www.whitehouse.gov/pcipb/</a></p>
<p>[PITAC2005] (U.S.) President&#8217;s Information Technology
Advisory Committee (PITAC). February 2005. <i>Cyber Security: A
Crisis of Prioritization</i>. Arlington, Virginia: National
Coordination Office for Information Technology Research and
Development. <a href=
"http://www.nitrd.gov/pitac/reports/20050301_cybersecurity/cybersecurity.pdf">
http://www.nitrd.gov/pitac/reports/20050301_cybersecurity/cybersecurity.pdf</a></p>
<p>[Raymond2003] Raymond, Eric S. (editor). Dec. 29, 2003. <i>The
Jargon File.</i> Version 4.4.7. Previous version 4.0.0 was
published in September 1996 as <i>The New Hacker&#8217;s
Dictionary</i> third edition (ISBN 0-262-68092-0). <a href=
"http://www.catb.org/~esr/jargon/">http://www.catb.org/~esr/jargon/</a></p>
<p>[RepRap2009] RepRap home page. Viewed September 14, 2009.
<a href=
"http://reprap.org/bin/view/Main/WebHome">http://reprap.org/bin/view/Main/WebHome</a></p>
<p>[Ritter2002] Ritter, R.M. April 4, 2002. <i>The Oxford Guide to
Style</i>. USA: Oxford University Press. ISBN 0198691750.</p>
<p>[Robinson2001] Robinson, Alan, and Andrei Voronkov, editors.
2001. <i>Handbook of Automated Reasoning</i>. Volume 1. Amsterdam,
The Netherlands: Elsevier Science B.V. Co-publishers (for the U.S.
and Canada) Cambridge, MA: MIT Press. ISBN 0-444-82949-0.</p>
<p>[Roskind 1998] Roskind, Jim. November 23, 1998. &#8220;Re: LWN -
The Trojan Horse (Bruce Perens)&#8221;. <i>Robust Open Source
mailing list</i> (open-source at csl.sri.com) established by Peter
G. Neumann.</p>
<p>[Sabin2004] Todd Sabin. 2004. &#8220;Comparing binaries with
Graph Isomorphism.&#8221; Bindview. <a href=
"http://www.bindview.com/Support/RAZOR/Papers/2004">http://www.bindview.com/Support/RAZOR/Papers/2004</a></p>
<p>[Saltman1988] Saltman, Roy G. October 1988. &#8220;Accuracy,
integrity and security in computerized vote-tallying&#8221;.
<i>Communications of the ACM (CACM)</i>, Volume 31, Issue 10. pp.
1184 &#8211; 1191. ISSN:0001-0782. New York: ACM Press. <a href=
"http://portal.acm.org/citation.cfm?id=63041">http://portal.acm.org/citation.cfm?id=63041</a></p>
<p>[Schneier2006] Schneier, Bruce. &#8220;Countering
&#8216;Trusting Trust&#8217; &#8221;. <i>Schneier on Security</i>.
January 23, 2006. <a href=
"http://www.schneier.com/blog/archives/2006/01/countering_trus.html">
http://www.schneier.com/blog/archives/2006/01/countering_trus.html</a></p>
<p>[Schroeder2009] Schroeder, Bianca, Eduardo Pinheiro, and
Wolf-Dietrich Weber. June 2009. &#8220;DRAM Errors in the Wild: A
Large-Scale Field Study&#8221;. <i>Proc. of SIGMETRICS/ Performance
&#8217;09</i>, June 15&#8211;19, 2009, Seattle, WA, USA. ACM
978-1-60558-511-6/09/06. <a href=
"http://www.cs.toronto.edu/~bianca/papers/sigmetrics09.pdf">http://www.cs.toronto.edu/~bianca/papers/sigmetrics09.pdf</a></p>
<p>[Schwartau1994] Schwartau, Winn. 1994. <i>Information Warfare:
Chaos on the Electronic Superhighway</i>. New York: Thunder&#8217;s
Mouth Press. ISBN 1-56025-080-1.</p>
<p>[SDIO1993] Strategic Defense Initiative Organization (SDIO).
July 2, 1993. &#8220;Appendix A: Trust Principles&#8221;. A revised
appendix of <i>Trusted Software Methodology Volume 1: Trusted
Software program Demonstration, Assessment and Refinement</i>.
SDI-S-SD-91-000007, June 17, 1992. Washington, DC: SDIO. Prepared
by GE Aerospace, Strategic Systems Department, Blue Bell, PA. CDRL
A075-101B.</p>
<p>[Shankland2001] Shankland, Stephen. January 11, 2001.
&#8220;Borland InterBase backdoor detected&#8221;. ZDNet News.
<a href=
"http://news.zdnet.com/2100-9595_22-527115.html">http://news.zdnet.com/2100-9595_22-527115.html</a></p>
<p>[Singh2002] Singh, Prabhat K., and Arun Lakhotia. February 2002.
Analysis and Detection of Computer Viruses and Worms: An Annotated
Bibliography. <i>ACM SIGPLAN Notices</i>. Volume 37, Issue 2. pp.
29 &#8211; 35.</p>
<p>[Spencer1998] Henry Spencer. November 23, 1998. &#8220;Re: LWN -
The Trojan Horse (Bruce Perens)&#8221;. <i>Robust Open Source
mailing list</i> (open-source at csl.sri.com) established by Peter
G. Neumann.</p>
<p>[Spencer2005] Henry Spencer, private communication.</p>
<p>[Spinellis2003] Spinellis, Diomidis. June 2003.
&#8220;Reflections on Trusting Trust Revisited,&#8221;
<i>Communications of the ACM</i>. Volume 46, Number 6. <a href=
"http://www.dmst.aueb.gr/dds/pubs/jrnl/2003-CACM-Reflections2/html/reflections2.pdf">
http://www.dmst.aueb.gr/dds/pubs/jrnl/2003-CACM-Reflections2/html/reflections2.pdf</a></p>
<p>[Stoll1979] Stoll, Robert R. 1979. <i>Set Theory and Logic</i>.
Mineola, NY: Dover Publications, Inc. (This is the Dover edition,
first published in 1979, that is a corrected republication of the
work originally published in 1963 by W.H. Freeman and Company.)
ISBN 0-486-63829-4.</p>
<p>[Stringer-Calvert1998] David William John Stringer-Calvert.
March 1998. &#8220;Mechanical Verification of Compiler
Correctness&#8221; (PhD thesis). University of York, Department of
Computer Science. <a href=
"http://www.csl.sri.com/users/dave_sc/papers/thesis.ps.gz">http://www.csl.sri.com/users/dave_sc/papers/thesis.ps.gz</a></p>
<p>[Thompson1984] Thompson, Ken. April 1984. &#8220;Reflections on
Trusting Trust&#8221;. <i>Communications of the ACM</i>. Volume 27,
Number 8. pp. 761-763. <a href=
"http://www.acm.org/classics/sep95">http://www.acm.org/classics/sep95</a></p>
<p>[Thornburg2000] Thornburg, Jonathan. April 18, 2000.
&#8220;?Backdoor in Microsoft web server?&#8221;. Newsgroup
sci.crypt. <a href=
"http://groups-beta.google.com/group/sci.crypt/msg/9305502fd7d4ee6f">
http://groups-beta.google.com/group/sci.crypt/msg/9305502fd7d4ee6f</a>.</p>
<p>[Ulsch2000] Ulsch, MacDonnell. July 2000. &#8220;Security
Strategies for E-Companies (EC Does it series)&#8221;.
<i>Information Security Magazine</i>. <a href=
"http://infosecuritymag.techtarget.com/articles/july00/columns2_ec_doesit.shtml">
http://infosecuritymag.techtarget.com/articles/july00/columns2_ec_doesit.shtml</a></p>
<p>[vonHagen2006] von Hagen, William. <i>The Definitive Guide to
GCC</i>, Second Edition. 2006. New York: Springer-Verlag. ISBN
978-1-59059-585-5.</p>
<p>[Wheeler2003s] Wheeler, David A. 2003. <i>Secure Programming for
Linux and Unix HOWTO</i>. <a href=
"http://www.dwheeler.com/secure-programs/">http://www.dwheeler.com/secure-programs/</a></p>
<p>[Wheeler2003t] Wheeler, David A. October 2003. <i>Techniques for
Cyber Attack Attribution</i>. Institute for Defense Analyses (IDA).
IDA Paper P-3792. Log: H 03-001218. <a href=
"http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA468859&amp;Location=U2&amp;doc=GetTRDoc.pdf">
<font size="2" style=
"font-size: 11pt">http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA468859&amp;Location=U2&amp;doc=GetTRDoc.pdf</font></a></p>
<p>[Wheeler2005] Wheeler, David A. December 2005. &#8220;Countering
Trusting Trust through Diverse Double-Compiling (DDC)&#8221;.
<i>Proceedings of the Twenty-First Annual Computer Security
Applications Conference (ACSAC).</i> Tucson, Arizona, pp. 28-40,
Los Alamitos: IEEE Computer Society. ISBN 0-7695-2461-3, ISSN
1063-9527, IEEE Computer Society Order Number P2461. <a href=
"http://www.dwheeler.com/trusting-trust">http://www.dwheeler.com/trusting-trust</a></p>
<p>[Wheeler2007] Wheeler, David A. April 12, 2007. <i>Why OSS/FS?
Look at the Numbers!</i> <a href=
"http://www.dwheeler.com/oss_fs_why.html">http://www.dwheeler.com/oss_fs_why.html</a></p>
<p>[Wheeler2008] Wheeler, David A. May 14, 2008. <i>Is OpenDocument
an Open Standard? Yes!</i> <a href=
"http://www.dwheeler.com/essays/opendocument-open.html">http://www.dwheeler.com/essays/opendocument-open.html</a></p>
<p>[Wheeler2009f] Wheeler, David A. February 3, 2009.
<i>Free-Libre/&#8203;Open Source Software (FLOSS) is Commercial
Software</i>. <a href=
"http://www.dwheeler.com/essays/commercial-floss.html">http://www.dwheeler.com/essays/commercial-floss.html</a></p>
<p>[Wheeler2009i] Wheeler, David A. May 26, 2009. The Most
Important Software Innovations. <a href=
"http://www.dwheeler.com/innovation/innovation.html">http://www.dwheeler.com/innovation/innovation.html</a></p>
<p>[Wheeler2009s] Wheeler, David A. Revised July 29, 2009.
<i>Sweet-expressions: Version 0.2</i>. <a href=
"http://www.dwheeler.com/readable/version02.html">http://www.dwheeler.com/readable/version02.html</a></p>
<p>[Williams2009] Williams, Jeff (Aspect Security). July 29, 2009.
&#8220;Enterprise Java Rootkits: &#8216;Hardly anyone watches the
developers&#8217;&#8221;. <i>BlackHat USA</i>. <a href=
"http://www.blackhat.com/presentations/bh-usa-09/WILLIAMS/BHUSA09-Williams-EnterpriseJavaRootkits-PAPER.pdf">
http://www.blackhat.com/presentations/bh-usa-09/WILLIAMS/BHUSA09-Williams-EnterpriseJavaRootkits-PAPER.pdf</a></p>
<p>[Wirth1996] Wirth, Niklaus. 1996. <i>Compiler Construction</i>.
Addison-Wesley. ISBN 0-201-40353-6.</p>
<p>[Wysopal] Wysopal, Chris. 2007. &#8220;Static Detection of
Application Backdoors&#8221;. <i>Black Hat</i>. <a href=
"https://www.blackhat.com/presentations/bh-usa-07/Wysopal_and_Eng/Whitepaper/bh-usa-07-wysopal_and_eng-WP.pdf">
https://www.blackhat.com/presentations/bh-usa-07/Wysopal_and_Eng/Whitepaper/bh-usa-07-wysopal_and_eng-WP.pdf</a></p>
<p>[Zitser2004] Zitser, Misha, Richard Lippmann, and Tim Leek.
2004. &#8220;Testing Static Analysis Tools using Exploitable Buffer
Overflows from Open Source Code&#8221;. <i>Proc. FSE-12, ACM
SIGSOFT</i>. <a href=
"http://www.ll.mit.edu/IST/pubs/04_TestingStatic_Zitser.pdf">http://www.ll.mit.edu/IST/pubs/04_TestingStatic_Zitser.pdf</a></p>
<p><br>
<br></p>
<h1>Footnotes</h1>
<div id="sdfootnote1">
<p><a class="sdfootnotesym" name="sdfootnote1sym" href=
"#sdfootnote1anc">1</a> An <i>executable</i> is data that can be
directly executed by a computing environment. An executable may be
code for an actual machine or for a simulated machine (e.g., a
&#8220;byte code&#8221;). A common alternative term for executable
is &#8220;binary&#8221; (e.g., [Sabin2004]), but this term is
misleading; in modern computers, <i>all</i> data is represented
using binary codes. For purposes of this dissertation,
&#8220;object code&#8221; is a synonym for
&#8220;executable&#8221;. <i>Source code</i> is a representation of
a program that can be translated into an executable, and is
typically human-readable. A <i>compiler</i> is an executable that
when executed translates source code into an executable (it may
also perform other actions). An <i>assembler</i> is a compiler for
a language whose instructions are primarily a close approximation
of the executing environment&#8217;s instructions. The process of
using a compiler to translate source code into an executable is
termed <i>compiling</i>.</p>
</div>
<div id="sdfootnote2">
<p><a class="sdfootnotesym" name="sdfootnote2sym" href=
"#sdfootnote2anc">2</a> An executable e corresponds to source code
s if and only if execution of e always behaves as specified by s
when the execution environment of e behaves correctly.</p>
</div>
<div id="sdfootnote3">
<p><a class="sdfootnotesym" name="sdfootnote3sym" href=
"#sdfootnote3anc">3</a> Determining if two executables are
equivalent is undecidable in general; see section 5.6.1.</p>
</div>
<div id="sdfootnote4">
<p><a class="sdfootnotesym" name="sdfootnote4sym" href=
"#sdfootnote4anc">4</a> This is theorem 2 (the bootstrap test
theorem) of [Goerigk1999]. For clarity, the text has been modified
so that its notation is the same as the notation used in this
dissertation.</p>
</div>
<div id="sdfootnote5">
<p><a class="sdfootnotesym" name="sdfootnote5sym" href=
"#sdfootnote5anc">5</a> CERT is not an acronym.</p>
</div>
<div id="sdfootnote6">
<p><a class="sdfootnotesym" name="sdfootnote6sym" href=
"#sdfootnote6anc">6</a> Open source software is, briefly, software
where users have the right to use the software for any purpose,
review it, modify it, and redistribute it (modified or not) without
requiring royalty payments [Wheeler2007]. The Open Source
Definition [OSI2006] and the Free Software Definition [FSF2009]
have more formal definitions for this term or the related term
&#8220;Free software&#8221;. There is quantitative data showing
that, in many cases, using open source software/&#8203;Free
software (abbreviated as OSS/FS, FLOSS, or FOSS) is a reasonable or
even superior approach to using their proprietary competition
according to various measures [Wheeler2007]. In almost all cases,
it is commercial software [Wheeler2009f].</p>
</div>
<div id="sdfootnote7">
<p><a class="sdfootnotesym" name="sdfootnote7sym" href=
"#sdfootnote7anc">7</a> Even if the attack is eventually detected,
if the attacker can be assured that the attack will not be detected
for a very long time, the attacker may still find it valuable. The
attacker could, for example, use this lengthy time to successfully
perform other attacks and subvert an infrastructure in many other
ways. Also, if the original attack is not detected for a long time,
it is often increasingly difficult to determine the identity of the
attacker or at least an important intermediary. For a summary of
techniques that can resolve this &#8220;attribution&#8221; problem,
see [Wheeler2003t].</p>
</div>
<div id="sdfootnote8">
<p><a class="sdfootnotesym" name="sdfootnote8sym" href=
"#sdfootnote8anc">8</a> DDC will not create an identical executable
unless the regeneration check would succeed, and so from that
perspective the regeneration check is mandatory. <i>Performing</i>
the regeneration check has not been made mandatory, because there
may be other evidence that it would succeed, but in most cases it
is strongly recommended.</p>
</div>
<div id="sdfootnote9">
<p><a class="sdfootnotesym" name="sdfootnote9sym" href=
"#sdfootnote9anc">9</a> For an &#8220;analysis and interpretation
of the process that led to First-Order Logic and its consolidation
as a core system of modern logic&#8221; see [Ferreir&#243;s2001].
An alternative to classical logic is intuitionist logic, which does
not accept the equivalence of <img src=
"wheeler-trusting-trust-ddc_html_2e4598d8.gif" alt="&not;&not;&Phi;" align="absmiddle" width="32" height="18"> and <img src=
"wheeler-trusting-trust-ddc_html_4072c6c2.gif" alt="&Phi;"
align="absmiddle" width="11" height="18"> as being universally
true; [Hesseling2003] describes in detail the early history of
intuitionist logic.</p>
</div>
<div id="sdfootnote10">
<p><a class="sdfootnotesym" name="sdfootnote10sym" href=
"#sdfootnote10anc">10</a> As a notation, FOL does have weaknesses.
For example, predicates and functions cannot have formulas
(booleans) as parameters, so traditional FOL cannot express a
function <i>if_then_else(formula1, term1, term2)</i> that returns
term1 if formula1 is true, else it returns term2. FOL also does not
include built-in support for types (sorts). There are extensions
and alternatives which remove these weaknesses. However, since
these FOL weaknesses do not interfere in the proof of DDC, and
since traditional FOL is both widely-understood and
widely-implemented, FOL is used in this dissertation.</p>
</div>
<div id="sdfootnote11">
<p><a class="sdfootnotesym" name="sdfootnote11sym" href=
"#sdfootnote11anc">11</a> For example, the original hand-created
proofs did not account for the possibility of different
environments. When attempting to modify the proofs to account for
the different environments, the painful &#8220;bookkeeping&#8221;
required to keep the proof accurate soon led the author to look for
an automated tool.</p>
</div>
<div id="sdfootnote12">
<p><a class="sdfootnotesym" name="sdfootnote12sym" href=
"#sdfootnote12anc">12</a> &#8220;S-expression&#8221; is short for
&#8220;symbolic expression&#8221;. It is a convention for
representing semi-structured data in human-readable textual form,
and is used for both code and data in Lisp. For our purposes, an
S-expression may be an atom (a number, symbol, or special term NIL)
or a list; a list contains 0 or more ordered S-expressions. The
actual definition is more complex (involving CONS pairs), but this
is not important for purposes of this dissertation.</p>
</div>
<div id="sdfootnote13">
<p><a class="sdfootnotesym" name="sdfootnote13sym" href=
"#sdfootnote13anc">13</a> As noted in section 5.2, the FOL notation
used in this paper does not have a built-in mechanism for notating
types such as &#8220;data&#8221; or &#8220;executable&#8221;. As
explained in section 5.1.1, types are noted to make the proof
easier to understand, even though they are not directly used in the
proof&#8217;s formal notation.</p>
</div>
<div id="sdfootnote14">
<p><a class="sdfootnotesym" name="sdfootnote14sym" href=
"#sdfootnote14anc">14</a> Such as
&#8220;sP_when_accurately_compiled_compiles_sA&#8221;</p>
</div>
<div id="sdfootnote15">
<p><a class="sdfootnotesym" name="sdfootnote15sym" href=
"#sdfootnote15anc">15</a> UTF-8 is short for &#8220;8-bit
UCS/Unicode Transformation Format&#8221;, where UCS is short for
&#8220;Universal Character set&#8221;. UTF-16 is short for
&#8220;16-bit UCS/Unicode Transformation Format&#8221;. EBCDIC is
an abbreviation for &#8220;Extended Binary Coded Decimal
Interchange Code&#8221;. As noted earlier, ASCII is short for
&#8220;American Standard Code for Information Interchange&#8221;.
These terms are normally used only as acronyms.</p>
</div>
<div id="sdfootnote16">
<p><a class="sdfootnotesym" name="sdfootnote16sym" href=
"#sdfootnote16anc">16</a> My thanks to Aaron Hatcher, who made this
observation.</p>
</div>
<div id="sdfootnote17">
<p><a class="sdfootnotesym" name="sdfootnote17sym" href=
"#sdfootnote17anc">17</a> My thanks to Aaron Hatcher, who attempted
to apply DDC to various versions of GCC included in Fedora Core,
and to Jakub Jelinek of Red Hat, who tried to provide Aaron with
the necessary information to regenerate the executables
after-the-fact. Aaron&#8217;s efforts were unsuccessful at the
time, but they provided insight that later led to the successful
application by Wheeler that is described here.</p>
</div>
<div id="sdfootnote18">
<p><a class="sdfootnotesym" name="sdfootnote18sym" href=
"#sdfootnote18anc">18</a> In practice, unexpected differences
between the &#8220;actual&#8221; and &#8220;expected&#8221;
hardware results may be frequent, due to issues such as incomplete
information and errors, but such differences could be
malicious.</p>
</div>
<div id="sdfootnote19">
<p><a class="sdfootnotesym" name="sdfootnote19sym" href=
"#sdfootnote19anc">19</a> It could be argued that the existence of
the DDC technique gives open source software and other software
whose source code is publicly available a decisive security
advantage, since only such software can be examined at the source
code level by anyone to determine if the corresponding executable
is malicious.</p>
</div>
<div id="sdfootnote20">
<p><a class="sdfootnotesym" name="sdfootnote20sym" href=
"#sdfootnote20anc">20</a> The Digital Standards Organization
defines &#8220;free and open standard&#8221; as follows:</p>
<div style="margin-left: 2em">
<ul>
<li>
<p>A free and open standard is immune to vendor capture at all
stages in its life-cycle. Immunity from vendor capture makes it
possible to freely use, improve upon, trust, and extend a standard
over time.</p>
</li>
<li>
<p>The standard is adopted and will be maintained by a
not-for-profit organization, and its ongoing development occurs on
the basis of an open decision-making procedure available to all
interested parties.</p>
</li>
<li>
<p>The standard has been published and the standard specification
document is available freely. It must be permissible to all to
copy, distribute, and use it freely.</p>
</li>
<li>
<p>The patents possibly present on (parts of) the standard are made
irrevocably available on a royalty-free basis.</p>
</li>
<li>
<p>There are no constraints on the re-use of the standard.</p>
</li>
</ul>
</div>
<p>The economic outcome of a free and open standard is that it
enables perfect competition between suppliers of products based on
the standard [Digistan]. Patents, by definition, are exclusive and
thus necessarily discriminatory when royalty payments or other
conditions are imposed. See [Wheeler2008] for a comparison of
various definitions of &#8220;open standard&#8221; and their
application to a particular specification.</p>
</div>
<h1>Curriculum Vitae</h1>
<p><img src="wheeler-trusting-trust-ddc_html_5ec3dd4a.jpg" alt="Picture of the very handsome David A. Wheeler" align="left" width="150" height="240"
border="0"><a href="http://www.dwheeler.com/">David A. Wheeler</a>
was born May 1965 in the United States of America and is an
American citizen. He completed his B.S. in Electronics Engineering
(with distinction) at George Mason University (GMU) in 1987
(awarded January 1988). He received his M.S. in Computer Science
and a certificate for Software Engineering at GMU in 1994, when he
also received a Computer Science graduate honor roll award. In 2000
he received a certificate in Information Systems Security from GMU.
In 2009 he completed his requirements for a PhD in Information
Technology from GMU.</p>
<p>From 1982 on he worked as a computer consultant, solving a
variety of problems. He also spent time as the maintainer of the
U.S.&#8217; first commercial multi-user role-playing game. In 1988
he joined the Institute for Defense Analyses (IDA), where he
continues to solve challenging problems. His numerous awards
include the Ada Programming Contest Award, membership in the Eta
Kappa Nu Honor Society, and the George Washington University
Engineering Award; he is also an Eagle Scout. His books include
<i>Software Inspection: An Industry Best Practice</i> (IEEE
Computer Society Press), <i>Ada 95: The Lovelace Tutorial</i>
(Springer-Verlag), and <i>Secure Programming for Linux and Unix
HOWTO</i> (self-published). His numerous articles include his
developerWorks column &#8220;Secure Programmer&#8221;, the article
<i>Why Open Source Software / Free Software? Look at the
Numbers!,</i> and &#8220;Countering Trusting Trust through Diverse
Double-Compiling (DDC)&#8221; in <i>Proceedings of the Twenty-First
Annual Computer Security Applications Conference</i> (ACSAC 2005).
He has long worked on tasks related to large or high-risk systems,
and in particular specializes in developing secure software,
Free-libre/&#8203;open source software (FLOSS), and open
standards.</p>
<p>For more information, including contact information, see David
A. Wheeler&#8217;s personal website at &lt;<a href=
"http://www.dwheeler.com/">http://www.dwheeler.com</a>&gt;.</p>
</body>
</html>

